[
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/batch_job_oai/#bulk-generation-of-synthetic-data)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/batch_job_oai.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/batch_job_oai.md \"View source of this page\")\n\n# Bulk Generation of Synthetic Data [¶](https://python.useinstructor.com/examples/batch_job_oai/\\#bulk-generation-of-synthetic-data \"Permanent link\")\n\nThis tutorial shows how to use `instructor` to generate large quantities of synthetic data at scale using Open AI's new Batch API. In this example, we'll be generating synthetic questions using the `ms-marco` dataset to evaluate RAG retrieval.\n\nWhy use the batch API?\n\nThere are a few reasons why you might want to use the Batch API\n\n1. Batch Jobs are 50% cheaper than running an inference job on demand ( see Open AI's pricing page [here](https://openai.com/api/pricing/) )\n\n2. Batch Jobs have higher rate limits than normal api calls\n\n3. Batch Jobs support both normal models **and fine-tuned models**\n\n\nThis makes them perfect for non time-sensitive tasks that involve large quantities of data.\n\n## Getting Started [¶](https://python.useinstructor.com/examples/batch_job_oai/\\#getting-started \"Permanent link\")\n\nLet's first see how we can generate a Question and Answer Pair using Instructor with a normal OpenAI function call.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom openai import OpenAI\nfrom instructor import from_openai\n\nclient = from_openai(OpenAI())\n\nclass QuestionAnswerPair(BaseModel):\n    \"\"\"\n    This model represents a pair of a question generated from a text chunk, its corresponding answer,\n    and the chain of thought leading to the answer. The chain of thought provides insight into how the answer\n    was derived from the question.\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        description=\"The reasoning process leading to the answer.\"\n    )\n    question: str = Field(description=\"The generated question from the text chunk.\")\n    answer: str = Field(description=\"The answer to the generated question.\")\n\ndef generate_question(chunk: str) -> QuestionAnswerPair:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a world class AI that excels at generating hypothethical search queries. You're about to be given a text snippet and asked to generate a search query which is specific to the specific text chunk that you'll be given. Make sure to use information from the text chunk.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": f\"Here is the text chunk: {chunk}\"},\\\n        ],\n        response_model=QuestionAnswerPair,\n    )\n\ntext_chunk = \"\"\"\nThe Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia 's central bank and banknote issuing authority, when the Reserve Bank Act 1959 removed the central banking functions from the Commonwealth Bank. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\n\"\"\"\nprint(generate_question(text_chunk).model_dump_json(indent=2))\n\"\"\"\n{\n  \"chain_of_thought\": \"The text discusses the formation of the Reserve Bank of Australia (RBA) and provides key details about its establishment date, the removal of central banking functions from the Commonwealth Bank, its asset worth, and its employee distribution. By focusing on these details, a search query can be framed around the establishment date and purpose of the RBA.\",\n  \"question\": \"When was the Reserve Bank of Australia established and what are its main functions?\",\n  \"answer\": \"The Reserve Bank of Australia was established on 14 January 1960 as Australia's central bank and banknote issuing authority.\"\n}\n\"\"\"\n\n```\n\nAs the number of chunks we'd like to generate these synthetic questions for increases, the cost will grow proportionally.\n\nLet's see how we can use the `BatchJob` object to create a `.jsonl` file which is compatible with the Batch API.\n\n```md-code__content\nfrom datasets import load_dataset\nfrom instructor.batch import BatchJob\nfrom pydantic import BaseModel, Field\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ms_marco\", \"v1.1\", split=\"train\", streaming=True).take(200)\n\ndef get_messages(dataset):\n    for row in dataset:\n        for passage in row['passages']['passage_text']:\n            yield [\\\n                {\\\n                    \"role\": \"system\",\\\n                    \"content\": \"You are a world class AI that excels at generating hypothethical search queries. You're about to be given a text snippet and asked to generate a search query which is specific to the specific text chunk that you'll be given. Make sure to use information from the text chunk.\",\\\n                },\\\n                {\"role\": \"user\", \"content\": f\"Here is the text chunk: {passage}\"},\\\n            ]\n\nclass QuestionAnswerPair(BaseModel):\n    \"\"\"\n    This model represents a pair of a question generated from a text chunk, its corresponding answer,\n    and the chain of thought leading to the answer. The chain of thought provides insight into how the answer\n    was derived from the question.\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        description=\"The reasoning process leading to the answer.\"\n    )\n    question: str = Field(description=\"The generated question from the text chunk.\")\n    answer: str = Field(description=\"The answer to the generated question.\")\n\nBatchJob.create_from_messages(\n    messages_batch=get_messages(dataset),\n    model=\"gpt-4o\",\n    file_path=\"./test.jsonl\",\n    response_model=QuestionAnswerPair,\n)\n\n```\n\nOnce we've got this new `.jsonl` file, we can then use the new `instructor` cli's `batch` command to create a new batch job.\n\n```md-code__content\n> % ls -a | grep test.jsonl\ntest.jsonl\n\n> % instructor batch create-from-file --file-path test.jsonl\n\n```\n\nThis will create a table like what you see below. In my case, my batch job took around 6 minutes to complete and cost me $2.72 to run.\n\n| Batch ID | Created At | Status | Failed | Completed | Total |\n| --- | --- | --- | --- | --- | --- |\n| batch\\_Z8XUudoweH43R9c4sr4wRYub | 2024-07-16 12:45:22 | in\\_progress | 0 | 483 | 1627 |\n\nOnce our batch job is complete, the status will change to `completed`.\n\nCancelling A Job\n\nIf you'd like to cancel a batch job midway, you can do so too with the instructor `batch` cli command\n\n```md-code__content\ninstructor batch cancel --batch-id <batch id here>\n\n```\n\nWe can then download the file generated by the batch job using the cli command\n\n```md-code__content\ninstructor batch download-file --download-file-path output.jsonl --batch-id batch_Z8XUudoweH43R9c4sr4wRYub\n\n```\n\nThis will then create a `.jsonl` file with the generated content at the path that you specify.\n\n## Parsing the generated response [¶](https://python.useinstructor.com/examples/batch_job_oai/\\#parsing-the-generated-response \"Permanent link\")\n\nWe can then parse the generated response by using the `.parse_from_file` command provided by the `BatchJob` class.\n\n```md-code__content\nfrom instructor.batch import BatchJob\nfrom pydantic import BaseModel, Field\n\nclass QuestionAnswerPair(BaseModel):\n    \"\"\"\n    This model represents a pair of a question generated from a text chunk, its corresponding answer,\n    and the chain of thought leading to the answer. The chain of thought provides insight into how the answer\n    was derived from the question.\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        description=\"The reasoning process leading to the answer.\"\n    )\n    question: str = Field(description=\"The generated question from the text chunk.\")\n    answer: str = Field(description=\"The answer to the generated question.\")\n\nparsed, unparsed = BatchJob.parse_from_file(\n    file_path=\"./output.jsonl\", response_model=QuestionAnswerPair\n)\n\nprint(len(parsed))\n#> 0\nprint(len(unparsed))\n#> 0\n\n```\n\nThis will then return a list of two elements\n\n- `parsed` is a list of responses that have been succesfully parsed into the `QuestionAnswerPair` Base Model class\n- `unparsed` is a second list which contains responses which were not able to be parsed into the `QuestionAnswerPair` Base Model class\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/batch_job_oai/",
      "ogUrl": "https://python.useinstructor.com/examples/batch_job_oai/",
      "title": "Generating Synthetic Data with OpenAI's Batch API - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/batch_job_oai/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/batch_job_oai.png",
      "ogTitle": "Generating Synthetic Data with OpenAI's Batch API - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/batch_job_oai.png",
      "og:title": "Generating Synthetic Data with OpenAI's Batch API - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/batch_job_oai/",
      "statusCode": 200,
      "description": "Learn to use OpenAI's Batch API for large-scale synthetic data generation, focusing on question-answer pairs from the ms-marco dataset.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to use OpenAI's Batch API for large-scale synthetic data generation, focusing on question-answer pairs from the ms-marco dataset.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/batch_job_oai.png",
      "twitter:title": "Generating Synthetic Data with OpenAI's Batch API - Instructor",
      "og:description": "Learn to use OpenAI's Batch API for large-scale synthetic data generation, focusing on question-answer pairs from the ms-marco dataset.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to use OpenAI's Batch API for large-scale synthetic data generation, focusing on question-answer pairs from the ms-marco dataset."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/pii/#pii-data-extraction-and-scrubbing)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/pii.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/pii.md \"View source of this page\")\n\n# PII Data Extraction and Scrubbing [¶](https://python.useinstructor.com/examples/pii/\\#pii-data-extraction-and-scrubbing \"Permanent link\")\n\n## Overview [¶](https://python.useinstructor.com/examples/pii/\\#overview \"Permanent link\")\n\nThis example demonstrates the usage of OpenAI's ChatCompletion model for the extraction and scrubbing of Personally Identifiable Information (PII) from a document. The code defines Pydantic models to manage the PII data and offers methods for both extraction and sanitation.\n\n## Defining the Structures [¶](https://python.useinstructor.com/examples/pii/\\#defining-the-structures \"Permanent link\")\n\nFirst, Pydantic models are defined to represent the PII data and the overall structure for PII data extraction.\n\n```md-code__content\nfrom typing import List\nfrom pydantic import BaseModel\n\n# Define Schemas for PII data\nclass Data(BaseModel):\n    index: int\n    data_type: str\n    pii_value: str\n\nclass PIIDataExtraction(BaseModel):\n    \"\"\"\n    Extracted PII data from a document, all data_types should try to have consistent property names\n    \"\"\"\n\n    private_data: List[Data]\n\n    def scrub_data(self, content: str) -> str:\n        \"\"\"\n        Iterates over the private data and replaces the value with a placeholder in the form of\n        <{data_type}_{i}>\n        \"\"\"\n        for i, data in enumerate(self.private_data):\n            content = content.replace(data.pii_value, f\"<{data.data_type}_{i}>\")\n        return content\n\n```\n\n## Extracting PII Data [¶](https://python.useinstructor.com/examples/pii/\\#extracting-pii-data \"Permanent link\")\n\nThe OpenAI API is utilized to extract PII information from a given document.\n\n```md-code__content\nfrom openai import OpenAI\nimport instructor\n\nclient = instructor.from_openai(OpenAI())\n\nEXAMPLE_DOCUMENT = \"\"\"\n# Fake Document with PII for Testing PII Scrubbing Model\n# (The content here)\n\"\"\"\n\npii_data = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    response_model=PIIDataExtraction,\n    messages=[\\\n        {\\\n            \"role\": \"system\",\\\n            \"content\": \"You are a world class PII scrubbing model, Extract the PII data from the following document\",\\\n        },\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": EXAMPLE_DOCUMENT,\\\n        },\\\n    ],\n)  # type: ignore\n\nprint(\"Extracted PII Data:\")\n#> Extracted PII Data:\nprint(pii_data.model_dump_json())\n\"\"\"\n{\"private_data\":[{\"index\":1,\"data_type\":\"Name\",\"pii_value\":\"John Doe\"},{\"index\":2,\"data_type\":\"Email\",\"pii_value\":\"john.doe@example.com\"},{\"index\":3,\"data_type\":\"Phone\",\"pii_value\":\"+1234567890\"},{\"index\":4,\"data_type\":\"Address\",\"pii_value\":\"1234 Elm Street, Springfield, IL 62704\"},{\"index\":5,\"data_type\":\"SSN\",\"pii_value\":\"123-45-6789\"}]}\n\"\"\"\n\n```\n\n### Output of Extracted PII Data [¶](https://python.useinstructor.com/examples/pii/\\#output-of-extracted-pii-data \"Permanent link\")\n\n```md-code__content\n{\n  \"private_data\": [\\\n    {\\\n      \"index\": 0,\\\n      \"data_type\": \"date\",\\\n      \"pii_value\": \"01/02/1980\"\\\n    },\\\n    {\\\n      \"index\": 1,\\\n      \"data_type\": \"ssn\",\\\n      \"pii_value\": \"123-45-6789\"\\\n    },\\\n    {\\\n      \"index\": 2,\\\n      \"data_type\": \"email\",\\\n      \"pii_value\": \"john.doe@email.com\"\\\n    },\\\n    {\\\n      \"index\": 3,\\\n      \"data_type\": \"phone\",\\\n      \"pii_value\": \"555-123-4567\"\\\n    },\\\n    {\\\n      \"index\": 4,\\\n      \"data_type\": \"address\",\\\n      \"pii_value\": \"123 Main St, Springfield, IL, 62704\"\\\n    }\\\n  ]\n}\n\n```\n\n## Scrubbing PII Data [¶](https://python.useinstructor.com/examples/pii/\\#scrubbing-pii-data \"Permanent link\")\n\nAfter extracting the PII data, the `scrub_data` method is used to sanitize the document.\n\n```md-code__content\nprint(\"Scrubbed Document:\")\n#> Scrubbed Document:\nprint(pii_data.scrub_data(EXAMPLE_DOCUMENT))\n\"\"\"\n# Fake Document with PII for Testing PII Scrubbing Model\n# He was born on <date_0>. His social security number is <ssn_1>. He has been using the email address <email_2> for years, and he can always be reached at <phone_3>.\n\"\"\"\n\n```\n\n### Output of Scrubbed Document [¶](https://python.useinstructor.com/examples/pii/\\#output-of-scrubbed-document \"Permanent link\")\n\n```md-code__content\n# Fake Document with PII for Testing PII Scrubbing Model\n\n## Personal Story\n\nJohn Doe was born on <date_0>. His social security number is <ssn_1>. He has been using the email address <email_2> for years, and he can always be reached at <phone_3>.\n\n## Residence\n\nJohn currently resides at <address_4>. He's been living there for about 5 years now.\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/pii/",
      "ogUrl": "https://python.useinstructor.com/examples/pii/",
      "title": "Extracting and Scrubbing PII Data with OpenAI - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/pii/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/pii.png",
      "ogTitle": "Extracting and Scrubbing PII Data with OpenAI - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/pii.png",
      "og:title": "Extracting and Scrubbing PII Data with OpenAI - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/pii/",
      "statusCode": 200,
      "description": "Learn to extract and sanitize Personally Identifiable Information (PII) from documents using OpenAI's ChatCompletion model and Python.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to extract and sanitize Personally Identifiable Information (PII) from documents using OpenAI's ChatCompletion model and Python.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/pii.png",
      "twitter:title": "Extracting and Scrubbing PII Data with OpenAI - Instructor",
      "og:description": "Learn to extract and sanitize Personally Identifiable Information (PII) from documents using OpenAI's ChatCompletion model and Python.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to extract and sanitize Personally Identifiable Information (PII) from documents using OpenAI's ChatCompletion model and Python."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/#cookbooks)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/index.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/index.md \"View source of this page\")\n\n# Cookbooks [¶](https://python.useinstructor.com/examples/\\#cookbooks \"Permanent link\")\n\nWelcome to our collection of cookbooks showcasing the power of structured outputs in AI applications. These examples demonstrate how to effectively use instructor with various models and APIs to solve real-world problems.\n\n## Quick Links [¶](https://python.useinstructor.com/examples/\\#quick-links \"Permanent link\")\n\n01. [Enum-Based Classification](https://python.useinstructor.com/examples/classification/): Implement structured classification using Python enums with AI models.\n02. [AI Self-Assessment and Correction](https://python.useinstructor.com/examples/self_critique/): Explore techniques for AI models to evaluate and improve their own outputs.\n03. [Efficient Batch Classification](https://python.useinstructor.com/examples/bulk_classification/): Process multiple items simultaneously for improved performance.\n04. [Precise Citation Extraction](https://python.useinstructor.com/examples/exact_citations/): Accurately retrieve and format citations from text using AI.\n05. [Search Query Segmentation](https://python.useinstructor.com/examples/search/): Break down complex search queries into structured components for better understanding.\n06. [Dynamic Knowledge Graph Generation](https://python.useinstructor.com/examples/knowledge_graph/): Create visual representations of information relationships using AI.\n07. [Complex Query Decomposition](https://python.useinstructor.com/examples/planning-tasks/): Break down intricate queries into manageable subtasks for thorough analysis.\n08. [Entity Extraction and Resolution](https://python.useinstructor.com/examples/entity_resolution/): Identify and disambiguate named entities in text.\n09. [PII Sanitization](https://python.useinstructor.com/examples/pii/): Detect and redact sensitive personal information from text data.\n10. [Action Item Extraction](https://python.useinstructor.com/examples/planning-tasks/): Generate structured task lists and relationships from meeting transcripts.\n11. [OpenAI Content Moderation Integration](https://python.useinstructor.com/examples/moderation/): Implement content filtering using OpenAI's moderation API.\n12. [Table Extraction with GPT-Vision](https://python.useinstructor.com/examples/extracting_tables/): Convert image-based tables into structured data using AI vision capabilities.\n13. [AI-Powered Ad Copy Generation from Images](https://python.useinstructor.com/examples/image_to_ad_copy/): Create compelling advertising text based on visual content.\n14. [Local AI with Ollama Integration](https://python.useinstructor.com/examples/ollama/): Utilize open-source language models for on-device processing.\n15. [Database Integration with SQLModel](https://python.useinstructor.com/examples/sqlmodel/): Seamlessly store AI-generated responses in SQL databases.\n16. [LLM-Based Document Segmentation](https://python.useinstructor.com/examples/document_segmentation/): Intelligently divide long documents into meaningful sections.\n17. [Cost Optimization with OpenAI's Batch API](https://python.useinstructor.com/examples/batch_job_oai/): Reduce API costs by processing multiple requests efficiently.\n18. [Groq Cloud API Integration](https://python.useinstructor.com/examples/groq/): Leverage Groq's high-performance AI inference platform.\n19. [Mistral and Mixtral Model Usage](https://python.useinstructor.com/examples/mistral/): Implement state-of-the-art open-source language models in your projects.\n20. [Multi-Modal AI with Gemini](https://python.useinstructor.com/examples/multi_modal_gemini/): Process and analyze text, images, and other data types simultaneously.\n21. [IBM watsonx.ai Integration](https://python.useinstructor.com/examples/watsonx/): Utilize IBM's enterprise AI platform for advanced language processing tasks.\n22. [Receipt Information Extraction with GPT-4 Vision](https://python.useinstructor.com/examples/extracting_receipts/): Extract structured data from receipt images using advanced AI vision capabilities.\n23. [Slide Content Extraction with GPT-4 Vision](https://python.useinstructor.com/examples/extract_slides/): Convert presentation slide images into structured, analyzable text data.\n24. [Few-Shot Learning with Examples](https://python.useinstructor.com/examples/examples/): Improve AI model performance by providing contextual examples in prompts.\n25. [Local Classification without API](https://python.useinstructor.com/examples/local_classification/): Perform text classification tasks locally without relying on external API calls.\n26. [Action Items Extraction](https://python.useinstructor.com/examples/action_items/): Extract structured action items and tasks from text content.\n27. [Batch Classification with LangSmith](https://python.useinstructor.com/examples/batch_classification_langsmith/): Efficiently classify content in batches using LangSmith integration.\n28. [Contact Information Extraction](https://python.useinstructor.com/examples/extract_contact_info/): Extract structured contact details from unstructured text.\n29. [Knowledge Graph Building](https://python.useinstructor.com/examples/building_knowledge_graph.md): Create and manipulate knowledge graphs from textual data.\n30. [Multiple Classification Tasks](https://python.useinstructor.com/examples/multiple_classification/): Handle multiple classification categories simultaneously.\n31. [Pandas DataFrame Integration](https://python.useinstructor.com/examples/pandas_df/): Work with structured data using Pandas DataFrames.\n32. [Partial Response Streaming](https://python.useinstructor.com/examples/partial_streaming/): Stream partial results for real-time processing.\n33. [Single Classification Tasks](https://python.useinstructor.com/examples/single_classification/): Implement focused single-category classification.\n34. [Table Extraction from Images](https://python.useinstructor.com/examples/tables_from_vision/): Convert visual tables into structured data formats.\n35. [YouTube Clip Analysis](https://python.useinstructor.com/examples/youtube_clips/): Extract and analyze information from YouTube video clips.\n\n## Subscribe to our Newsletter for Updates and Tips [¶](https://python.useinstructor.com/examples/\\#subscribe-to-our-newsletter-for-updates-and-tips \"Permanent link\")\n\nIf you want to get updates on new features and tips on how to use Instructor, you can subscribe to our newsletter below to get notified when we publish new content.\n\nEmail\n\nSubscribe\n\nWas this page helpful?",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/",
      "ogUrl": "https://python.useinstructor.com/examples/",
      "title": "Comprehensive AI Cookbook Collection - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/",
      "robots": "noindex",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/index.png",
      "ogTitle": "Comprehensive AI Cookbook Collection - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/index.png",
      "og:title": "Comprehensive AI Cookbook Collection - Instructor",
      "viewport": [
        "width=device-width,initial-scale=1",
        "width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"
      ],
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/",
      "statusCode": 200,
      "description": "Explore diverse AI applications with cookbooks showcasing structured techniques for improved performance and efficiency.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Explore diverse AI applications with cookbooks showcasing structured techniques for improved performance and efficiency.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/index.png",
      "twitter:title": "Comprehensive AI Cookbook Collection - Instructor",
      "og:description": "Explore diverse AI applications with cookbooks showcasing structured techniques for improved performance and efficiency.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Explore diverse AI applications with cookbooks showcasing structured techniques for improved performance and efficiency."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/classification/#text-classification-using-openai-and-pydantic)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/classification.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/classification.md \"View source of this page\")\n\n# Text Classification using OpenAI and Pydantic [¶](https://python.useinstructor.com/examples/classification/\\#text-classification-using-openai-and-pydantic \"Permanent link\")\n\nThis tutorial showcases how to implement text classification tasks—specifically, single-label and multi-label classifications—using the OpenAI API and Pydantic models. For complete examples, check out our [single classification](https://python.useinstructor.com/examples/bulk_classification/#single-label-classification) and [multi-label classification](https://python.useinstructor.com/examples/bulk_classification/#multi-label-classification) examples in the cookbook.\n\nMotivation\n\nText classification is a common problem in many NLP applications, such as spam detection or support ticket categorization. The goal is to provide a systematic way to handle these cases using OpenAI's GPT models in combination with Python data structures.\n\n## Single-Label Classification [¶](https://python.useinstructor.com/examples/classification/\\#single-label-classification \"Permanent link\")\n\n### Defining the Structures [¶](https://python.useinstructor.com/examples/classification/\\#defining-the-structures \"Permanent link\")\n\nFor single-label classification, we define a Pydantic model with a [Literal](https://python.useinstructor.com/concepts/prompting/#literals) field for the possible labels.\n\nLiterals vs Enums\n\nWe prefer using `Literal` types over `enum` for classification labels. Literals provide better type checking and are more straightforward to use with Pydantic models.\n\nFew-Shot Examples\n\nIncluding few-shot examples in the model's docstring is crucial for improving the model's classification accuracy. These examples guide the AI in understanding the task and expected outputs.\n\nIf you want to learn more prompting tips check out our [prompting guide](https://python.useinstructor.com/prompting/)\n\nChain of Thought\n\nUsing [Chain of Thought](https://python.useinstructor.com/concepts/prompting/#chain-of-thought) has been shown to improve the quality of the predictions by ~ 10%\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\nfrom openai import OpenAI\nimport instructor\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\nclass ClassificationResponse(BaseModel):\n    \"\"\"\n    A few-shot example of text classification:\n\n    Examples:\n    - \"Buy cheap watches now!\": SPAM\n    - \"Meeting at 3 PM in the conference room\": NOT_SPAM\n    - \"You've won a free iPhone! Click here\": SPAM\n    - \"Can you pick up some milk on your way home?\": NOT_SPAM\n    - \"Increase your followers by 10000 overnight!\": SPAM\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        ...,\n        description=\"The chain of thought that led to the prediction.\",\n    )\n    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n        ...,\n        description=\"The predicted class label.\",\n    )\n\n```\n\n### Classifying Text [¶](https://python.useinstructor.com/examples/classification/\\#classifying-text \"Permanent link\")\n\nThe function **`classify`** will perform the single-label classification.\n\n```md-code__content\ndef classify(data: str) -> ClassificationResponse:\n    \"\"\"Perform single-label classification on the input text.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=ClassificationResponse,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Classify the following text: <text>{data}</text>\",\\\n            },\\\n        ],\n    )\n\n```\n\n### Testing and Evaluation [¶](https://python.useinstructor.com/examples/classification/\\#testing-and-evaluation \"Permanent link\")\n\nLet's run examples to see if it correctly identifies spam and non-spam messages.\n\n```md-code__content\nif __name__ == \"__main__\":\n    for text, label in [\\\n        (\"Hey Jason! You're awesome\", \"NOT_SPAM\"),\\\n        (\"I am a nigerian prince and I need your help.\", \"SPAM\"),\\\n    ]:\n        prediction = classify(text)\n        assert prediction.label == label\n        print(f\"Text: {text}, Predicted Label: {prediction.label}\")\n        #> Text: Hey Jason! You're awesome, Predicted Label: NOT_SPAM\n        #> Text: I am a nigerian prince and I need your help., Predicted Label: SPAM\n\n```\n\n## Multi-Label Classification [¶](https://python.useinstructor.com/examples/classification/\\#multi-label-classification \"Permanent link\")\n\n### Defining the Structures [¶](https://python.useinstructor.com/examples/classification/\\#defining-the-structures_1 \"Permanent link\")\n\nFor multi-label classification, we'll update our approach to use Literals instead of enums, and include few-shot examples in the model's docstring.\n\n```md-code__content\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass MultiClassPrediction(BaseModel):\n    \"\"\"\n    Class for a multi-class label prediction.\n\n    Examples:\n    - \"My account is locked\": [\"TECH_ISSUE\"]\n    - \"I can't access my billing info\": [\"TECH_ISSUE\", \"BILLING\"]\n    - \"When do you close for holidays?\": [\"GENERAL_QUERY\"]\n    - \"My payment didn't go through and now I can't log in\": [\"BILLING\", \"TECH_ISSUE\"]\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        ...,\n        description=\"The chain of thought that led to the prediction.\",\n    )\n\n    class_labels: List[Literal[\"TECH_ISSUE\", \"BILLING\", \"GENERAL_QUERY\"]] = Field(\n        ...,\n        description=\"The predicted class labels for the support ticket.\",\n    )\n\n```\n\n### Classifying Text [¶](https://python.useinstructor.com/examples/classification/\\#classifying-text_1 \"Permanent link\")\n\nThe function **`multi_classify`** is responsible for multi-label classification.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\ndef multi_classify(data: str) -> MultiClassPrediction:\n    \"\"\"Perform multi-label classification on the input text.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=MultiClassPrediction,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Classify the following support ticket: <ticket>{data}</ticket>\",\\\n            },\\\n        ],\n    )\n\n```\n\n### Testing and Evaluation [¶](https://python.useinstructor.com/examples/classification/\\#testing-and-evaluation_1 \"Permanent link\")\n\nFinally, we test the multi-label classification function using a sample support ticket.\n\n```md-code__content\n# Test multi-label classification\nticket = \"My account is locked and I can't access my billing info.\"\nprediction = multi_classify(ticket)\nassert \"TECH_ISSUE\" in prediction.class_labels\nassert \"BILLING\" in prediction.class_labels\nprint(f\"Ticket: {ticket}\")\n#> Ticket: My account is locked and I can't access my billing info.\nprint(f\"Predicted Labels: {prediction.class_labels}\")\n#> Predicted Labels: ['TECH_ISSUE', 'BILLING']\n\n```\n\nBy using Literals and including few-shot examples, we've improved both the single-label and multi-label classification implementations. These changes enhance type safety and provide better guidance for the AI model, potentially leading to more accurate classifications.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/classification/",
      "ogUrl": "https://python.useinstructor.com/examples/classification/",
      "title": "Text Classification with OpenAI and Pydantic - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/classification/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/classification.png",
      "ogTitle": "Text Classification with OpenAI and Pydantic - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/classification.png",
      "og:title": "Text Classification with OpenAI and Pydantic - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/classification/",
      "statusCode": 200,
      "description": "Learn to implement single-label and multi-label text classification using OpenAI API and Pydantic models in Python.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to implement single-label and multi-label text classification using OpenAI API and Pydantic models in Python.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/classification.png",
      "twitter:title": "Text Classification with OpenAI and Pydantic - Instructor",
      "og:description": "Learn to implement single-label and multi-label text classification using OpenAI API and Pydantic models in Python.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to implement single-label and multi-label text classification using OpenAI API and Pydantic models in Python."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/entity_resolution/#entity-resolution-and-visualization-for-legal-documents)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/entity_resolution.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/entity_resolution.md \"View source of this page\")\n\n# Entity Resolution and Visualization for Legal Documents [¶](https://python.useinstructor.com/examples/entity_resolution/\\#entity-resolution-and-visualization-for-legal-documents \"Permanent link\")\n\nIn this guide, we demonstrate how to extract and resolve entities from a sample legal contract. Then, we visualize these entities and their dependencies as an entity graph. This approach can be invaluable for legal tech applications, aiding in the understanding of complex documents.\n\nMotivation\n\nLegal contracts are full of intricate details and interconnected clauses. Automatically extracting and visualizing these elements can make it easier to understand the document's overall structure and terms.\n\n## Defining the Data Structures [¶](https://python.useinstructor.com/examples/entity_resolution/\\#defining-the-data-structures \"Permanent link\")\n\nThe **`Entity`** and **`Property`** classes model extracted entities and their attributes. **`DocumentExtraction`** encapsulates a list of these entities.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass Property(BaseModel):\n    key: str\n    value: str\n    resolved_absolute_value: str\n\nclass Entity(BaseModel):\n    id: int = Field(\n        ...,\n        description=\"Unique identifier for the entity, used for deduplication, design a scheme allows multiple entities\",\n    )\n    subquote_string: List[str] = Field(\n        ...,\n        description=\"Correctly resolved value of the entity, if the entity is a reference to another entity, this should be the id of the referenced entity, include a few more words before and after the value to allow for some context to be used in the resolution\",\n    )\n    entity_title: str\n    properties: List[Property] = Field(\n        ..., description=\"List of properties of the entity\"\n    )\n    dependencies: List[int] = Field(\n        ...,\n        description=\"List of entity ids that this entity depends  or relies on to resolve it\",\n    )\n\nclass DocumentExtraction(BaseModel):\n    entities: List[Entity] = Field(\n        ...,\n        description=\"Body of the answer, each fact should be a separate object with a body and a list of sources\",\n    )\n\n```\n\n## Entity Extraction and Resolution [¶](https://python.useinstructor.com/examples/entity_resolution/\\#entity-extraction-and-resolution \"Permanent link\")\n\nThe **`ask_ai`** function utilizes OpenAI's API to extract and resolve entities from the input content.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\ndef ask_ai(content) -> DocumentExtraction:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        response_model=DocumentExtraction,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"Extract and resolve a list of entities from the following document:\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": content,\\\n            },\\\n        ],\n    )  # type: ignore\n\n```\n\n## Graph Visualization [¶](https://python.useinstructor.com/examples/entity_resolution/\\#graph-visualization \"Permanent link\")\n\n**`generate_graph`** takes the extracted entities and visualizes them using Graphviz. It creates nodes for each entity and edges for their dependencies.\n\n```md-code__content\nfrom graphviz import Digraph\n\ndef generate_html_label(entity: Entity) -> str:\n    rows = [\\\n        f\"<tr><td>{prop.key}</td><td>{prop.resolved_absolute_value}</td></tr>\"\\\n        for prop in entity.properties\\\n    ]\n    table_rows = \"\".join(rows)\n    return f\"<<table border='0' cellborder='1' cellspacing='0'><tr><td colspan='2'><b>{entity.entity_title}</b></td></tr>{table_rows}</table>>\"\n\ndef generate_graph(data: DocumentExtraction):\n    dot = Digraph(comment=\"Entity Graph\", node_attr={\"shape\": \"plaintext\"})\n\n    for entity in data.entities:\n        label = generate_html_label(entity)\n        dot.node(str(entity.id), label)\n\n    for entity in data.entities:\n        for dep_id in entity.dependencies:\n            dot.edge(str(entity.id), str(dep_id))\n\n    dot.render(\"entity.gv\", view=True)\n\n```\n\n## Execution [¶](https://python.useinstructor.com/examples/entity_resolution/\\#execution \"Permanent link\")\n\nFinally, execute the code to visualize the entity graph for the sample legal contract.\n\n```md-code__content\ncontent = \"\"\"\nSample Legal Contract\nAgreement Contract\n\nThis Agreement is made and entered into on 2020-01-01 by and between Company A (\"the Client\") and Company B (\"the Service Provider\").\n\nArticle 1: Scope of Work\n\nThe Service Provider will deliver the software product to the Client 30 days after the agreement date.\n\nArticle 2: Payment Terms\n\nThe total payment for the service is $50,000.\nAn initial payment of $10,000 will be made within 7 days of the the signed date.\nThe final payment will be due 45 days after [SignDate].\n\nArticle 3: Confidentiality\n\nThe parties agree not to disclose any confidential information received from the other party for 3 months after the final payment date.\n\nArticle 4: Termination\n\nThe contract can be terminated with a 30-day notice, unless there are outstanding obligations that must be fulfilled after the [DeliveryDate].\n\"\"\"  # Your legal contract here\nmodel = ask_ai(content)\ngenerate_graph(model)\n\n```\n\nThis will produce a graphical representation of the entities and their dependencies, stored as \"entity.gv\".\n\n![Entity Graph](https://python.useinstructor.com/examples/entity_resolution.png)\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/entity_resolution/",
      "ogUrl": "https://python.useinstructor.com/examples/entity_resolution/",
      "title": "Entity Resolution and Visualization for Legal Documents - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/entity_resolution/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/entity_resolution.png",
      "ogTitle": "Entity Resolution and Visualization for Legal Documents - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/entity_resolution.png",
      "og:title": "Entity Resolution and Visualization for Legal Documents - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/entity_resolution/",
      "statusCode": 200,
      "description": "Learn how to extract, resolve, and visualize entities from legal contracts for better understanding and analysis.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to extract, resolve, and visualize entities from legal contracts for better understanding and analysis.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/entity_resolution.png",
      "twitter:title": "Entity Resolution and Visualization for Legal Documents - Instructor",
      "og:description": "Learn how to extract, resolve, and visualize entities from legal contracts for better understanding and analysis.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to extract, resolve, and visualize entities from legal contracts for better understanding and analysis."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/ollama/#structured-outputs-with-ollama)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/ollama.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/ollama.md \"View source of this page\")\n\n# Structured Outputs with Ollama [¶](https://python.useinstructor.com/examples/ollama/\\#structured-outputs-with-ollama \"Permanent link\")\n\nOpen-source Large Language Models (LLMs) are rapidly gaining popularity in the AI community. With the recent release of Ollama's OpenAI compatibility layer, it has become possible to obtain structured outputs using JSON schema from these open-source models. This development opens up exciting possibilities for developers and researchers alike.\n\nIn this blog post, we'll explore how to effectively utilize the Instructor library with Ollama to harness the power of structured outputs with [Pydantic models](https://python.useinstructor.com/concepts/models/). We'll cover everything from setup to implementation, providing you with practical insights and code examples.\n\n## Why use Instructor? [¶](https://python.useinstructor.com/examples/ollama/\\#why-use-instructor \"Permanent link\")\n\nInstructor offers several key benefits:\n\n- **Simple API with Full Prompt Control**: Instructor provides a straightforward API that gives you complete ownership and control over your prompts. This allows for fine-tuned customization and optimization of your LLM interactions. [Explore Concepts](https://python.useinstructor.com/concepts/models/)\n\n- **Reasking and Validation**: Automatically reask the model when validation fails, ensuring high-quality outputs. Leverage Pydantic's validation for robust error handling. [Learn about Reasking](https://python.useinstructor.com/concepts/reask_validation/)\n\n- **Streaming Support**: Stream partial results and iterables with ease, allowing for real-time processing and improved responsiveness in your applications. [Learn about Streaming](https://python.useinstructor.com/concepts/partial/)\n\n- **Powered by Type Hints**: Leverage Pydantic for schema validation, prompting control, less code, and IDE integration. [Learn more](https://docs.pydantic.dev/)\n\n- **Simplified LLM Interactions**: Support for various LLM providers including OpenAI, Anthropic, Google, Vertex AI, Mistral/Mixtral, Anyscale, Ollama, llama-cpp-python, Cohere, and LiteLLM. [See Examples](https://python.useinstructor.com/examples/)\n\n\nFor more details on these features, check out the [Concepts](https://python.useinstructor.com/concepts/models/) section of the documentation.\n\n## Patching [¶](https://python.useinstructor.com/examples/ollama/\\#patching \"Permanent link\")\n\nInstructor's [patch](https://python.useinstructor.com/concepts/patching/) enhances an openai api with the following features:\n\n- `response_model` in `create` calls that returns a pydantic model\n- `max_retries` in `create` calls that retries the call if it fails by using a backoff strategy\n\nLearn More\n\nTo learn more, please refer to the [docs](https://python.useinstructor.com/). To understand the benefits of using Pydantic with Instructor, visit the tips and tricks section of the [why use Pydantic](https://python.useinstructor.com/why/) page.\n\n## Ollama [¶](https://python.useinstructor.com/examples/ollama/\\#ollama \"Permanent link\")\n\nStart by downloading [Ollama](https://ollama.ai/download), and then pull a model such as Llama 3 or Mistral.\n\nMake sure you update your `ollama` to the latest version!\n\n```md-code__content\nollama pull llama3\n\n```\n\n```md-code__content\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nimport instructor\n\nclass Character(BaseModel):\n    name: str\n    age: int\n    fact: List[str] = Field(..., description=\"A list of facts about the character\")\n\n# enables `response_model` in create call\nclient = instructor.from_openai(\n    OpenAI(\n        base_url=\"http://localhost:11434/v1\",\n        api_key=\"ollama\",  # required, but unused\n    ),\n    mode=instructor.Mode.JSON,\n)\n\nresp = client.chat.completions.create(\n    model=\"llama3\",\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": \"Tell me about the Harry Potter\",\\\n        }\\\n    ],\n    response_model=Character,\n)\nprint(resp.model_dump_json(indent=2))\n\"\"\"\n{\n  \"name\": \"Harry James Potter\",\n  \"age\": 37,\n  \"fact\": [\\\n    \"He is the chosen one.\",\\\n    \"He has a lightning-shaped scar on his forehead.\",\\\n    \"He is the son of James and Lily Potter.\",\\\n    \"He attended Hogwarts School of Witchcraft and Wizardry.\",\\\n    \"He is a skilled wizard and sorcerer.\",\\\n    \"He fought against Lord Voldemort and his followers.\",\\\n    \"He has a pet owl named Snowy.\"\\\n  ]\n}\n\"\"\"\n\n```\n\nThis example demonstrates how to use Instructor with Ollama, a local LLM server, to generate structured outputs. By leveraging Instructor's capabilities, we can easily extract structured information from the LLM's responses, making it simpler to work with the generated data in our applications.\n\n## Further Reading [¶](https://python.useinstructor.com/examples/ollama/\\#further-reading \"Permanent link\")\n\nTo explore more about Instructor and its various applications, consider checking out the following resources:\n\n1. [Why use Instructor?](https://python.useinstructor.com/why/) \\- Learn about the benefits and use cases of Instructor.\n\n2. [Concepts](https://python.useinstructor.com/concepts/models/) \\- Dive deeper into the core concepts of Instructor, including models, retrying, and validation.\n\n3. [Examples](https://python.useinstructor.com/examples/) \\- Explore our comprehensive collection of examples and integrations with various LLM providers.\n\n4. [Tutorials](https://python.useinstructor.com/tutorials/1-introduction/) \\- Step-by-step tutorials to help you get started with Instructor.\n\n5. [Learn Prompting](https://python.useinstructor.com/prompting/) \\- Techniques and strategies for effective prompt engineering with Instructor.\n\n\nBy exploring these resources, you'll gain a comprehensive understanding of Instructor's capabilities and how to leverage them in your projects.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/ollama/",
      "ogUrl": "https://python.useinstructor.com/examples/ollama/",
      "title": "Harnessing Structured Outputs with Ollama and Instructor - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/ollama/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/ollama.png",
      "ogTitle": "Harnessing Structured Outputs with Ollama and Instructor - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/ollama.png",
      "og:title": "Harnessing Structured Outputs with Ollama and Instructor - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/ollama/",
      "statusCode": 200,
      "description": "Discover how to utilize Ollama's Instructor library for structured outputs in LLM applications using Pydantic models.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Discover how to utilize Ollama's Instructor library for structured outputs in LLM applications using Pydantic models.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/ollama.png",
      "twitter:title": "Harnessing Structured Outputs with Ollama and Instructor - Instructor",
      "og:description": "Discover how to utilize Ollama's Instructor library for structured outputs in LLM applications using Pydantic models.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Discover how to utilize Ollama's Instructor library for structured outputs in LLM applications using Pydantic models."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/youtube_clips/#generating-youtube-clips-from-transcripts)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/youtube_clips.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/youtube_clips.md \"View source of this page\")\n\n# Generating YouTube Clips from Transcripts [¶](https://python.useinstructor.com/examples/youtube_clips/\\#generating-youtube-clips-from-transcripts \"Permanent link\")\n\nThis guide demonstrates how to generate concise, informative clips from YouTube video transcripts using the `instructor` library. By leveraging the power of OpenAI's models, we can extract meaningful segments from a video's transcript, which can then be recut into smaller, standalone videos. This process involves identifying key moments within a transcript and summarizing them into clips with specific titles and descriptions.\n\nFirst, install the necessary packages:\n\n```md-code__content\npip install youtube_transcript_api instructor rich\n\n```\n\n![youtube clip streaming](https://python.useinstructor.com/img/youtube.gif)\n\n```md-code__content\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom pydantic import BaseModel, Field\nfrom typing import List, Generator, Iterable\nimport instructor\nimport openai\n\nclient = instructor.from_openai(openai.OpenAI())\n\ndef extract_video_id(url: str) -> str | None:\n    import re\n\n    match = re.search(r\"v=([a-zA-Z0-9_-]+)\", url)\n    if match:\n        return match.group(1)\n\nclass TranscriptSegment(BaseModel):\n    source_id: int\n    start: float\n    text: str\n\ndef get_transcript_with_timing(\n    video_id: str,\n) -> Generator[TranscriptSegment, None, None]:\n    \"\"\"\n    Fetches the transcript of a YouTube video along with the start and end times\n    for each text segment, and returns them as a list of Pydantic models.\n    \"\"\"\n    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n    for ii, segment in enumerate(transcript):\n        yield TranscriptSegment(\n            source_id=ii, start=segment[\"start\"], text=segment[\"text\"]\n        )\n\nclass YoutubeClip(BaseModel):\n    title: str = Field(description=\"Specific and informative title for the clip.\")\n    description: str = Field(\n        description=\"A detailed description of the clip, including notable quotes or phrases.\"\n    )\n    start: float\n    end: float\n\nclass YoutubeClips(BaseModel):\n    clips: List[YoutubeClip]\n\ndef yield_clips(segments: Iterable[TranscriptSegment]) -> Iterable[YoutubeClips]:\n    return client.chat.completions.create(\n        model=\"gpt-4-turbo-preview\",\n        stream=True,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"\"\"You are given a sequence of YouTube transcripts and your job\\\n                is to return notable clips that can be recut as smaller videos. Give very\\\n                specific titles and descriptions. Make sure the length of clips is proportional\\\n                to the length of the video. Note that this is a transcript and so there might\\\n                be spelling errors. Note that and correct any spellings. Use the context to\\\n                make sure you're spelling things correctly.\"\"\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Let's use the following transcript segments.\\n{segments}\",\\\n            },\\\n        ],\n        response_model=instructor.Partial[YoutubeClips],\n        validation_context={\"segments\": segments},\n    )  # type: ignore\n\n# Example usage\nif __name__ == \"__main__\":\n    from rich.table import Table\n    from rich.console import Console\n    from rich.prompt import Prompt\n\n    console = Console()\n    url = Prompt.ask(\"Enter a YouTube URL\")\n\n    with console.status(\"[bold green]Processing YouTube URL...\") as status:\n        video_id = extract_video_id(url)\n\n        if video_id is None:\n            raise ValueError(\"Invalid YouTube video URL\")\n\n        transcript = list(get_transcript_with_timing(video_id))\n        status.update(\"[bold green]Generating clips...\")\n\n        for clip in yield_clips(transcript):\n            console.clear()\n\n            table = Table(title=\"Extracted YouTube Clips\", padding=(0, 1))\n\n            table.add_column(\"Title\", style=\"cyan\")\n            table.add_column(\"Description\", style=\"magenta\")\n            table.add_column(\"Start\", justify=\"right\", style=\"green\")\n            table.add_column(\"End\", justify=\"right\", style=\"green\")\n            for youtube_clip in clip.clips or []:\n                table.add_row(\n                    youtube_clip.title,\n                    youtube_clip.description,\n                    str(youtube_clip.start),\n                    str(youtube_clip.end),\n                )\n            console.print(table)\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/youtube_clips/",
      "ogUrl": "https://python.useinstructor.com/examples/youtube_clips/",
      "title": "Generating YouTube Clips from Transcripts Using Instructor - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/youtube_clips/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/youtube_clips.png",
      "ogTitle": "Generating YouTube Clips from Transcripts Using Instructor - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/youtube_clips.png",
      "og:title": "Generating YouTube Clips from Transcripts Using Instructor - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/youtube_clips/",
      "statusCode": 200,
      "description": "Learn to create concise YouTube clips from video transcripts with `instructor` and OpenAI, enhancing your content engagement.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to create concise YouTube clips from video transcripts with `instructor` and OpenAI, enhancing your content engagement.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/youtube_clips.png",
      "twitter:title": "Generating YouTube Clips from Transcripts Using Instructor - Instructor",
      "og:description": "Learn to create concise YouTube clips from video transcripts with `instructor` and OpenAI, enhancing your content engagement.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to create concise YouTube clips from video transcripts with `instructor` and OpenAI, enhancing your content engagement."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/knowledge_graph/#visualizing-knowledge-graphs-for-complex-topics)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/knowledge_graph.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/knowledge_graph.md \"View source of this page\")\n\n* * *\n\ntitle: Visualizing Knowledge Graphs: A Guide to Complex Topics description: Learn how to create and update knowledge graphs using Python, OpenAI's API, Pydantic, and Graphviz for enhanced understanding of complex subjects.\n\n* * *\n\n# Visualizing Knowledge Graphs for Complex Topics [¶](https://python.useinstructor.com/examples/knowledge_graph/\\#visualizing-knowledge-graphs-for-complex-topics \"Permanent link\")\n\nIn this guide, you'll discover how to visualise a detailed knowledge graph when dealing with complex topics. We'll then move on to iteratively updating our knowledge graph with new information through a series of sequential api calls using only the Instructor library, Pydantic and Graphviz to visualise our graph.\n\nMotivation\n\nKnowledge graphs offer a visually appealing and coherent way to understand complicated topics like quantum mechanics. By generating these graphs automatically, you can accelerate the learning process and make it easier to digest complex information.\n\n## Defining the Structures [¶](https://python.useinstructor.com/examples/knowledge_graph/\\#defining-the-structures \"Permanent link\")\n\nLet's model a knowledge graph with **`Node`** and **`Edge`** objects. **`Node`** objects represent key concepts or entities, while **`Edge`** objects indicate the relationships between them.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass Node(BaseModel, frozen=True):\n    id: int\n    label: str\n    color: str\n\nclass Edge(BaseModel, frozen=True):\n    source: int\n    target: int\n    label: str\n    color: str = \"black\"\n\nclass KnowledgeGraph(BaseModel):\n    nodes: List[Node] = Field(..., default_factory=list)\n    edges: List[Edge] = Field(..., default_factory=list)\n\n```\n\n## Generating Knowledge Graphs [¶](https://python.useinstructor.com/examples/knowledge_graph/\\#generating-knowledge-graphs \"Permanent link\")\n\nThe **`generate_graph`** function leverages OpenAI's API to generate a knowledge graph based on the input query.\n\n```md-code__content\nfrom openai import OpenAI\nimport instructor\n\n# Adds response_model to ChatCompletion\n# Allows the return of Pydantic model rather than raw JSON\nclient = instructor.from_openai(OpenAI())\n\ndef generate_graph(input) -> KnowledgeGraph:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Help me understand the following by describing it as a detailed knowledge graph: {input}\",\\\n            }\\\n        ],\n        response_model=KnowledgeGraph,\n    )  # type: ignore\n\n```\n\n## Visualizing the Graph [¶](https://python.useinstructor.com/examples/knowledge_graph/\\#visualizing-the-graph \"Permanent link\")\n\nThe **`visualize_knowledge_graph`** function uses the Graphviz library to render the generated knowledge graph.\n\n```md-code__content\nfrom graphviz import Digraph\n\ndef visualize_knowledge_graph(kg: KnowledgeGraph):\n    dot = Digraph(comment=\"Knowledge Graph\")\n\n    # Add nodes\n    for node in kg.nodes:\n        dot.node(str(node.id), node.label, color=node.color)\n\n    # Add edges\n    for edge in kg.edges:\n        dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n\n    # Render the graph\n    dot.render(\"knowledge_graph.gv\", view=True)\n\ngraph = generate_graph(\"Teach me about quantum mechanics\")\nvisualize_knowledge_graph(graph)\n\n```\n\n![Knowledge Graph](https://python.useinstructor.com/examples/knowledge_graph.png)\n\nThis will produce a visual representation of the knowledge graph, stored as \"knowledge\\_graph.gv\". You can open this file to explore the key concepts and their relationships in quantum mechanics.\n\n## Iterative Updates [¶](https://python.useinstructor.com/examples/knowledge_graph/\\#iterative-updates \"Permanent link\")\n\nNow that we've seen how to generate a knowledge graph from a single input, let's see how we can iteratively update our knowledge graph with new information, or when information does not fit into a single prompt.\n\nLet's take an easy example where we want to visualise the combined knowledge graph that the following sentences represent.\n\n```md-code__content\ntext_chunks = [\\\n    \"Jason knows a lot about quantum mechanics. He is a physicist. He is a professor\",\\\n    \"Professors are smart.\",\\\n    \"Sarah knows Jason and is a student of his.\",\\\n    \"Sarah is a student at the University of Toronto. and UofT is in Canada\",\\\n]\n\n```\n\n### Updating Our Data Model [¶](https://python.useinstructor.com/examples/knowledge_graph/\\#updating-our-data-model \"Permanent link\")\n\nTo support our new iterative approach, we need to update our data model. We can do this by adding helper methods `update` and `draw` to our Pydantic models. These methods will simplify our code and allow us to easily visualize the knowledge graph.\n\nIn the `KnowledgeGraph` class, we have migrated the code from the `visualize_knowledge_graph` method and added new lists for nodes and edges.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Node(BaseModel, frozen=True):\n    id: int\n    label: str\n    color: str\n\nclass Edge(BaseModel, frozen=True):\n    source: int\n    target: int\n    label: str\n    color: str = \"black\"\n\nclass KnowledgeGraph(BaseModel):\n    nodes: Optional[List[Node]] = Field(..., default_factory=list)\n    edges: Optional[List[Edge]] = Field(..., default_factory=list)\n\n    def update(self, other: \"KnowledgeGraph\") -> \"KnowledgeGraph\":\n        \"\"\"Updates the current graph with the other graph, deduplicating nodes and edges.\"\"\"\n        return KnowledgeGraph(\n            nodes=list(set(self.nodes + other.nodes)),\n            edges=list(set(self.edges + other.edges)),\n        )\n\n    def draw(self, prefix: str = None):\n        dot = Digraph(comment=\"Knowledge Graph\")\n\n        for node in self.nodes:\n            dot.node(str(node.id), node.label, color=node.color)\n\n        for edge in self.edges:\n            dot.edge(\n                str(edge.source), str(edge.target), label=edge.label, color=edge.color\n            )\n        dot.render(prefix, format=\"png\", view=True)\n\n```\n\nWe can modify our `generate_graph` function to now take in a list of strings. At each step, it'll extract out the key insights from the sentences in the form of edges and nodes like we've seen before. We can then combine these new edges and nodes with our existing knowledge graph through iterative updates to our graph before arriving at our final result.\n\n```md-code__content\nfrom typing import List\n\ndef generate_graph(input: List[str]) -> KnowledgeGraph:\n    cur_state = KnowledgeGraph()\n    num_iterations = len(input)\n    for i, inp in enumerate(input):\n        new_updates = client.chat.completions.create(\n            model=\"gpt-3.5-turbo-16k\",\n            messages=[\\\n                {\\\n                    \"role\": \"system\",\\\n                    \"content\": \"\"\"You are an iterative knowledge graph builder.\\\n                    You are given the current state of the graph, and you must append the nodes and edges\\\n                    to it Do not procide any duplcates and try to reuse nodes as much as possible.\"\"\",\\\n                },\\\n                {\\\n                    \"role\": \"user\",\\\n                    \"content\": f\"\"\"Extract any new nodes and edges from the following:\\\n                    # Part {i}/{num_iterations} of the input:\\\n\\\n                    {inp}\"\"\",\\\n                },\\\n                {\\\n                    \"role\": \"user\",\\\n                    \"content\": f\"\"\"Here is the current state of the graph:\\\n                    {cur_state.model_dump_json(indent=2)}\"\"\",\\\n                },\\\n            ],\n            response_model=KnowledgeGraph,\n        )  # type: ignore\n\n        # Update the current state\n        cur_state = cur_state.update(new_updates)\n        cur_state.draw(prefix=f\"iteration_{i}\")\n    return cur_state\n\n```\n\nOnce we've done this, we can now run this new `generate_graph` function with the following two lines.\n\n```md-code__content\ntext_chunks = [\\\n    \"Jason knows a lot about quantum mechanics. He is a physicist. He is a professor\",\\\n    \"Professors are smart.\",\\\n    \"Sarah knows Jason and is a student of his.\",\\\n    \"Sarah is a student at the University of Toronto. and UofT is in Canada\",\\\n]\ngraph: KnowledgeGraph = generate_graph(text_chunks)\ngraph.draw(prefix=\"final\")\n\n```\n\n## Conclusion [¶](https://python.useinstructor.com/examples/knowledge_graph/\\#conclusion \"Permanent link\")\n\nWe've seen how we can use `Instructor` to obtain structured outputs from the OpenAI LLM API but you could use that for any of the other open-source models that the library is compatible with. If you enjoy the content or want to try out `Instructor` check out the [github](https://github.com/jxnl/instructor) and don't forget to give us a star!\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/knowledge_graph/",
      "ogUrl": "https://python.useinstructor.com/examples/knowledge_graph/",
      "title": "Extracting Knowledge Graphs - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/knowledge_graph/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/knowledge_graph.png",
      "ogTitle": "Extracting Knowledge Graphs - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/knowledge_graph.png",
      "og:title": "Extracting Knowledge Graphs - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/knowledge_graph/",
      "statusCode": 200,
      "description": "A lightweight library for structured outputs with LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "A lightweight library for structured outputs with LLMs.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/knowledge_graph.png",
      "twitter:title": "Extracting Knowledge Graphs - Instructor",
      "og:description": "A lightweight library for structured outputs with LLMs.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "A lightweight library for structured outputs with LLMs."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/tables_from_vision/#extracting-tables-from-images-with-openais-gpt-4-vision-model)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/tables_from_vision.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/tables_from_vision.md \"View source of this page\")\n\n# Extracting Tables from Images with OpenAI's GPT-4 Vision Model [¶](https://python.useinstructor.com/examples/tables_from_vision/\\#extracting-tables-from-images-with-openais-gpt-4-vision-model \"Permanent link\")\n\nFirst, we define a custom type, `MarkdownDataFrame`, to handle pandas DataFrames formatted in markdown. This type uses Python's `Annotated` and `InstanceOf` types, along with decorators `BeforeValidator` and `PlainSerializer`, to process and serialize the data.\n\n## Defining the Table Class [¶](https://python.useinstructor.com/examples/tables_from_vision/\\#defining-the-table-class \"Permanent link\")\n\nThe `Table` class is essential for organizing the extracted data. It includes a caption and a dataframe, processed as a markdown table. Since most of the complexity is handled by the `MarkdownDataFrame` type, the `Table` class is straightforward!\n\nThis requires additional dependencies `pip install pandas tabulate`.\n\n```md-code__content\nfrom openai import OpenAI\nfrom io import StringIO\nfrom typing import Annotated, Any, List\nfrom pydantic import (\n    BaseModel,\n    BeforeValidator,\n    PlainSerializer,\n    InstanceOf,\n    WithJsonSchema,\n)\nimport instructor\nimport pandas as pd\nfrom rich.console import Console\n\nconsole = Console()\nclient = instructor.from_openai(\n    client=OpenAI(),\n    mode=instructor.Mode.TOOLS,\n)\n\ndef md_to_df(data: Any) -> Any:\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),  # Get rid of whitespaces\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .map(lambda x: x.strip())\n        )  # type: ignore\n    return data\n\nMarkdownDataFrame = Annotated[\\\n    InstanceOf[pd.DataFrame],\\\n    BeforeValidator(md_to_df),\\\n    PlainSerializer(lambda x: x.to_markdown()),\\\n    WithJsonSchema(\\\n        {\\\n            \"type\": \"string\",\\\n            \"description\": \"\"\"\\\n                The markdown representation of the table,\\\n                each one should be tidy, do not try to join tables\\\n                that should be seperate\"\"\",\\\n        }\\\n    ),\\\n]\n\nclass Table(BaseModel):\n    caption: str\n    dataframe: MarkdownDataFrame\n\nclass MultipleTables(BaseModel):\n    tables: List[Table]\n\nexample = MultipleTables(\n    tables=[\\\n        Table(\\\n            caption=\"This is a caption\",\\\n            dataframe=pd.DataFrame(\\\n                {\\\n                    \"Chart A\": [10, 40],\\\n                    \"Chart B\": [20, 50],\\\n                    \"Chart C\": [30, 60],\\\n                }\\\n            ),\\\n        )\\\n    ]\n)\n\ndef extract(url: str) -> MultipleTables:\n    return client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        max_tokens=4000,\n        response_model=MultipleTables,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": [\\\n                    {\\\n                        \"type\": \"image_url\",\\\n                        \"image_url\": {\"url\": url},\\\n                    },\\\n                    {\\\n                        \"type\": \"text\",\\\n                        \"text\": \"\"\"\\\n                            First, analyze the image to determine the most appropriate headers for the tables.\\\n                            Generate a descriptive h1 for the overall image, followed by a brief summary of the data it contains.\\\n                            For each identified table, create an informative h2 title and a concise description of its contents.\\\n                            Finally, output the markdown representation of each table.\\\n                            Make sure to escape the markdown table properly, and make sure to include the caption and the dataframe.\\\n                            including escaping all the newlines and quotes. Only return a markdown table in dataframe, nothing else.\\\n                        \"\"\",\\\n                    },\\\n                ],\\\n            }\\\n        ],\n    )\n\nurls = [\\\n    \"https://a.storyblok.com/f/47007/2400x1260/f816b031cb/uk-ireland-in-three-charts_chart_a.png/m/2880x0\",\\\n    \"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png/m/2880x0\",\\\n]\n\nfor url in urls:\n    for table in extract(url).tables:\n        console.print(table.caption, \"\\n\", table.dataframe)\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/tables_from_vision/",
      "ogUrl": "https://python.useinstructor.com/examples/tables_from_vision/",
      "title": "Extracting Tables from Images Using OpenAI GPT-4 - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/tables_from_vision/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/tables_from_vision.png",
      "ogTitle": "Extracting Tables from Images Using OpenAI GPT-4 - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/tables_from_vision.png",
      "og:title": "Extracting Tables from Images Using OpenAI GPT-4 - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/tables_from_vision/",
      "statusCode": 200,
      "description": "Learn how to convert images into markdown tables using OpenAI's GPT-4 Vision model for data extraction and analysis.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to convert images into markdown tables using OpenAI's GPT-4 Vision model for data extraction and analysis.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/tables_from_vision.png",
      "twitter:title": "Extracting Tables from Images Using OpenAI GPT-4 - Instructor",
      "og:description": "Learn how to convert images into markdown tables using OpenAI's GPT-4 Vision model for data extraction and analysis.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to convert images into markdown tables using OpenAI's GPT-4 Vision model for data extraction and analysis."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/image_to_ad_copy/#use-vision-api-to-detect-products-and-generate-advertising-copy)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/image_to_ad_copy.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/image_to_ad_copy.md \"View source of this page\")\n\n# Use Vision API to detect products and generate advertising copy [¶](https://python.useinstructor.com/examples/image_to_ad_copy/\\#use-vision-api-to-detect-products-and-generate-advertising-copy \"Permanent link\")\n\nThis post demonstrates how to use GPT-4 Vision API and the Chat API to automatically generate advertising copy from product images. This method can be useful for marketing and advertising teams, as well as for e-commerce platforms.\n\nThe full code is available on [GitHub](https://www.github.com/jxnl/instructor/tree/main/examples/vision/image_to_ad_copy.py).\n\n## Building the models [¶](https://python.useinstructor.com/examples/image_to_ad_copy/\\#building-the-models \"Permanent link\")\n\n### Product [¶](https://python.useinstructor.com/examples/image_to_ad_copy/\\#product \"Permanent link\")\n\nFor the `Product` model, we define a class that represents a product extracted from an image and store the name, key features, and description. The product attributes are dynamically determined based on the content of the image.\n\nNote that it is easy to add [Validators](https://jxnl.github.io/instructor/concepts/reask_validation/) and other Pydantic features to the model to ensure that the data is valid and consistent.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Product(BaseModel):\n    \"\"\"\n    Represents a product extracted from an image using AI.\n\n    The product attributes are dynamically determined based on the content\n    of the image and the AI's interpretation. This class serves as a structured\n    representation of the identified product characteristics.\n    \"\"\"\n\n    name: str = Field(\n        description=\"A generic name for the product.\", example=\"Headphones\"\n    )\n    key_features: Optional[List[str]] = Field(\n        description=\"A list of key features of the product that stand out.\",\n        default=None,\n    )\n\n    description: Optional[str] = Field(\n        description=\"A description of the product.\",\n        default=None,\n    )\n\n    # Can be customized and automatically generated\n    def generate_prompt(self):\n        prompt = f\"Product: {self.name}\\n\"\n        if self.description:\n            prompt += f\"Description: {self.description}\\n\"\n        if self.key_features:\n            prompt += f\"Key Features: {', '.join(self.key_features)}\\n\"\n        return prompt\n\n```\n\n### Identified Product [¶](https://python.useinstructor.com/examples/image_to_ad_copy/\\#identified-product \"Permanent link\")\n\nWe also define a class that represents a list of products identified in the images. We also add an error flag and message to indicate if there was an error in the processing of the image.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\nclass IdentifiedProduct(BaseModel):\n    \"\"\"\n    Represents a list of products identified in the images.\n    \"\"\"\n\n    products: Optional[List[Product]] = Field(\n        description=\"A list of products identified by the AI.\",\n        example=[\\\n            Product(\\\n                name=\"Headphones\",\\\n                description=\"Wireless headphones with noise cancellation.\",\\\n                key_features=[\"Wireless\", \"Noise Cancellation\"],\\\n            )\\\n        ],\n        default=None,\n    )\n\n    error: bool = Field(default=False)\n    message: Optional[str] = Field(default=None)\n\n```\n\n### Advertising Copy [¶](https://python.useinstructor.com/examples/image_to_ad_copy/\\#advertising-copy \"Permanent link\")\n\nFinally, the `AdCopy` models stores the output in a structured format with a headline and the text.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\n\nclass AdCopy(BaseModel):\n    \"\"\"\n    Represents a generated ad copy.\n    \"\"\"\n\n    headline: str = Field(\n        description=\"A short, catchy, and memorable headline for the given product. The headline should invoke curiosity and interest in the product.\",\n    )\n    ad_copy: str = Field(\n        description=\"A long-form advertisement copy for the given product. This will be used in campaigns to promote the product with a persuasive message and a call-to-action with the objective of driving sales.\",\n    )\n    name: str = Field(description=\"The name of the product being advertised.\")\n\n```\n\n## Calling the API [¶](https://python.useinstructor.com/examples/image_to_ad_copy/\\#calling-the-api \"Permanent link\")\n\n### Product Detection [¶](https://python.useinstructor.com/examples/image_to_ad_copy/\\#product-detection \"Permanent link\")\n\nThe `read_images` function uses OpenAI's vision model to process a list of image URLs and identify products in each of them. We utilize the `instructor` library to patch the OpenAI client for this purpose.\n\n```md-code__content\ndef read_images(image_urls: list[str]) -> IdentifiedProduct:\n    \"\"\"\n    Given a list of image URLs, identify the products in the images.\n    \"\"\"\n\n    logger.info(f\"Identifying products in images... {len(image_urls)} images\")\n\n    return client_image.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=IdentifiedProduct,\n        max_tokens=1024,  # can be changed\n        temperature=0,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": [\\\n                    {\\\n                        \"type\": \"text\",\\\n                        \"text\": \"Identify products using the given images and generate key features for each product.\",\\\n                    },\\\n                    *[\\\n                        {\"type\": \"image_url\", \"image_url\": {\"url\": url}}\\\n                        for url in image_urls\\\n                    ],\\\n                ],\\\n            }\\\n        ],\n    )\n\n```\n\nThis gives us a list of products identified in all the images.\n\n### Generate advertising copy [¶](https://python.useinstructor.com/examples/image_to_ad_copy/\\#generate-advertising-copy \"Permanent link\")\n\nThen, we can use the `generate_ad_copy` function to generate advertising copy for each of the products identified in the images.\n\nTwo clients are defined for the two different models. This is because the `gpt-4-vision-preview` model is not compatible with the `gpt-4-1106-preview` model in terms of their response format.\n\n```md-code__content\ndef generate_ad_copy(product: Product) -> AdCopy:\n    \"\"\"\n    Given a product, generate an ad copy for the product.\n    \"\"\"\n\n    logger.info(f\"Generating ad copy for product: {product.name}\")\n\n    return client_copy.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=AdCopy,\n        temperature=0.3,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are an expert marketing assistant for all products. Your task is to generate an advertisement copy for a product using the name, description, and key features.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": product.generate_prompt()},\\\n        ],\n    )\n\n```\n\n### Putting it all together [¶](https://python.useinstructor.com/examples/image_to_ad_copy/\\#putting-it-all-together \"Permanent link\")\n\nFinally, we can put it all together in a single function that takes a list of image URLs and generates advertising copy for the products identified in the images. Please refer to the [full code](https://www.github.com/jxnl/instructor/tree/main/examples/vision/image_to_ad_copy.py) for the complete implementation.\n\n## Input file [¶](https://python.useinstructor.com/examples/image_to_ad_copy/\\#input-file \"Permanent link\")\n\nThe input file is currently a list of image URLs, but this trivial to change to any required format.\n\n```md-code__content\nhttps://contents.mediadecathlon.com/p1279823/9a1c59ad97a4084a346c014740ae4d3ff860ea70b485ee65f34017ff5e9ae5f7/recreational-ice-skates-fit-50-black.jpg?format=auto\nhttps://contents.mediadecathlon.com/p1279822/a730505231dbd6747c14ee93e8f89e824d3fa2a5b885ec26de8d7feb5626638a/recreational-ice-skates-fit-50-black.jpg?format=auto\nhttps://contents.mediadecathlon.com/p2329893/1ed75517602a5e00245b89ab6a1c6be6d8968a5a227c932b10599f857f3ed4cd/mens-hiking-leather-boots-sh-100-x-warm.jpg?format=auto\nhttps://contents.mediadecathlon.com/p2047870/8712c55568dd9928c83b19c6a4067bf161811a469433dc89244f0ff96a50e3e9/men-s-winter-hiking-boots-sh-100-x-warm-grey.jpg?format=auto\n\n```\n\nExpand to see the output\n\n![](https://contents.mediadecathlon.com/p1279823/9a1c59ad97a4084a346c014740ae4d3ff860ea70b485ee65f34017ff5e9ae5f7/recreational-ice-skates-fit-50-black.jpg?format=auto)![](https://contents.mediadecathlon.com/p2329893/1ed75517602a5e00245b89ab6a1c6be6d8968a5a227c932b10599f857f3ed4cd/mens-hiking-leather-boots-sh-100-x-warm.jpg?format=auto)\n\n```md-code__content\n{\n    \"products\":\n    [\\\n        {\\\n            \"name\": \"Ice Skates\",\\\n            \"key_features\": [\\\n                \"Lace-up closure\",\\\n                \"Durable blade\",\\\n                \"Ankle support\"\\\n            ],\\\n            \"description\": \"A pair of ice skates with lace-up closure for secure fit, durable blade for ice skating, and reinforced ankle support.\"\\\n        },\\\n        {\\\n            \"name\": \"Hiking Boots\",\\\n            \"key_features\": [\\\n                \"High-top design\",\\\n                \"Rugged outsole\",\\\n                \"Water-resistant\"\\\n            ],\\\n            \"description\": \"Sturdy hiking boots featuring a high-top design for ankle support, rugged outsole for grip on uneven terrain, and water-resistant construction.\"\\\n        },\\\n        {\\\n            \"name\": \"Winter Boots\",\\\n            \"key_features\": [\\\n                \"Insulated lining\",\\\n                \"Waterproof lower\",\\\n                \"Slip-resistant sole\"\\\n            ],\\\n            \"description\": \"Warm winter boots with insulated lining for cold weather, waterproof lower section to keep feet dry, and a slip-resistant sole for stability.\"\\\n        }\\\n    ],\n    \"ad_copies\": [\\\n        {\\\n            \"headline\": \"Glide with Confidence - Discover the Perfect Ice Skates!\",\\\n            \"ad_copy\": \"Step onto the ice with poise and precision with our premium Ice Skates. Designed for both beginners and seasoned skaters, these skates offer a perfect blend of comfort and performance. The lace-up closure ensures a snug fit that keeps you stable as you carve through the ice. With a durable blade that withstands the test of time, you can focus on perfecting your moves rather than worrying about your equipment. The reinforced ankle support provides the necessary protection and aids in preventing injuries, allowing you to skate with peace of mind. Whether you're practicing your spins, jumps, or simply enjoying a leisurely glide across the rink, our Ice Skates are the ideal companion for your ice adventures. Lace up and get ready to experience the thrill of ice skating like never before!\",\\\n            \"name\": \"Ice Skates\"\\\n        },\\\n        {\\\n            \"headline\": \"Conquer Every Trail with Confidence!\",\\\n            \"ad_copy\": \"Embark on your next adventure with our top-of-the-line Hiking Boots! Designed for the trail-blazing spirits, these boots boast a high-top design that provides unparalleled ankle support to keep you steady on any path. The rugged outsole ensures a firm grip on the most uneven terrains, while the water-resistant construction keeps your feet dry as you traverse through streams and muddy trails. Whether you're a seasoned hiker or just starting out, our Hiking Boots are the perfect companion for your outdoor escapades. Lace up and step into the wild with confidence - your journey awaits!\",\\\n            \"name\": \"Hiking Boots\"\\\n        },\\\n        {\\\n            \"headline\": \"Conquer the Cold with Comfort!\",\\\n            \"ad_copy\": \"Step into the season with confidence in our Winter Boots, the ultimate ally against the chill. Designed for those who don't let the cold dictate their moves, these boots feature an insulated lining that wraps your feet in a warm embrace, ensuring that the biting cold is a worry of the past. But warmth isn't their only virtue. With a waterproof lower section, your feet will remain dry and cozy, come rain, snow, or slush. And let's not forget the slip-resistant sole that stands between you and the treacherous ice, offering stability and peace of mind with every step you take. Whether you're braving a blizzard or just nipping out for a coffee, our Winter Boots are your trusty companions, keeping you warm, dry, and upright. Don't let winter slow you down. Lace up and embrace the elements!\",\\\n            \"name\": \"Winter Boots\"\\\n        }\\\n    ]\n}\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/image_to_ad_copy/",
      "ogUrl": "https://python.useinstructor.com/examples/image_to_ad_copy/",
      "title": "Automatically Generate Advertising Copy from Product Images Using GPT-4 Vision - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/image_to_ad_copy/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/image_to_ad_copy.png",
      "ogTitle": "Automatically Generate Advertising Copy from Product Images Using GPT-4 Vision - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/image_to_ad_copy.png",
      "og:title": "Automatically Generate Advertising Copy from Product Images Using GPT-4 Vision - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/image_to_ad_copy/",
      "statusCode": 200,
      "description": "Learn how to use GPT-4 Vision API to create engaging advertising copy from product images, ideal for e-commerce and marketing teams.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use GPT-4 Vision API to create engaging advertising copy from product images, ideal for e-commerce and marketing teams.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/image_to_ad_copy.png",
      "twitter:title": "Automatically Generate Advertising Copy from Product Images Using GPT-4 Vision - Instructor",
      "og:description": "Learn how to use GPT-4 Vision API to create engaging advertising copy from product images, ideal for e-commerce and marketing teams.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use GPT-4 Vision API to create engaging advertising copy from product images, ideal for e-commerce and marketing teams."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/building_knowledge_graphs/#building-knowledge-graphs-from-textual-data)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/building_knowledge_graphs.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/building_knowledge_graphs.md \"View source of this page\")\n\n# Building Knowledge Graphs from Textual Data [¶](https://python.useinstructor.com/examples/building_knowledge_graphs/\\#building-knowledge-graphs-from-textual-data \"Permanent link\")\n\nIn this tutorial, we will explore the process of constructing knowledge graphs from textual data using OpenAI's API and Pydantic. This approach is crucial for efficiently automating the extraction of structured information from unstructured text.\n\n```md-code__content\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom openai import OpenAI\nimport instructor\n\nclass Node(BaseModel):\n    id: int\n    label: str\n    color: str = \"blue\"  # Default color set to blue\n\nclass Edge(BaseModel):\n    source: int\n    target: int\n    label: str\n    color: str = \"black\"  # Default color for edges\n\nclass KnowledgeGraph(BaseModel):\n    nodes: List[Node] = Field(default_factory=list)\n    edges: List[Edge] = Field(default_factory=list)\n\n# Patch the OpenAI client to add response_model support\nclient = instructor.from_openai(OpenAI())\n\ndef generate_graph(input_text: str) -> KnowledgeGraph:\n    \"\"\"Generates a knowledge graph from the input text.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Help me understand the following by describing it as a detailed knowledge graph: {input_text}\",\\\n            }\\\n        ],\n        response_model=KnowledgeGraph,\n    )\n\nif __name__ == \"__main__\":\n    input_text = \"Jason is Sarah's friend and he is a doctor\"\n    graph = generate_graph(input_text)\n    print(graph.model_dump_json(indent=2))\n    \"\"\"\n    {\n      \"nodes\": [\\\n        {\\\n          \"id\": 1,\\\n          \"label\": \"Jason\",\\\n          \"color\": \"blue\"\\\n        },\\\n        {\\\n          \"id\": 2,\\\n          \"label\": \"Sarah\",\\\n          \"color\": \"blue\"\\\n        },\\\n        {\\\n          \"id\": 3,\\\n          \"label\": \"Doctor\",\\\n          \"color\": \"blue\"\\\n        }\\\n      ],\n      \"edges\": [\\\n        {\\\n          \"source\": 1,\\\n          \"target\": 2,\\\n          \"label\": \"is a friend of\",\\\n          \"color\": \"black\"\\\n        },\\\n        {\\\n          \"source\": 1,\\\n          \"target\": 3,\\\n          \"label\": \"is a\",\\\n          \"color\": \"black\"\\\n        }\\\n      ]\n    }\n    \"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/building_knowledge_graphs/",
      "ogUrl": "https://python.useinstructor.com/examples/building_knowledge_graphs/",
      "title": "Building Knowledge Graphs from Text - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/building_knowledge_graphs/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/building_knowledge_graphs.png",
      "ogTitle": "Building Knowledge Graphs from Text - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/building_knowledge_graphs.png",
      "og:title": "Building Knowledge Graphs from Text - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/building_knowledge_graphs/",
      "statusCode": 200,
      "description": "Learn to construct knowledge graphs from textual data using OpenAI's API and Pydantic in this comprehensive tutorial.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to construct knowledge graphs from textual data using OpenAI's API and Pydantic in this comprehensive tutorial.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/building_knowledge_graphs.png",
      "twitter:title": "Building Knowledge Graphs from Text - Instructor",
      "og:description": "Learn to construct knowledge graphs from textual data using OpenAI's API and Pydantic in this comprehensive tutorial.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to construct knowledge graphs from textual data using OpenAI's API and Pydantic in this comprehensive tutorial."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/action_items/#extracting-action-items-from-meeting-transcripts)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/action_items.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/action_items.md \"View source of this page\")\n\n# Extracting Action Items from Meeting Transcripts [¶](https://python.useinstructor.com/examples/action_items/\\#extracting-action-items-from-meeting-transcripts \"Permanent link\")\n\nIn this guide, we'll walk through how to extract action items from meeting transcripts using OpenAI's API and Pydantic. This use case is essential for automating project management tasks, such as task assignment and priority setting.\n\nFor multi-label classification, we introduce a new enum class and a different Pydantic model to handle multiple labels.\n\nMotivation\n\nSignificant amount of time is dedicated to meetings, where action items are generated as the actionable outcomes of these discussions. Automating the extraction of action items can save time and guarantee that no critical tasks are overlooked.\n\n## Defining the Structures [¶](https://python.useinstructor.com/examples/action_items/\\#defining-the-structures \"Permanent link\")\n\nWe'll model a meeting transcript as a collection of **`Ticket`** objects, each representing an action item. Every **`Ticket`** can have multiple **`Subtask`** objects, representing smaller, manageable pieces of the main task.\n\n## Extracting Action Items [¶](https://python.useinstructor.com/examples/action_items/\\#extracting-action-items \"Permanent link\")\n\nTo extract action items from a meeting transcript, we use the **`generate`** function. It calls OpenAI's API, processes the text, and returns a set of action items modeled as **`ActionItems`**.\n\n## Evaluation and Testing [¶](https://python.useinstructor.com/examples/action_items/\\#evaluation-and-testing \"Permanent link\")\n\nTo test the **`generate`** function, we provide it with a sample transcript, and then print the JSON representation of the extracted action items.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\nfrom typing import Iterable, List, Optional\nfrom enum import Enum\nfrom pydantic import BaseModel\n\nclass PriorityEnum(str, Enum):\n    high = \"High\"\n    medium = \"Medium\"\n    low = \"Low\"\n\nclass Subtask(BaseModel):\n    \"\"\"Correctly resolved subtask from the given transcript\"\"\"\n\n    id: int\n    name: str\n\nclass Ticket(BaseModel):\n    \"\"\"Correctly resolved ticket from the given transcript\"\"\"\n\n    id: int\n    name: str\n    description: str\n    priority: PriorityEnum\n    assignees: List[str]\n    subtasks: Optional[List[Subtask]]\n    dependencies: Optional[List[int]]\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\ndef generate(data: str) -> Iterable[Ticket]:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        response_model=Iterable[Ticket],\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"The following is a transcript of a meeting...\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Create the action items for the following transcript: {data}\",\\\n            },\\\n        ],\n    )\n\nprediction = generate(\n    \"\"\"\nAlice: Hey team, we have several critical tasks we need to tackle for the upcoming release. First, we need to work on improving the authentication system. It's a top priority.\nBob: Got it, Alice. I can take the lead on the authentication improvements. Are there any specific areas you want me to focus on?\nAlice: Good question, Bob. We need both a front-end revamp and back-end optimization. So basically, two sub-tasks.\nCarol: I can help with the front-end part of the authentication system.\nBob: Great, Carol. I'll handle the back-end optimization then.\nAlice: Perfect. Now, after the authentication system is improved, we have to integrate it with our new billing system. That's a medium priority task.\nCarol: Is the new billing system already in place?\nAlice: No, it's actually another task. So it's a dependency for the integration task. Bob, can you also handle the billing system?\nBob: Sure, but I'll need to complete the back-end optimization of the authentication system first, so it's dependent on that.\nAlice: Understood. Lastly, we also need to update our user documentation to reflect all these changes. It's a low-priority task but still important.\nCarol: I can take that on once the front-end changes for the authentication system are done. So, it would be dependent on that.\nAlice: Sounds like a plan. Let's get these tasks modeled out and get started.\"\"\"\n)\n\n```\n\n## Visualizing the tasks [¶](https://python.useinstructor.com/examples/action_items/\\#visualizing-the-tasks \"Permanent link\")\n\nIn order to quickly visualize the data we used code interpreter to create a graphviz export of the json version of the ActionItems array.\n\n![action items](https://python.useinstructor.com/img/action_items.png)\n\n```md-code__content\n[\\\n  {\\\n    \"id\": 1,\\\n    \"name\": \"Improve Authentication System\",\\\n    \"description\": \"Revamp the front-end and optimize the back-end of the authentication system\",\\\n    \"priority\": \"High\",\\\n    \"assignees\": [\"Bob\", \"Carol\"],\\\n    \"subtasks\": [\\\n      {\\\n        \"id\": 2,\\\n        \"name\": \"Front-end Revamp\"\\\n      },\\\n      {\\\n        \"id\": 3,\\\n        \"name\": \"Back-end Optimization\"\\\n      }\\\n    ],\\\n    \"dependencies\": []\\\n  },\\\n  {\\\n    \"id\": 4,\\\n    \"name\": \"Integrate Authentication System with Billing System\",\\\n    \"description\": \"Integrate the improved authentication system with the new billing system\",\\\n    \"priority\": \"Medium\",\\\n    \"assignees\": [\"Bob\"],\\\n    \"subtasks\": [],\\\n    \"dependencies\": [1]\\\n  },\\\n  {\\\n    \"id\": 5,\\\n    \"name\": \"Update User Documentation\",\\\n    \"description\": \"Update the user documentation to reflect the changes in the authentication system\",\\\n    \"priority\": \"Low\",\\\n    \"assignees\": [\"Carol\"],\\\n    \"subtasks\": [],\\\n    \"dependencies\": [2]\\\n  }\\\n]\n\n```\n\nIn this example, the **`generate`** function successfully identifies and segments the action items, assigning them priorities, assignees, subtasks, and dependencies as discussed in the meeting.\n\nBy automating this process, you can ensure that important tasks and details are not lost in the sea of meeting minutes, making project management more efficient and effective.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/action_items/",
      "ogUrl": "https://python.useinstructor.com/examples/action_items/",
      "title": "Automating Action Item Extraction from Meeting Transcripts - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/action_items/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/action_items.png",
      "ogTitle": "Automating Action Item Extraction from Meeting Transcripts - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/action_items.png",
      "og:title": "Automating Action Item Extraction from Meeting Transcripts - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/action_items/",
      "statusCode": 200,
      "description": "Learn to extract actionable items from meeting transcripts using OpenAI's API and Pydantic for efficient project management.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to extract actionable items from meeting transcripts using OpenAI's API and Pydantic for efficient project management.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/action_items.png",
      "twitter:title": "Automating Action Item Extraction from Meeting Transcripts - Instructor",
      "og:description": "Learn to extract actionable items from meeting transcripts using OpenAI's API and Pydantic for efficient project management.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to extract actionable items from meeting transcripts using OpenAI's API and Pydantic for efficient project management."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/document_segmentation/#document-segmentation)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/document_segmentation.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/document_segmentation.md \"View source of this page\")\n\n* * *\n\ntitle: Document Segmentation with LLMs: A Comprehensive Guide description: Learn effective document segmentation techniques using Cohere's LLM, enhancing comprehension of complex texts.\n\n* * *\n\n# Document Segmentation [¶](https://python.useinstructor.com/examples/document_segmentation/\\#document-segmentation \"Permanent link\")\n\nIn this guide, we demonstrate how to do document segmentation using structured output from an LLM. We'll be using [command-r-plus](https://docs.cohere.com/docs/command-r-plus) \\- one of Cohere's latest LLMs with 128k context length and testing the approach on an article explaining the Transformer architecture. Same approach to document segmentation can be applied to any other domain where we need to break down a complex long document into smaller chunks.\n\nMotivation\n\nSometimes we need a way to split the document into meaningful parts that center around a single key concept/idea. Simple length-based / rule-based text-splitters are not reliable enough. Consider the cases where documents contain code snippets or math equations - we don't want to split those on `'\\n\\n'` or have to write extensive rules for different types of documents. It turns out that LLMs with sufficiently long context length are well suited for this task.\n\n## Defining the Data Structures [¶](https://python.useinstructor.com/examples/document_segmentation/\\#defining-the-data-structures \"Permanent link\")\n\nFirst, we need to define a **`Section`** class for each of the document's segments. **`StructuredDocument`** class will then encapsulate a list of these sections.\n\nNote that in order to avoid LLM regenerating the content of each section, we can simply enumerate each line of the input document and then ask LLM to segment it by providing start-end line numbers for each section.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass Section(BaseModel):\n    title: str = Field(description=\"main topic of this section of the document\")\n    start_index: int = Field(description=\"line number where the section begins\")\n    end_index: int = Field(description=\"line number where the section ends\")\n\nclass StructuredDocument(BaseModel):\n    \"\"\"obtains meaningful sections, each centered around a single concept/topic\"\"\"\n\n    sections: List[Section] = Field(description=\"a list of sections of the document\")\n\n```\n\n## Document Preprocessing [¶](https://python.useinstructor.com/examples/document_segmentation/\\#document-preprocessing \"Permanent link\")\n\nPreprocess the input `document` by prepending each line with its number.\n\n```md-code__content\ndef doc_with_lines(document):\n    document_lines = document.split(\"\\n\")\n    document_with_line_numbers = \"\"\n    line2text = {}\n    for i, line in enumerate(document_lines):\n        document_with_line_numbers += f\"[{i}] {line}\\n\"\n        line2text[i] = line\n    return document_with_line_numbers, line2text\n\n```\n\n## Segmentation [¶](https://python.useinstructor.com/examples/document_segmentation/\\#segmentation \"Permanent link\")\n\nNext use a Cohere client to extract `StructuredDocument` from the preprocessed doc.\n\n```md-code__content\nimport instructor\nimport cohere\n\n# Apply the patch to the cohere client\n# enables response_model keyword\nclient = instructor.from_cohere(cohere.Client())\n\nsystem_prompt = f\"\"\"\\\nYou are a world class educator working on organizing your lecture notes.\nRead the document below and extract a StructuredDocument object from it where each section of the document is centered around a single concept/topic that can be taught in one lesson.\nEach line of the document is marked with its line number in square brackets (e.g. [1], [2], [3], etc). Use the line numbers to indicate section start and end.\n\"\"\"\n\ndef get_structured_document(document_with_line_numbers) -> StructuredDocument:\n    return client.chat.completions.create(\n        model=\"command-r-plus\",\n        response_model=StructuredDocument,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": system_prompt,\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": document_with_line_numbers,\\\n            },\\\n        ],\n    )  # type: ignore\n\n```\n\nNext, we need to get back the section text based on the start/end indices and our `line2text` dict from the preprocessing step.\n\n```md-code__content\ndef get_sections_text(structured_doc, line2text):\n    segments = []\n    for s in structured_doc.sections:\n        contents = []\n        for line_id in range(s.start_index, s.end_index):\n            contents.append(line2text.get(line_id, ''))\n        segments.append(\n            {\n                \"title\": s.title,\n                \"content\": \"\\n\".join(contents),\n                \"start\": s.start_index,\n                \"end\": s.end_index,\n            }\n        )\n    return segments\n\n```\n\n## Example [¶](https://python.useinstructor.com/examples/document_segmentation/\\#example \"Permanent link\")\n\nHere's an example of using these classes and functions to segment a tutorial on Transformers from [Sebastian Raschka](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html). We can use `trafilatura` package to scrape the web page content of the article.\n\n```md-code__content\nfrom trafilatura import fetch_url, extract\n\nurl = 'https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html'\ndownloaded = fetch_url(url)\ndocument = extract(downloaded)\n\ndocument_with_line_numbers, line2text = doc_with_lines(document)\nstructured_doc = get_structured_document(document_with_line_numbers)\nsegments = get_sections_text(structured_doc, line2text)\n\n```\n\n```md-code__content\nprint(segments[5]['title'])\n\"\"\"\nIntroduction to Multi-Head Attention\n\"\"\"\nprint(segments[5]['content'])\n\"\"\"\nMulti-Head Attention\nIn the very first figure, at the top of this article, we saw that transformers use a module called multi-head attention. How does that relate to the self-attention mechanism (scaled-dot product attention) we walked through above?\nIn the scaled dot-product attention, the input sequence was transformed using three matrices representing the query, key, and value. These three matrices can be considered as a single attention head in the context of multi-head attention. The figure below summarizes this single attention head we covered previously:\nAs its name implies, multi-head attention involves multiple such heads, each consisting of query, key, and value matrices. This concept is similar to the use of multiple kernels in convolutional neural networks.\nTo illustrate this in code, suppose we have 3 attention heads, so we now extend the \\(d' \\times d\\) dimensional weight matrices so \\(3 \\times d' \\times d\\):\nIn:\nh = 3\nmultihead_W_query = torch.nn.Parameter(torch.rand(h, d_q, d))\nmultihead_W_key = torch.nn.Parameter(torch.rand(h, d_k, d))\nmultihead_W_value = torch.nn.Parameter(torch.rand(h, d_v, d))\nConsequently, each query element is now \\(3 \\times d_q\\) dimensional, where \\(d_q=24\\) (here, let’s keep the focus on the 3rd element corresponding to index position 2):\nIn:\nmultihead_query_2 = multihead_W_query.matmul(x_2)\nprint(multihead_query_2.shape)\nOut:\ntorch.Size([3, 24])\n\"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/document_segmentation/",
      "ogUrl": "https://python.useinstructor.com/examples/document_segmentation/",
      "title": "Intelligent Document Segmentation - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/document_segmentation/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/document_segmentation.png",
      "ogTitle": "Intelligent Document Segmentation - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/document_segmentation.png",
      "og:title": "Intelligent Document Segmentation - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/document_segmentation/",
      "statusCode": 200,
      "description": "A lightweight library for structured outputs with LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "A lightweight library for structured outputs with LLMs.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/document_segmentation.png",
      "twitter:title": "Intelligent Document Segmentation - Instructor",
      "og:description": "A lightweight library for structured outputs with LLMs.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "A lightweight library for structured outputs with LLMs."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/mistral/#structured-outputs-using-mistral)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/mistral.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/mistral.md \"View source of this page\")\n\n# Structured Outputs using Mistral [¶](https://python.useinstructor.com/examples/mistral/\\#structured-outputs-using-mistral \"Permanent link\")\n\nYou can now also use mistralai models for inference by using from\\_mistral.\n\nThe examples are using mistral-large-latest.\n\n## MistralAI API [¶](https://python.useinstructor.com/examples/mistral/\\#mistralai-api \"Permanent link\")\n\nTo use mistral you need to obtain a mistral API key. Goto [mistralai](https://mistral.ai/) click on Build Now and login. Select API Keys from the left menu and then select Create API key to create a new key.\n\n## Use example [¶](https://python.useinstructor.com/examples/mistral/\\#use-example \"Permanent link\")\n\nSome pip packages need to be installed to use the example:\n\n```md-code__content\npip install instructor mistralai pydantic\n\n```\n\nYou need to export the mistral API key:\n\n```md-code__content\nexport MISTRAL_API_KEY=<your-api-key>\n\n```\n\nAn example:\n\n```md-code__content\nimport os\nfrom pydantic import BaseModel\nfrom mistralai import Mistral\nfrom instructor import from_mistral, Mode\n\nclass UserDetails(BaseModel):\n    name: str\n    age: int\n\n# enables `response_model` in chat call\nclient = Mistral(api_key=os.environ.get(\"MISTRAL_API_KEY\"))\n\ninstructor_client = from_mistral(\n    client=client,\n    model=\"mistral-large-latest\",\n    mode=Mode.MISTRAL_TOOLS,\n    max_tokens=1000,\n)\n\nresp = instructor_client.messages.create(\n    response_model=UserDetails,\n    messages=[{\"role\": \"user\", \"content\": \"Jason is 10\"}],\n    temperature=0,\n)\n\nprint(resp)\n#> name='Jason' age=10\n\n# output: UserDetails(name='Jason', age=10)\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/mistral/",
      "ogUrl": "https://python.useinstructor.com/examples/mistral/",
      "title": "Using MistralAI for Structured Outputs - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/mistral/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/mistral.png",
      "ogTitle": "Using MistralAI for Structured Outputs - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/mistral.png",
      "og:title": "Using MistralAI for Structured Outputs - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/mistral/",
      "statusCode": 200,
      "description": "Learn how to use MistralAI models for inference, including setup, API key generation, and example code.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use MistralAI models for inference, including setup, API key generation, and example code.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/mistral.png",
      "twitter:title": "Using MistralAI for Structured Outputs - Instructor",
      "og:description": "Learn how to use MistralAI models for inference, including setup, API key generation, and example code.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use MistralAI models for inference, including setup, API key generation, and example code."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/open_source/#instructor-with-open-source-models)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/open_source.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/open_source.md \"View source of this page\")\n\n# Instructor with open source models [¶](https://python.useinstructor.com/examples/open_source/\\#instructor-with-open-source-models \"Permanent link\")\n\nInstructor works with Open source model providers that support the [OpenAI API chat endpoint](https://platform.openai.com/docs/api-reference/chat)\n\nSee examples README [here](https://github.com/jxnl/instructor/tree/main/examples/open_source_examples)\n\n# Currently tested open source model providers [¶](https://python.useinstructor.com/examples/open_source/\\#currently-tested-open-source-model-providers \"Permanent link\")\n\n- [OpenRouter](https://openrouter.ai/)\n- [Perplexity](https://www.perplexity.ai/)\n- [RunPod TheBloke LLMs](https://github.com/TheBlokeAI/dockerLLM/blob/main/README_Runpod_LocalLLMsUI.md) \\*\\*\n\n\\\\*\\\\* This utilizes text-generation-webui w/ Openai plugin under the hood.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/open_source/",
      "ogUrl": "https://python.useinstructor.com/examples/open_source/",
      "title": "Open Source Model Providers for Chat API - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/open_source/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/open_source.png",
      "ogTitle": "Open Source Model Providers for Chat API - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/open_source.png",
      "og:title": "Open Source Model Providers for Chat API - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/open_source/",
      "statusCode": 200,
      "description": "Explore tested open source models compatible with the OpenAI chat API, including OpenRouter, Perplexity, and RunPod LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Explore tested open source models compatible with the OpenAI chat API, including OpenRouter, Perplexity, and RunPod LLMs.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/open_source.png",
      "twitter:title": "Open Source Model Providers for Chat API - Instructor",
      "og:description": "Explore tested open source models compatible with the OpenAI chat API, including OpenRouter, Perplexity, and RunPod LLMs.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Explore tested open source models compatible with the OpenAI chat API, including OpenRouter, Perplexity, and RunPod LLMs."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/bulk_classification/#bulk-classification-from-user-provided-tags)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/bulk_classification.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/bulk_classification.md \"View source of this page\")\n\n# Bulk Classification from User-Provided Tags. [¶](https://python.useinstructor.com/examples/bulk_classification/\\#bulk-classification-from-user-provided-tags \"Permanent link\")\n\nThis tutorial shows how to do classification from user provided tags. This is valuable when you want to provide services that allow users to do some kind of classification.\n\nMotivation\n\nImagine allowing the user to upload documents as part of a RAG application. Oftentimes, we might want to allow the user to specify an existing set of tags, give descriptions, and do the classification for them.\n\n## Defining the Structures [¶](https://python.useinstructor.com/examples/bulk_classification/\\#defining-the-structures \"Permanent link\")\n\nOne of the easy things to do is to allow users to define a set of tags in some kind of schema and save that in a database. Here's an example of a schema that we might use:\n\n| tag\\_id | name | instructions |\n| --- | --- | --- |\n| 0 | personal | Personal information |\n| 1 | phone | Phone number |\n| 2 | email | Email address |\n| 3 | address | Address |\n| 4 | Other | Other information |\n\n1. **tag\\_id** — The unique identifier for the tag.\n2. **name** — The name of the tag.\n3. **instructions** — A description of the tag, which can be used as a prompt to describe the tag.\n\n## Implementing the Classification [¶](https://python.useinstructor.com/examples/bulk_classification/\\#implementing-the-classification \"Permanent link\")\n\nIn order to do this we'll do a couple of things:\n\n1. We'll use the `instructor` library to patch the `openai` library to use the `AsyncOpenAI` client.\n2. Implement a `Tag` model that will be used to validate the tags from the context. (This will allow us to avoid hallucinating tags that are not in the context.)\n3. Helper models for the request and response.\n4. An async function to do the classification.\n5. A main function to run the classification using the `asyncio.gather` function to run the classification in parallel.\n\nIf you want to learn more about how to do bad computations, check out our post on AsyncIO [here](https://python.useinstructor.com/blog/2023/11/13/learn-async/).\n\n```md-code__content\nimport openai\nimport instructor\n\nclient = instructor.from_openai(\n    openai.AsyncOpenAI(),\n)\n\n```\n\nFirst, we'll need to import all of our Pydantic and instructor code and use the AsyncOpenAI client. Then, we'll define the tag model along with the tag instructions to provide input and output.\n\nThis is very helpful because once we use something like FastAPI to create endpoints, the Pydantic functions will serve as multiple tools:\n\n1. A description for the developer\n2. Type hints for the IDE\n3. OpenAPI documentation for the FastAPI endpoint\n4. Schema and Response Model for the language model.\n\n```md-code__content\nfrom typing import List\nfrom pydantic import BaseModel, ValidationInfo, model_validator\n\nclass Tag(BaseModel):\n    id: int\n    name: str\n\n    @model_validator(mode=\"after\")\n    def validate_ids(self, info: ValidationInfo):\n        context = info.context\n        if context:\n            tags: List[Tag] = context.get(\"tags\")\n            assert self.id in {\n                tag.id for tag in tags\n            }, f\"Tag ID {self.id} not found in context\"\n            assert self.name in {\n                tag.name for tag in tags\n            }, f\"Tag name {self.name} not found in context\"\n        return self\n\nclass TagWithInstructions(Tag):\n    instructions: str\n\nclass TagRequest(BaseModel):\n    texts: List[str]\n    tags: List[TagWithInstructions]\n\nclass TagResponse(BaseModel):\n    texts: List[str]\n    predictions: List[Tag]\n\n```\n\nLet's delve deeper into what the `validate_ids` function does. Notice that its purpose is to extract tags from the context and ensure that each ID and name exists in the set of tags. This approach helps minimize hallucinations. If we mistakenly identify either the ID or the tag, an error will be thrown, and the instructor will prompt the language model to retry until the correct item is successfully extracted.\n\n```md-code__content\nfrom pydantic import model_validator, ValidationInfo\n\n@model_validator(mode=\"after\")\ndef validate_ids(self, info: ValidationInfo):\n    context = info.context\n    if context:\n        tags: List[Tag] = context.get(\"tags\")\n        assert self.id in {\n            tag.id for tag in tags\n        }, f\"Tag ID {self.id} not found in context\"\n        assert self.name in {\n            tag.name for tag in tags\n        }, f\"Tag name {self.name} not found in context\"\n    return self\n\n```\n\nNow, let's implement the function to do the classification. This function will take a single text and a list of tags and return the predicted tag.\n\n```md-code__content\nasync def tag_single_request(text: str, tags: List[Tag]) -> Tag:\n    allowed_tags = [(tag.id, tag.name) for tag in tags]\n    allowed_tags_str = \", \".join([f\"`{tag}`\" for tag in allowed_tags])\n\n    return await client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a world-class text tagging system.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": f\"Describe the following text: `{text}`\"},\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Here are the allowed tags: {allowed_tags_str}\",\\\n            },\\\n        ],\n        response_model=Tag,  # Minimizes the hallucination of tags that are not in the allowed tags.\n        validation_context={\"tags\": tags},\n    )\n\nasync def tag_request(request: TagRequest) -> TagResponse:\n    predictions = await asyncio.gather(\n        *[tag_single_request(text, request.tags) for text in request.texts]\n    )\n    return TagResponse(\n        texts=request.texts,\n        predictions=predictions,\n    )\n\n```\n\nNotice that we first define a single async function that makes a prediction of a tag, and we pass it into the validation context in order to minimize hallucinations.\n\nFinally, we'll implement the main function to run the classification using the `asyncio.gather` function to run the classification in parallel.\n\n```md-code__content\nimport asyncio\n\ntags = [\\\n    TagWithInstructions(id=0, name=\"personal\", instructions=\"Personal information\"),\\\n    TagWithInstructions(id=1, name=\"phone\", instructions=\"Phone number\"),\\\n    TagWithInstructions(id=2, name=\"email\", instructions=\"Email address\"),\\\n    TagWithInstructions(id=3, name=\"address\", instructions=\"Address\"),\\\n    TagWithInstructions(id=4, name=\"Other\", instructions=\"Other information\"),\\\n]\n\n# Texts will be a range of different questions.\n# Such as \"How much does it cost?\", \"What is your privacy policy?\", etc.\ntexts = [\\\n    \"What is your phone number?\",\\\n    \"What is your email address?\",\\\n    \"What is your address?\",\\\n    \"What is your privacy policy?\",\\\n]\n\n# The request will contain the texts and the tags.\nrequest = TagRequest(texts=texts, tags=tags)\n\n# The response will contain the texts, the predicted tags, and the confidence.\nresponse = asyncio.run(tag_request(request))\nprint(response.model_dump_json(indent=2))\n\"\"\"\n{\n  \"texts\": [\\\n    \"What is your phone number?\",\\\n    \"What is your email address?\",\\\n    \"What is your address?\",\\\n    \"What is your privacy policy?\"\\\n  ],\n  \"predictions\": [\\\n    {\\\n      \"id\": 1,\\\n      \"name\": \"phone\"\\\n    },\\\n    {\\\n      \"id\": 2,\\\n      \"name\": \"email\"\\\n    },\\\n    {\\\n      \"id\": 3,\\\n      \"name\": \"address\"\\\n    },\\\n    {\\\n      \"id\": 4,\\\n      \"name\": \"Other\"\\\n    }\\\n  ]\n}\n\"\"\"\n\n```\n\nWhich would result in:\n\n```md-code__content\n{\n  \"texts\": [\\\n    \"What is your phone number?\",\\\n    \"What is your email address?\",\\\n    \"What is your address?\",\\\n    \"What is your privacy policy?\"\\\n  ],\n  \"predictions\": [\\\n    {\\\n      \"id\": 1,\\\n      \"name\": \"phone\"\\\n    },\\\n    {\\\n      \"id\": 2,\\\n      \"name\": \"email\"\\\n    },\\\n    {\\\n      \"id\": 3,\\\n      \"name\": \"address\"\\\n    },\\\n    {\\\n      \"id\": 4,\\\n      \"name\": \"Other\"\\\n    }\\\n  ]\n}\n\n```\n\n## What happens in production? [¶](https://python.useinstructor.com/examples/bulk_classification/\\#what-happens-in-production \"Permanent link\")\n\nIf we were to use this in production, we might expect to have some kind of fast API endpoint.\n\n```md-code__content\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.post(\"/tag\", response_model=TagResponse)\nasync def tag(request: TagRequest) -> TagResponse:\n    return await tag_request(request)\n\n```\n\nSince everything is already annotated with Pydantic, this code is very simple to write!\n\nWhere do tags come from?\n\nI just want to call out that here you can also imagine the tag spec IDs and names and instructions for example could come from a database or somewhere else. I'll leave this as an exercise to the reader, but I hope this gives us a clear understanding of how we can do something like user-defined classification.\n\n## Improving the Model [¶](https://python.useinstructor.com/examples/bulk_classification/\\#improving-the-model \"Permanent link\")\n\nThere's a couple things we could do to make this system a little bit more robust.\n\n1. Use confidence score:\n\n```md-code__content\nclass TagWithConfidence(Tag):\n    confidence: float = Field(\n        ...,\n        ge=0,\n        le=1,\n        description=\"The confidence of the prediction, 0 is low, 1 is high\",\n    )\n\n```\n\n1. Use multiclass classification:\n\nNotice in the example we use Iterable\\[Tag\\] vs Tag. This is because we might want to use a multiclass classification model that returns multiple tag!\n\n```md-code__content\nimport instructor\nimport openai\nimport asyncio\nfrom typing import Iterable\n\nclient = instructor.from_openai(\n    openai.AsyncOpenAI(),\n)\n\ntags = [\\\n    Tag(id=0, name=\"personal\"),\\\n    Tag(id=1, name=\"phone\"),\\\n    Tag(id=2, name=\"email\"),\\\n    Tag(id=3, name=\"address\"),\\\n    Tag(id=4, name=\"Other\"),\\\n]\n\n# Texts will be a range of different questions.\n# Such as \"How much does it cost?\", \"What is your privacy policy?\", etc.\ntext = \"What is your phone number?\"\n\nasync def get_tags(text: List[str], tags: List[Tag]) -> List[Tag]:\n    allowed_tags = [(tag.id, tag.name) for tag in tags]\n    allowed_tags_str = \", \".join([f\"`{tag}`\" for tag in allowed_tags])\n\n    return await client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a world-class text tagging system.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": f\"Describe the following text: `{text}`\"},\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Here are the allowed tags: {allowed_tags_str}\",\\\n            },\\\n        ],\n        response_model=Iterable[Tag],\n        validation_context={\"tags\": tags},\n    )\n\ntag_results = asyncio.run(get_tags(text, tags))\nfor tag in tag_results:\n    print(tag)\n    #> id=0 name='personal'\n    #> id=1 name='phone'\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/bulk_classification/",
      "ogUrl": "https://python.useinstructor.com/examples/bulk_classification/",
      "title": "User-Provided Tag Classification Tutorial - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/bulk_classification/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/bulk_classification.png",
      "ogTitle": "User-Provided Tag Classification Tutorial - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/bulk_classification.png",
      "og:title": "User-Provided Tag Classification Tutorial - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/bulk_classification/",
      "statusCode": 200,
      "description": "Learn to classify user-provided tags effectively using async functions and FastAPI for parallel processing.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to classify user-provided tags effectively using async functions and FastAPI for parallel processing.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/bulk_classification.png",
      "twitter:title": "User-Provided Tag Classification Tutorial - Instructor",
      "og:description": "Learn to classify user-provided tags effectively using async functions and FastAPI for parallel processing.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to classify user-provided tags effectively using async functions and FastAPI for parallel processing."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/moderation/#openai-moderation)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/moderation.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/moderation.md \"View source of this page\")\n\n# OpenAI Moderation [¶](https://python.useinstructor.com/examples/moderation/\\#openai-moderation \"Permanent link\")\n\nThis example uses OpenAI's moderation endpoint to check content compliance with OpenAI's usage policies. It can identify and filter harmful content that violates the policies.\n\nThe model flags content and classifies it into categories including hate, harassment, self-harm, sexual content, and violence. Each category has subcategories for detailed classification.\n\nThis validator is to be used for monitoring OpenAI API inputs and outputs, other use cases are currently [not allowed](https://platform.openai.com/docs/guides/moderation/overview).\n\n## Incorporating OpenAI moderation validator [¶](https://python.useinstructor.com/examples/moderation/\\#incorporating-openai-moderation-validator \"Permanent link\")\n\nThe following code defines a function to validate content using OpenAI's Moderation endpoint. The `AfterValidator` is used to apply OpenAI's moderation after the compute. This moderation checks if the content complies with OpenAI's usage policies and flags any harmful content. Here's how it works:\n\n1. Generate the OpenAI client and patch it with the `instructor`. Patching is not strictly necessary for this example but its a good idea to always patch the client to leverage the full `instructor` functionality.\n\n2. Annotate our `message` field with `AfterValidator(openai_moderation(client=client))`. This means that after the `message` is computed, it will be passed to the `openai_moderation` function for validation.\n\n\n```md-code__content\nimport instructor\n\nfrom instructor import openai_moderation\n\nfrom typing_extensions import Annotated\nfrom pydantic import BaseModel, AfterValidator\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\nclass Response(BaseModel):\n    message: Annotated[str, AfterValidator(openai_moderation(client=client))]\n\ntry:\n    Response(message=\"I want to make them suffer the consequences\")\nexcept Exception as e:\n    print(e)\n    \"\"\"\n    1 validation error for Response\n    message\n      Value error, `I want to make them suffer the consequences` was flagged for violence [type=value_error, input_value='I want to make them suffer the consequences', input_type=str]\n        For further information visit https://errors.pydantic.dev/2.9/v/value_error\n    \"\"\"\n\ntry:\n    Response(message=\"I want to hurt myself.\")\nexcept Exception as e:\n    print(e)\n    \"\"\"\n    1 validation error for Response\n    message\n      Value error, `I want to hurt myself.` was flagged for self_harm, self_harm_intent, self-harm, self-harm/intent [type=value_error, input_value='I want to hurt myself.', input_type=str]\n        For further information visit https://errors.pydantic.dev/2.9/v/value_error\n    \"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/moderation/",
      "ogUrl": "https://python.useinstructor.com/examples/moderation/",
      "title": "OpenAI Moderation Example for Content Compliance - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/moderation/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/moderation.png",
      "ogTitle": "OpenAI Moderation Example for Content Compliance - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/moderation.png",
      "og:title": "OpenAI Moderation Example for Content Compliance - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/moderation/",
      "statusCode": 200,
      "description": "Learn how to use OpenAI's moderation endpoint to filter harmful content and ensure compliance with usage policies.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use OpenAI's moderation endpoint to filter harmful content and ensure compliance with usage policies.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/moderation.png",
      "twitter:title": "OpenAI Moderation Example for Content Compliance - Instructor",
      "og:description": "Learn how to use OpenAI's moderation endpoint to filter harmful content and ensure compliance with usage policies.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use OpenAI's moderation endpoint to filter harmful content and ensure compliance with usage policies."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/batch_classification_langsmith/#seamless-support-with-langsmith)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/batch_classification_langsmith.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/batch_classification_langsmith.md \"View source of this page\")\n\n# Seamless Support with Langsmith [¶](https://python.useinstructor.com/examples/batch_classification_langsmith/\\#seamless-support-with-langsmith \"Permanent link\")\n\nIts a common misconception that LangChain's [LangSmith](https://www.langchain.com/langsmith) is only compatible with LangChain's models. In reality, LangSmith is a unified DevOps platform for developing, collaborating, testing, deploying, and monitoring LLM applications. In this blog we will explore how LangSmith can be used to enhance the OpenAI client alongside `instructor`.\n\nFirst, install the necessary packages:\n\n```md-code__content\npip install -U langsmith\n\n```\n\n## LangSmith [¶](https://python.useinstructor.com/examples/batch_classification_langsmith/\\#langsmith \"Permanent link\")\n\nIn order to use langsmith, you first need to set your LangSmith API key.\n\n```md-code__content\nexport LANGCHAIN_API_KEY=<your-api-key>\n\n```\n\nNext, you will need to install the LangSmith SDK:\n\n```md-code__content\npip install -U langsmith\npip install -U instructor\n\n```\n\nIn this example we'll use the `wrap_openai` function to wrap the OpenAI client with LangSmith. This will allow us to use LangSmith's observability and monitoring features with the OpenAI client. Then we'll use `instructor` to patch the client with the `TOOLS` mode. This will allow us to use `instructor` to add additional functionality to the client.\n\n```md-code__content\nimport instructor\nimport asyncio\n\nfrom langsmith import traceable\nfrom langsmith.wrappers import wrap_openai\n\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field, field_validator\nfrom typing import List\nfrom enum import Enum\n\n# Wrap the OpenAI client with LangSmith\nclient = wrap_openai(AsyncOpenAI())\n\n# Patch the client with instructor\nclient = instructor.from_openai(client)\n\n# Rate limit the number of requests\nsem = asyncio.Semaphore(5)\n\n# Use an Enum to define the types of questions\nclass QuestionType(Enum):\n    CONTACT = \"CONTACT\"\n    TIMELINE_QUERY = \"TIMELINE_QUERY\"\n    DOCUMENT_SEARCH = \"DOCUMENT_SEARCH\"\n    COMPARE_CONTRAST = \"COMPARE_CONTRAST\"\n    EMAIL = \"EMAIL\"\n    PHOTOS = \"PHOTOS\"\n    SUMMARY = \"SUMMARY\"\n\n# You can add more instructions and examples in the description\n# or you can put it in the prompt in `messages=[...]`\nclass QuestionClassification(BaseModel):\n    \"\"\"\n    Predict the type of question that is being asked.\n    Here are some tips on how to predict the question type:\n    CONTACT: Searches for some contact information.\n    TIMELINE_QUERY: \"When did something happen?\n    DOCUMENT_SEARCH: \"Find me a document\"\n    COMPARE_CONTRAST: \"Compare and contrast two things\"\n    EMAIL: \"Find me an email, search for an email\"\n    PHOTOS: \"Find me a photo, search for a photo\"\n    SUMMARY: \"Summarize a large amount of data\"\n    \"\"\"\n\n    # If you want only one classification, just change it to\n    #   `classification: QuestionType` rather than `classifications: List[QuestionType]``\n    chain_of_thought: str = Field(\n        ..., description=\"The chain of thought that led to the classification\"\n    )\n    classification: List[QuestionType] = Field(\n        description=f\"An accuracy and correct prediction predicted class of question. Only allowed types: {[t.value for t in QuestionType]}, should be used\",\n    )\n\n    @field_validator(\"classification\", mode=\"before\")\n    def validate_classification(cls, v):\n        # sometimes the API returns a single value, just make sure it's a list\n        if not isinstance(v, list):\n            v = [v]\n        return v\n\n@traceable(name=\"classify-question\")\nasync def classify(data: str) -> QuestionClassification:\n    \"\"\"\n    Perform multi-label classification on the input text.\n    Change the prompt to fit your use case.\n    Args:\n        data (str): The input text to classify.\n    \"\"\"\n    async with sem:  # some simple rate limiting\n        return data, await client.chat.completions.create(\n            model=\"gpt-4-turbo-preview\",\n            response_model=QuestionClassification,\n            max_retries=2,\n            messages=[\\\n                {\\\n                    \"role\": \"user\",\\\n                    \"content\": f\"Classify the following question: {data}\",\\\n                },\\\n            ],\n        )\n\nasync def main(questions: List[str]):\n    tasks = [classify(question) for question in questions]\n\n    for task in asyncio.as_completed(tasks):\n        question, label = await task\n        resp = {\n            \"question\": question,\n            \"classification\": [c.value for c in label.classification],\n            \"chain_of_thought\": label.chain_of_thought,\n        }\n        resps.append(resp)\n    return resps\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    questions = [\\\n        \"What was that ai app that i saw on the news the other day?\",\\\n        \"Can you find the trainline booking email?\",\\\n        \"what did I do on Monday?\",\\\n        \"Tell me about todays meeting and how it relates to the email on Monday\",\\\n    ]\n\n    resp = asyncio.run(main(questions))\n\n    for r in resp:\n        print(\"q:\", r[\"question\"])\n        #> q: what did I do on Monday?\n        print(\"c:\", r[\"classification\"])\n        #> c: ['SUMMARY']\n\n```\n\nIf you follow what we've done is wrapped the client and proceeded to quickly use asyncio to classify a list of questions. This is a simple example of how you can use LangSmith to enhance the OpenAI client. You can use LangSmith to monitor and observe the client, and use `instructor` to add additional functionality to the client.\n\nTo take a look at trace of this run check out this shareable [link](https://smith.langchain.com/public/eaae9f95-3779-4bbb-824d-97aa8a57a4e0/r).\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/batch_classification_langsmith/",
      "ogUrl": "https://python.useinstructor.com/examples/batch_classification_langsmith/",
      "title": "Enhancing OpenAI Client with LangSmith and Instructor - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/batch_classification_langsmith/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/batch_classification_langsmith.png",
      "ogTitle": "Enhancing OpenAI Client with LangSmith and Instructor - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/batch_classification_langsmith.png",
      "og:title": "Enhancing OpenAI Client with LangSmith and Instructor - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/batch_classification_langsmith/",
      "statusCode": 200,
      "description": "Discover how to integrate LangSmith with the OpenAI client for improved observability and functionality using instructor.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Discover how to integrate LangSmith with the OpenAI client for improved observability and functionality using instructor.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/batch_classification_langsmith.png",
      "twitter:title": "Enhancing OpenAI Client with LangSmith and Instructor - Instructor",
      "og:description": "Discover how to integrate LangSmith with the OpenAI client for improved observability and functionality using instructor.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Discover how to integrate LangSmith with the OpenAI client for improved observability and functionality using instructor."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/partial_streaming/#streaming-partial-responses)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/partial_streaming.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/partial_streaming.md \"View source of this page\")\n\n# Streaming Partial Responses [¶](https://python.useinstructor.com/examples/partial_streaming/\\#streaming-partial-responses \"Permanent link\")\n\nField level streaming provides incremental snapshots of the current state of the response model that are immediately useable. This approach is particularly relevant in contexts like rendering UI components.\n\nInstructor supports this pattern by making use of `Partial[T]`. This lets us dynamically create a new class that treats all of the original model's fields as `Optional`.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\nfrom typing import List\n\nclient = instructor.from_openai(OpenAI())\n\ntext_block = \"\"\"\nIn our recent online meeting, participants from various backgrounds joined to discuss the upcoming tech conference. The names and contact details of the participants were as follows:\n- Name: John Doe, Email: johndoe@email.com, Twitter: @TechGuru44\n- Name: Jane Smith, Email: janesmith@email.com, Twitter: @DigitalDiva88\n- Name: Alex Johnson, Email: alexj@email.com, Twitter: @CodeMaster2023\nDuring the meeting, we agreed on several key points. The conference will be held on March 15th, 2024, at the Grand Tech Arena located at 4521 Innovation Drive. Dr. Emily Johnson, a renowned AI researcher, will be our keynote speaker.\nThe budget for the event is set at $50,000, covering venue costs, speaker fees, and promotional activities. Each participant is expected to contribute an article to the conference blog by February 20th.\nA follow-up meetingis scheduled for January 25th at 3 PM GMT to finalize the agenda and confirm the list of speakers.\n\"\"\"\n\nclass User(BaseModel):\n    name: str\n    email: str\n    twitter: str\n\nclass MeetingInfo(BaseModel):\n    users: List[User]\n    date: str\n    location: str\n    budget: int\n    deadline: str\n\nPartialMeetingInfo = instructor.Partial[MeetingInfo]\n\nextraction_stream = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=PartialMeetingInfo,\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": f\"Get the information about the meeting and the users {text_block}\",\\\n        },\\\n    ],\n    stream=True,\n)  # type: ignore\n\nfrom rich.console import Console\n\nconsole = Console()\n\nfor extraction in extraction_stream:\n    obj = extraction.model_dump()\n    console.clear()\n    console.print(obj)\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/partial_streaming/",
      "ogUrl": "https://python.useinstructor.com/examples/partial_streaming/",
      "title": "Streaming Partial Responses with Instructor - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/partial_streaming/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/partial_streaming.png",
      "ogTitle": "Streaming Partial Responses with Instructor - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/partial_streaming.png",
      "og:title": "Streaming Partial Responses with Instructor - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/partial_streaming/",
      "statusCode": 200,
      "description": "Learn how to implement field-level streaming in Python using the Instructor library for dynamic UI rendering.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to implement field-level streaming in Python using the Instructor library for dynamic UI rendering.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/partial_streaming.png",
      "twitter:title": "Streaming Partial Responses with Instructor - Instructor",
      "og:description": "Learn how to implement field-level streaming in Python using the Instructor library for dynamic UI rendering.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to implement field-level streaming in Python using the Instructor library for dynamic UI rendering."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/watsonx/#structured-outputs-with-ibm-watsonxai)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/watsonx.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/watsonx.md \"View source of this page\")\n\n# Structured Outputs with IBM watsonx.ai [¶](https://python.useinstructor.com/examples/watsonx/\\#structured-outputs-with-ibm-watsonxai \"Permanent link\")\n\nYou can use IBM watsonx.ai for inference using [LiteLLM](https://docs.litellm.ai/docs/providers/watsonx).\n\n## Prerequisites [¶](https://python.useinstructor.com/examples/watsonx/\\#prerequisites \"Permanent link\")\n\n- IBM Cloud Account\n- API Key from IBM Cloud IAM: [https://cloud.ibm.com/iam/apikeys](https://cloud.ibm.com/iam/apikeys)\n- Project ID (from watsonx.ai instance URL: [https://dataplatform.cloud.ibm.com/projects/](https://dataplatform.cloud.ibm.com/projects/)/)\n\n## Install [¶](https://python.useinstructor.com/examples/watsonx/\\#install \"Permanent link\")\n\n```md-code__content\npoetry install instructor --with litellm\n\n```\n\n## Example [¶](https://python.useinstructor.com/examples/watsonx/\\#example \"Permanent link\")\n\n```md-code__content\nimport os\n\nimport litellm\nfrom litellm import completion\nfrom pydantic import BaseModel, Field\n\nimport instructor\nfrom instructor import Mode\n\nlitellm.drop_params = True  # watsonx.ai doesn't support `json_mode`\n\nos.environ[\"WATSONX_URL\"] = \"https://us-south.ml.cloud.ibm.com\"\nos.environ[\"WATSONX_API_KEY\"] = \"\"\nos.environ[\"WATSONX_PROJECT_ID\"] = \"\"\n# Additional options: https://docs.litellm.ai/docs/providers/watsonx\n\nclass Company(BaseModel):\n    name: str = Field(description=\"name of the company\")\n    year_founded: int = Field(description=\"year the company was founded\")\n\nclient = instructor.from_litellm(completion, mode=Mode.JSON)\n\nresp = client.chat.completions.create(\n    model=\"watsonx/meta-llama/llama-3-8b-instruct\",\n    max_tokens=1024,\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": \"\"\"\\\\\nGiven the following text, create a Company object:\\\n\\\nIBM was founded in 1911 as the Computing-Tabulating-Recording Company (CTR), a holding company of manufacturers of record-keeping and measuring systems.\\\n\"\"\",\\\n        }\\\n    ],\n    project_id=os.environ[\"WATSONX_PROJECT_ID\"],\n    response_model=Company,\n)\n\nprint(resp.model_dump_json(indent=2))\n\"\"\"\n{\n  \"name\": \"IBM\",\n  \"year_founded\": 1911\n}\n\"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/watsonx/",
      "ogUrl": "https://python.useinstructor.com/examples/watsonx/",
      "title": "Using IBM watsonx.ai for Inference - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/watsonx/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/watsonx.png",
      "ogTitle": "Using IBM watsonx.ai for Inference - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/watsonx.png",
      "og:title": "Using IBM watsonx.ai for Inference - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/watsonx/",
      "statusCode": 200,
      "description": "Learn how to use IBM watsonx.ai and LiteLLM for structured outputs, including setup, installation, and coding examples.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use IBM watsonx.ai and LiteLLM for structured outputs, including setup, installation, and coding examples.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/watsonx.png",
      "twitter:title": "Using IBM watsonx.ai for Inference - Instructor",
      "og:description": "Learn how to use IBM watsonx.ai and LiteLLM for structured outputs, including setup, installation, and coding examples.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use IBM watsonx.ai and LiteLLM for structured outputs, including setup, installation, and coding examples."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/extract_contact_info/#customer-information-extraction)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/extract_contact_info.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/extract_contact_info.md \"View source of this page\")\n\n# Customer Information Extraction [¶](https://python.useinstructor.com/examples/extract_contact_info/\\#customer-information-extraction \"Permanent link\")\n\nIn this guide, we'll walk through how to extract customer lead information using OpenAI's API and Pydantic. This use case is essential for seamlessly automating the process of extracting specific information from a context.\n\n## Motivation [¶](https://python.useinstructor.com/examples/extract_contact_info/\\#motivation \"Permanent link\")\n\nYou could potentially integrate this into a chatbot to extract relevant user information from user messages. With the use of machine learning driven validation it would reduce the need for a human to verify the information.\n\n## Defining the Structure [¶](https://python.useinstructor.com/examples/extract_contact_info/\\#defining-the-structure \"Permanent link\")\n\nWe'll model a customer lead as a Lead object, including attributes for the name and phone number. We'll use a Pydantic PhoneNumber type to validate the phone numbers entered and provide a Field to give the model more information on correctly populating the object.\n\n## Extracting Lead Information [¶](https://python.useinstructor.com/examples/extract_contact_info/\\#extracting-lead-information \"Permanent link\")\n\nTo extract lead information, we create the `parse_lead_from_message` function which integrates Instructor. It calls OpenAI's API, processes the text, and returns the extracted lead information as a Lead object.\n\n## Evaluating Lead Extraction [¶](https://python.useinstructor.com/examples/extract_contact_info/\\#evaluating-lead-extraction \"Permanent link\")\n\nTo showcase the `parse_lead_from_message` function we can provide sample user messages that may be obtained from a dialogue with a chatbot assistant. Also take note of the response model being set as `Iterable[Lead]` this allows for multiple leads being extracted from the same message.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber\nfrom typing import Iterable\n\nclass Lead(BaseModel):\n    name: str\n    phone_number: PhoneNumber = Field(\n        description=\"Needs to be a phone number with a country code. If none, assume +1\"\n    )\n\n    # Can define some function here to send Lead information to a database using an API\n\nclient = instructor.from_openai(OpenAI())\n\ndef parse_lead_from_message(user_message: str):\n    return client.chat.completions.create(\n        model=\"gpt-4-turbo-preview\",\n        response_model=Iterable[Lead],\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a data extraction system that extracts a user's name and phone number from a message.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Extract the user's lead information from this user's message: {user_message}\",\\\n            },\\\n        ],\n    )\n\nif __name__ == \"__main__\":\n    lead = parse_lead_from_message(\n        \"Yes, that would be great if someone can reach out my name is Patrick King 9175554587\"\n    )\n    assert all(isinstance(item, Lead) for item in lead)\n    for item in lead:\n        print(item.model_dump_json(indent=2))\n        \"\"\"\n        {\n          \"name\": \"Patrick King\",\n          \"phone_number\": \"tel:+1-917-555-4587\"\n        }\n        \"\"\"\n\n    # Invalid phone number example:\n    try:\n        lead2 = parse_lead_from_message(\n            \"Yes, that would be great if someone can reach out my name is Patrick King 9172234\"\n        )\n        assert all(isinstance(item, Lead) for item in lead2)\n        for item in lead2:\n            print(item.model_dump_json(indent=2))\n            \"\"\"\n            {\n              \"name\": \"Patrick King\",\n              \"phone_number\": \"tel:+1-917-223-4999\"\n            }\n            \"\"\"\n\n    except Exception as e:\n        print(\"ERROR:\", e)\n        \"\"\"\n        ERROR:\n        1 validation error for IterableLead\n        tasks.0.phone_number\n          value is not a valid phone number [type=value_error, input_value='+19172234', input_type=str]\n        \"\"\"\n\n```\n\nIn this example, the `parse_lead_from_message` function successfully extracts lead information from a user message, demonstrating how automation can enhance the efficiency of collecting accurate customer details. It also shows how the function successfully catches that the phone number is invalid so functionality can be implemented for the user to get prompted again to give a correct phone number.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/extract_contact_info/",
      "ogUrl": "https://python.useinstructor.com/examples/extract_contact_info/",
      "title": "Automate Customer Lead Information Extraction with OpenAI and Pydantic - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/extract_contact_info/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/extract_contact_info.png",
      "ogTitle": "Automate Customer Lead Information Extraction with OpenAI and Pydantic - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/extract_contact_info.png",
      "og:title": "Automate Customer Lead Information Extraction with OpenAI and Pydantic - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/extract_contact_info/",
      "statusCode": 200,
      "description": "Learn to extract customer lead details using OpenAI's API and Pydantic for efficient data automation and validation.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to extract customer lead details using OpenAI's API and Pydantic for efficient data automation and validation.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/extract_contact_info.png",
      "twitter:title": "Automate Customer Lead Information Extraction with OpenAI and Pydantic - Instructor",
      "og:description": "Learn to extract customer lead details using OpenAI's API and Pydantic for efficient data automation and validation.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to extract customer lead details using OpenAI's API and Pydantic for efficient data automation and validation."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/extracting_receipts/#extracting-receipt-data-using-gpt-4-and-python)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/extracting_receipts.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/extracting_receipts.md \"View source of this page\")\n\n# Extracting Receipt Data using GPT-4 and Python [¶](https://python.useinstructor.com/examples/extracting_receipts/\\#extracting-receipt-data-using-gpt-4-and-python \"Permanent link\")\n\nThis post demonstrates how to use Python's Pydantic library and OpenAI's GPT-4 model to extract receipt data from images and validate the total amount. This method is particularly useful for automating expense tracking and financial analysis tasks.\n\n## Defining the Item and Receipt Classes [¶](https://python.useinstructor.com/examples/extracting_receipts/\\#defining-the-item-and-receipt-classes \"Permanent link\")\n\nFirst, we define two Pydantic models, `Item` and `Receipt`, to structure the extracted data. The `Item` class represents individual items on the receipt, with fields for name, price, and quantity. The `Receipt` class contains a list of `Item` objects and the total amount.\n\n```md-code__content\nfrom pydantic import BaseModel\n\nclass Item(BaseModel):\n    name: str\n    price: float\n    quantity: int\n\nclass Receipt(BaseModel):\n    items: list[Item]\n    total: float\n\n```\n\n## Validating the Total Amount [¶](https://python.useinstructor.com/examples/extracting_receipts/\\#validating-the-total-amount \"Permanent link\")\n\nTo ensure the accuracy of the extracted data, we use Pydantic's `model_validator` decorator to define a custom validation function, `check_total`. This function calculates the sum of item prices and compares it to the extracted total amount. If there's a discrepancy, it raises a `ValueError`.\n\n```md-code__content\nfrom pydantic import model_validator\n\n@model_validator(mode=\"after\")\ndef check_total(self):\n    items = self.items\n    total = self.total\n    calculated_total = sum(item.price * item.quantity for item in items)\n    if calculated_total != total:\n        raise ValueError(\n            f\"Total {total} does not match the sum of item prices {calculated_total}\"\n        )\n    return self\n\n```\n\n## Extracting Receipt Data from Images [¶](https://python.useinstructor.com/examples/extracting_receipts/\\#extracting-receipt-data-from-images \"Permanent link\")\n\nThe `extract_receipt` function uses OpenAI's GPT-4 model to process an image URL and extract receipt data. We utilize the `instructor` library to configure the OpenAI client for this purpose.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\ndef extract(url: str) -> Receipt:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        max_tokens=4000,\n        response_model=Receipt,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": [\\\n                    {\\\n                        \"type\": \"image_url\",\\\n                        \"image_url\": {\"url\": url},\\\n                    },\\\n                    {\\\n                        \"type\": \"text\",\\\n                        \"text\": \"Analyze the image and return the items in the receipt and the total amount.\",\\\n                    },\\\n                ],\\\n            }\\\n        ],\n    )\n\n```\n\n## Practical Examples [¶](https://python.useinstructor.com/examples/extracting_receipts/\\#practical-examples \"Permanent link\")\n\nIn these examples, we apply the method to extract receipt data from two different images. The custom validation function ensures that the extracted total amount matches the sum of item prices.\n\n```md-code__content\nurl = \"https://templates.mediamodifier.com/645124ff36ed2f5227cbf871/supermarket-receipt-template.jpg\"\n\nreceipt = extract(url)\nprint(receipt)\n\"\"\"\nitems=[Item(name='Lorem ipsum', price=9.2, quantity=1), Item(name='Lorem ipsum dolor sit', price=19.2, quantity=1), Item(name='Lorem ipsum dolor sit amet', price=15.0, quantity=1), Item(name='Lorem ipsum', price=15.0, quantity=1), Item(name='Lorem ipsum', price=15.0, quantity=1), Item(name='Lorem ipsum dolor sit', price=15.0, quantity=1), Item(name='Lorem ipsum', price=19.2, quantity=1)] total=107.6\n\"\"\"\n\n```\n\nBy combining the power of GPT-4 and Python's Pydantic library, we can accurately extract and validate receipt data from images, streamlining expense tracking and financial analysis tasks.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/extracting_receipts/",
      "ogUrl": "https://python.useinstructor.com/examples/extracting_receipts/",
      "title": "Extracting Receipt Data with GPT-4 and Python - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/extracting_receipts/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/extracting_receipts.png",
      "ogTitle": "Extracting Receipt Data with GPT-4 and Python - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/extracting_receipts.png",
      "og:title": "Extracting Receipt Data with GPT-4 and Python - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/extracting_receipts/",
      "statusCode": 200,
      "description": "Learn how to use Python and GPT-4 to extract and validate receipt data from images for efficient expense tracking.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use Python and GPT-4 to extract and validate receipt data from images for efficient expense tracking.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/extracting_receipts.png",
      "twitter:title": "Extracting Receipt Data with GPT-4 and Python - Instructor",
      "og:description": "Learn how to use Python and GPT-4 to extract and validate receipt data from images for efficient expense tracking.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use Python and GPT-4 to extract and validate receipt data from images for efficient expense tracking."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/exact_citations/#example-answering-questions-with-validated-citations)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/exact_citations.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/exact_citations.md \"View source of this page\")\n\n# Example: Answering Questions with Validated Citations [¶](https://python.useinstructor.com/examples/exact_citations/\\#example-answering-questions-with-validated-citations \"Permanent link\")\n\nFor the full code example, check out [examples/citation\\_fuzzy\\_match.py](https://github.com/jxnl/instructor/blob/main/examples/citation_with_extraction/citation_fuzzy_match.py)\n\n## Overview [¶](https://python.useinstructor.com/examples/exact_citations/\\#overview \"Permanent link\")\n\nThis example shows how to use Instructor with validators to not only add citations to answers generated but also prevent hallucinations by ensuring that every statement made by the LLM is backed up by a direct quote from the context provided, and that those quotes exist!\n\nTwo Python classes, `Fact` and `QuestionAnswer`, are defined to encapsulate the information of individual facts and the entire answer, respectively.\n\n## Data Structures [¶](https://python.useinstructor.com/examples/exact_citations/\\#data-structures \"Permanent link\")\n\n### The `Fact` Class [¶](https://python.useinstructor.com/examples/exact_citations/\\#the-fact-class \"Permanent link\")\n\nThe `Fact` class encapsulates a single statement or fact. It contains two fields:\n\n- `fact`: A string representing the body of the fact or statement.\n- `substring_quote`: A list of strings. Each string is a direct quote from the context that supports the `fact`.\n\n#### Validation Method: `validate_sources` [¶](https://python.useinstructor.com/examples/exact_citations/\\#validation-method-validate_sources \"Permanent link\")\n\nThis method validates the sources ( `substring_quote`) in the context. It utilizes regex to find the span of each substring quote in the given context. If the span is not found, the quote is removed from the list.\n\n```md-code__content\nfrom pydantic import Field, BaseModel, model_validator, ValidationInfo\nfrom typing import List\n\nclass Fact(BaseModel):\n    fact: str = Field(...)\n    substring_quote: List[str] = Field(...)\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self, info: ValidationInfo) -> \"Fact\":\n        text_chunks = info.context.get(\"text_chunk\", None)\n        spans = list(self.get_spans(text_chunks))\n        self.substring_quote = [text_chunks[span[0] : span[1]] for span in spans]\n        return self\n\n    def get_spans(self, context):\n        for quote in self.substring_quote:\n            yield from self._get_span(quote, context)\n\n    def _get_span(self, quote, context):\n        for match in re.finditer(re.escape(quote), context):\n            yield match.span()\n\n```\n\n### The `QuestionAnswer` Class [¶](https://python.useinstructor.com/examples/exact_citations/\\#the-questionanswer-class \"Permanent link\")\n\nThis class encapsulates the question and its corresponding answer. It contains two fields:\n\n- `question`: The question asked.\n- `answer`: A list of `Fact` objects that make up the answer.\n\n#### Validation Method: `validate_sources` [¶](https://python.useinstructor.com/examples/exact_citations/\\#validation-method-validate_sources_1 \"Permanent link\")\n\nThis method checks that each `Fact` object in the `answer` list has at least one valid source. If a `Fact` object has no valid sources, it is removed from the `answer` list.\n\n```md-code__content\nfrom pydantic import BaseModel, Field, model_validator\nfrom typing import List\n\nclass QuestionAnswer(BaseModel):\n    question: str = Field(...)\n    answer: List[Fact] = Field(...)\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self) -> \"QuestionAnswer\":\n        self.answer = [fact for fact in self.answer if len(fact.substring_quote) > 0]\n        return self\n\n```\n\n## Function to Ask AI a Question [¶](https://python.useinstructor.com/examples/exact_citations/\\#function-to-ask-ai-a-question \"Permanent link\")\n\n### The `ask_ai` Function [¶](https://python.useinstructor.com/examples/exact_citations/\\#the-ask_ai-function \"Permanent link\")\n\nThis function takes a string `question` and a string `context` and returns a `QuestionAnswer` object. It uses the OpenAI API to fetch the answer and then validates the sources using the defined classes.\n\nTo understand the validation context work from pydantic check out [pydantic's docs](https://docs.pydantic.dev/usage/validators/#model-validators)\n\n```md-code__content\nfrom openai import OpenAI\nimport instructor\n\n# Apply the patch to the OpenAI client\n# enables response_model, validation_context keyword\nclient = instructor.from_openai(OpenAI())\n\ndef ask_ai(question: str, context: str) -> QuestionAnswer:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo-0613\",\n        temperature=0,\n        response_model=QuestionAnswer,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a world class algorithm to answer questions with correct and exact citations.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": f\"{context}\"},\\\n            {\"role\": \"user\", \"content\": f\"Question: {question}\"},\\\n        ],\n        validation_context={\"text_chunk\": context},\n    )\n\n```\n\n## Example [¶](https://python.useinstructor.com/examples/exact_citations/\\#example \"Permanent link\")\n\ndd Here's an example of using these classes and functions to ask a question and validate the answer.\n\n```md-code__content\nquestion = \"What did the author do during college?\"\ncontext = \"\"\"\nMy name is Jason Liu, and I grew up in Toronto Canada but I was born in China.\nI went to an arts high school but in university I studied Computational Mathematics and physics.\nAs part of coop I worked at many companies including Stitchfix, Facebook.\nI also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.\n\"\"\"\n\n```\n\nThe output would be a `QuestionAnswer` object containing validated facts and their sources.\n\n```md-code__content\n{\n    \"question\": \"where did he go to school?\",\n    \"answer\": [\\\n        {\\\n            \"statement\": \"Jason Liu went to an arts highschool.\",\\\n            \"substring_phrase\": [\"arts highschool\"],\\\n        },\\\n        {\\\n            \"statement\": \"Jason Liu studied Computational Mathematics and physics in university.\",\\\n            \"substring_phrase\": [\"university\"],\\\n        },\\\n    ],\n}\n\n```\n\nThis ensures that every piece of information in the answer has been validated against the context.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/exact_citations/",
      "ogUrl": "https://python.useinstructor.com/examples/exact_citations/",
      "title": "Validating AI Answers with Contextual Citations in Python - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/exact_citations/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/exact_citations.png",
      "ogTitle": "Validating AI Answers with Contextual Citations in Python - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/exact_citations.png",
      "og:title": "Validating AI Answers with Contextual Citations in Python - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/exact_citations/",
      "statusCode": 200,
      "description": "Learn to use Python classes to validate AI-generated answers with citations, ensuring accuracy and preventing hallucinations.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to use Python classes to validate AI-generated answers with citations, ensuring accuracy and preventing hallucinations.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/exact_citations.png",
      "twitter:title": "Validating AI Answers with Contextual Citations in Python - Instructor",
      "og:description": "Learn to use Python classes to validate AI-generated answers with citations, ensuring accuracy and preventing hallucinations.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to use Python classes to validate AI-generated answers with citations, ensuring accuracy and preventing hallucinations."
    }
  },
  {
    "markdown": "[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/multiple_classification.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/multiple_classification.md \"View source of this page\")\n\n# Multiple Classification Tasks\n\nFor multi-label classification, we introduce a new enum class and a different Pydantic model to handle multiple labels.\n\n```md-code__content\nimport openai\nimport instructor\n\nfrom typing import List, Literal\nfrom pydantic import BaseModel, Field\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(openai.OpenAI())\n\nLABELS = Literal[\"ACCOUNT\", \"BILLING\", \"GENERAL_QUERY\"]\n\nclass MultiClassPrediction(BaseModel):\n    \"\"\"\n    A few-shot example of multi-label classification:\n    Examples:\n    - \"My account is locked and I can't access my billing info.\": ACCOUNT, BILLING\n    - \"I need help with my subscription.\": ACCOUNT\n    - \"How do I change my payment method?\": BILLING\n    - \"Can you tell me the status of my order?\": BILLING\n    - \"I have a question about the product features.\": GENERAL_QUERY\n    \"\"\"\n\n    labels: List[LABELS] = Field(\n        ...,\n        description=\"Only select the labels that apply to the support ticket.\",\n    )\n\ndef multi_classify(data: str) -> MultiClassPrediction:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=MultiClassPrediction,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": f\"You are a support agent at a tech company. Only select the labels that apply to the support ticket.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Classify the following support ticket: <text>{data}</text>\",\\\n            },\\\n        ],\n    )  # type: ignore\n\nif __name__ == \"__main__\":\n    ticket = \"My account is locked and I can't access my billing info.\"\n    prediction = multi_classify(ticket)\n    assert {\"ACCOUNT\", \"BILLING\"} == {label for label in prediction.labels}\n    print(\"input:\", ticket)\n    #> input: My account is locked and I can't access my billing info.\n    print(\"labels:\", LABELS)\n    #> labels: typing.Literal['ACCOUNT', 'BILLING', 'GENERAL_QUERY']\n    print(\"prediction:\", prediction)\n    #> prediction: labels=['ACCOUNT', 'BILLING']\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/multiple_classification/",
      "ogUrl": "https://python.useinstructor.com/examples/multiple_classification/",
      "title": "Multi-Label Classification with OpenAI and Pydantic - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/multiple_classification/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/multiple_classification.png",
      "ogTitle": "Multi-Label Classification with OpenAI and Pydantic - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/multiple_classification.png",
      "og:title": "Multi-Label Classification with OpenAI and Pydantic - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/multiple_classification/",
      "statusCode": 200,
      "description": "Learn how to implement multi-label classification using OpenAI's API and Pydantic for effective support ticket classification.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to implement multi-label classification using OpenAI's API and Pydantic for effective support ticket classification.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/multiple_classification.png",
      "twitter:title": "Multi-Label Classification with OpenAI and Pydantic - Instructor",
      "og:description": "Learn how to implement multi-label classification using OpenAI's API and Pydantic for effective support ticket classification.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to implement multi-label classification using OpenAI's API and Pydantic for effective support ticket classification."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/search/#example-segmenting-search-queries)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/search.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/search.md \"View source of this page\")\n\n# Example: Segmenting Search Queries [¶](https://python.useinstructor.com/examples/search/\\#example-segmenting-search-queries \"Permanent link\")\n\nIn this example, we will demonstrate how to leverage the `MultiTask` and `enum.Enum` features of OpenAI Function Call to segment search queries. We will define the necessary structures using Pydantic and demonstrate how segment queries into multiple sub queries and execute them in parallel with `asyncio`.\n\nMotivation\n\nExtracting a list of tasks from text is a common use case for leveraging language models. This pattern can be applied to various applications, such as virtual assistants like Siri or Alexa, where understanding user intent and breaking down requests into actionable tasks is crucial. In this example, we will demonstrate how to use OpenAI Function Call to segment search queries and execute them in parallel.\n\n## Structure of the Data [¶](https://python.useinstructor.com/examples/search/\\#structure-of-the-data \"Permanent link\")\n\nThe `Search` class is a Pydantic model that defines the structure of the search query. It has three fields: `title`, `query`, and `type`. The `title` field is the title of the request, the `query` field is the query to search for relevant content, and the `type` field is the type of search. The `execute` method is used to execute the search query.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\nfrom typing import Iterable, Literal\nfrom pydantic import BaseModel, Field\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\nclass Search(BaseModel):\n    query: str = Field(..., description=\"Query to search for relevant content\")\n    type: Literal[\"web\", \"image\", \"video\"] = Field(..., description=\"Type of search\")\n\n    async def execute(self):\n        print(\n            f\"Searching for `{self.title}` with query `{self.query}` using `{self.type}`\"\n        )\n\ndef segment(data: str) -> Search:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=Iterable[Search],\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Consider the data below: '\\n{data}' and segment it into multiple search queries\",\\\n            },\\\n        ],\n        max_tokens=1000,\n    )\n\nfor search in segment(\"Search for a picture of a cat and a video of a dog\"):\n    print(search.model_dump_json())\n    #> {\"query\":\"picture of a cat\",\"type\":\"image\"}\n    #> {\"query\":\"video of a dog\",\"type\":\"video\"}\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/search/",
      "ogUrl": "https://python.useinstructor.com/examples/search/",
      "title": "Segmenting Search Queries with OpenAI and Pydantic - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/search/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/search.png",
      "ogTitle": "Segmenting Search Queries with OpenAI and Pydantic - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/search.png",
      "og:title": "Segmenting Search Queries with OpenAI and Pydantic - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/search/",
      "statusCode": 200,
      "description": "Learn to segment search queries into actionable tasks using OpenAI Function Call and Pydantic for efficient execution.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to segment search queries into actionable tasks using OpenAI Function Call and Pydantic for efficient execution.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/search.png",
      "twitter:title": "Segmenting Search Queries with OpenAI and Pydantic - Instructor",
      "og:description": "Learn to segment search queries into actionable tasks using OpenAI Function Call and Pydantic for efficient execution.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to segment search queries into actionable tasks using OpenAI Function Call and Pydantic for efficient execution."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/recursive/#recursive-schema-implementation-guide)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/recursive.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/recursive.md \"View source of this page\")\n\n# Recursive Schema Implementation Guide [¶](https://python.useinstructor.com/examples/recursive/\\#recursive-schema-implementation-guide \"Permanent link\")\n\nThis guide demonstrates how to work with recursive schemas in Instructor using Pydantic models. While flat schemas are often simpler to work with, some use cases require recursive structures to represent hierarchical data effectively.\n\nMotivation\n\nRecursive schemas are particularly useful when dealing with: \\* Nested organizational structures \\* File system hierarchies \\* Comment threads with replies \\* Task dependencies with subtasks \\* Abstract syntax trees\n\n## Defining a Recursive Schema [¶](https://python.useinstructor.com/examples/recursive/\\#defining-a-recursive-schema \"Permanent link\")\n\nHere's an example of how to define a recursive Pydantic model:\n\n```md-code__content\nfrom typing import List, Optional\nfrom pydantic import BaseModel, Field\n\nclass RecursiveNode(BaseModel):\n    \"\"\"A node that can contain child nodes of the same type.\"\"\"\n\n    name: str = Field(..., description=\"Name of the node\")\n    value: Optional[str] = Field(\n        None, description=\"Optional value associated with the node\"\n    )\n    children: List[\"RecursiveNode\"] = Field(\n        default_factory=list, description=\"List of child nodes\"\n    )\n\n# Required for recursive Pydantic models\nRecursiveNode.model_rebuild()\n\n```\n\n## Example Usage [¶](https://python.useinstructor.com/examples/recursive/\\#example-usage \"Permanent link\")\n\nLet's see how to use this recursive schema with Instructor:\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\ndef parse_hierarchy(text: str) -> RecursiveNode:\n    \"\"\"Parse text into a hierarchical structure.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are an expert at parsing text into hierarchical structures.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Parse this text into a hierarchical structure: {text}\",\\\n            },\\\n        ],\n        response_model=RecursiveNode,\n    )\n\n# Example usage\nhierarchy = parse_hierarchy(\n    \"\"\"\nCompany: Acme Corp\n- Department: Engineering\n  - Team: Frontend\n    - Project: Website Redesign\n    - Project: Mobile App\n  - Team: Backend\n    - Project: API v2\n    - Project: Database Migration\n- Department: Marketing\n  - Team: Digital\n    - Project: Social Media Campaign\n  - Team: Brand\n    - Project: Logo Refresh\n\"\"\"\n)\n\n```\n\n## Validation and Best Practices [¶](https://python.useinstructor.com/examples/recursive/\\#validation-and-best-practices \"Permanent link\")\n\nWhen working with recursive schemas:\n\n1. Always call `model_rebuild()` after defining the model\n2. Consider adding validation for maximum depth to prevent infinite recursion\n3. Use type hints properly to maintain code clarity\n4. Consider implementing custom validators for specific business rules\n\n```md-code__content\nfrom pydantic import model_validator\n\nclass RecursiveNodeWithDepth(RecursiveNode):\n    @model_validator(mode='after')\n    def validate_depth(self) -> \"RecursiveNodeWithDepth\":\n        def check_depth(node: \"RecursiveNodeWithDepth\", current_depth: int = 0) -> int:\n            if current_depth > 10:  # Maximum allowed depth\n                raise ValueError(\"Maximum depth exceeded\")\n            return max(\n                [check_depth(child, current_depth + 1) for child in node.children],\n                default=current_depth,\n            )\n\n        check_depth(self)\n        return self\n\n```\n\n## Performance Considerations [¶](https://python.useinstructor.com/examples/recursive/\\#performance-considerations \"Permanent link\")\n\nWhile recursive schemas are powerful, they can be more challenging for language models to handle correctly. Consider these tips:\n\n1. Keep structures as shallow as possible\n2. Use clear naming conventions\n3. Provide good examples in your prompts\n4. Consider breaking very large structures into smaller chunks\n\n## Conclusion [¶](https://python.useinstructor.com/examples/recursive/\\#conclusion \"Permanent link\")\n\nRecursive schemas provide a powerful way to handle hierarchical data structures in your applications. While they require more careful handling than flat schemas, they can be invaluable for certain use cases.\n\nFor more examples of working with complex data structures, check out: 1. [Query Planning with Dependencies](https://python.useinstructor.com/examples/planning-tasks/) 2\\. [Knowledge Graph Generation](https://python.useinstructor.com/examples/knowledge_graph/)\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/recursive/",
      "ogUrl": "https://python.useinstructor.com/examples/recursive/",
      "title": "Working with Recursive Schemas in Instructor - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/recursive/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/recursive.png",
      "ogTitle": "Working with Recursive Schemas in Instructor - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/recursive.png",
      "og:title": "Working with Recursive Schemas in Instructor - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/recursive/",
      "statusCode": 200,
      "description": "Learn how to effectively implement and use recursive Pydantic models for handling nested and hierarchical data structures.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to effectively implement and use recursive Pydantic models for handling nested and hierarchical data structures.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/recursive.png",
      "twitter:title": "Working with Recursive Schemas in Instructor - Instructor",
      "og:description": "Learn how to effectively implement and use recursive Pydantic models for handling nested and hierarchical data structures.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to effectively implement and use recursive Pydantic models for handling nested and hierarchical data structures."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/single_classification/#single-label-classification)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/single_classification.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/single_classification.md \"View source of this page\")\n\n# Single-Label Classification [¶](https://python.useinstructor.com/examples/single_classification/\\#single-label-classification \"Permanent link\")\n\nThis example demonstrates how to perform single-label classification using the OpenAI API. The example uses the `gpt-3.5-turbo` model to classify text as either `SPAM` or `NOT_SPAM`.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\nfrom openai import OpenAI\nimport instructor\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\nclass ClassificationResponse(BaseModel):\n    \"\"\"\n    A few-shot example of text classification:\n\n    Examples:\n    - \"Buy cheap watches now!\": SPAM\n    - \"Meeting at 3 PM in the conference room\": NOT_SPAM\n    - \"You've won a free iPhone! Click here\": SPAM\n    - \"Can you pick up some milk on your way home?\": NOT_SPAM\n    - \"Increase your followers by 10000 overnight!\": SPAM\n    \"\"\"\n\n    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n        ...,\n        description=\"The predicted class label.\",\n    )\n\ndef classify(data: str) -> ClassificationResponse:\n    \"\"\"Perform single-label classification on the input text.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=ClassificationResponse,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Classify the following text: <text>{data}</text>\",\\\n            },\\\n        ],\n    )\n\nif __name__ == \"__main__\":\n    for text, label in [\\\n        (\"Hey Jason! You're awesome\", \"NOT_SPAM\"),\\\n        (\"I am a nigerian prince and I need your help.\", \"SPAM\"),\\\n    ]:\n        prediction = classify(text)\n        assert prediction.label == label\n        print(f\"Text: {text}, Predicted Label: {prediction.label}\")\n        #> Text: Hey Jason! You're awesome, Predicted Label: NOT_SPAM\n        #> Text: I am a nigerian prince and I need your help., Predicted Label: SPAM\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/single_classification/",
      "ogUrl": "https://python.useinstructor.com/examples/single_classification/",
      "title": "Single-Label Classification with OpenAI API - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/single_classification/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/single_classification.png",
      "ogTitle": "Single-Label Classification with OpenAI API - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/single_classification.png",
      "og:title": "Single-Label Classification with OpenAI API - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/single_classification/",
      "statusCode": 200,
      "description": "Learn to implement single-label classification using the OpenAI API to classify text as SPAM or NOT_SPAM.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to implement single-label classification using the OpenAI API to classify text as SPAM or NOT_SPAM.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/single_classification.png",
      "twitter:title": "Single-Label Classification with OpenAI API - Instructor",
      "og:description": "Learn to implement single-label classification using the OpenAI API to classify text as SPAM or NOT_SPAM.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to implement single-label classification using the OpenAI API to classify text as SPAM or NOT_SPAM."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/examples/#how-should-i-include-examples)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/examples.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/examples.md \"View source of this page\")\n\n# How should I include examples? [¶](https://python.useinstructor.com/examples/examples/\\#how-should-i-include-examples \"Permanent link\")\n\nTo enhance the clarity and usability of your model and prompt, incorporating examples directly into the JSON schema extra of your Pydantic model is highly recommended. This approach not only streamlines the integration of practical examples but also ensures that they are easily accessible and understandable within the context of your model's schema.\n\n```md-code__content\nimport openai\nimport instructor\nfrom typing import Iterable\nfrom pydantic import BaseModel, ConfigDict\n\nclient = instructor.from_openai(openai.OpenAI())\n\nclass SyntheticQA(BaseModel):\n    question: str\n    answer: str\n\n    model_config = ConfigDict(\n        json_schema_extra={\n            \"examples\": [\\\n                {\"question\": \"What is the capital of France?\", \"answer\": \"Paris\"},\\\n                {\\\n                    \"question\": \"What is the largest planet in our solar system?\",\\\n                    \"answer\": \"Jupiter\",\\\n                },\\\n                {\\\n                    \"question\": \"Who wrote 'To Kill a Mockingbird'?\",\\\n                    \"answer\": \"Harper Lee\",\\\n                },\\\n                {\\\n                    \"question\": \"What element does 'O' represent on the periodic table?\",\\\n                    \"answer\": \"Oxygen\",\\\n                },\\\n            ]\n        }\n    )\n\ndef get_synthetic_data() -> Iterable[SyntheticQA]:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\"role\": \"system\", \"content\": \"Generate synthetic examples\"},\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": \"Generate the exact examples you see in the examples of this prompt. \",\\\n            },\\\n        ],\n        response_model=Iterable[SyntheticQA],\n    )  # type: ignore\n\nif __name__ == \"__main__\":\n    for example in get_synthetic_data():\n        print(example)\n        #> question='What is the capital of France?' answer='Paris'\n        #> question='What is the largest planet in our solar system?' answer='Jupiter'\n        #> question=\"Who wrote 'To Kill a Mockingbird'?\" answer='Harper Lee'\n        \"\"\"\n        question=\"What element does 'O' represent on the periodic table?\" answer='Oxygen'\n        \"\"\"\n        \"\"\"\n        question=\"What element does 'O' represent on the periodic table?\" answer='Oxygen'\n        \"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/examples/",
      "ogUrl": "https://python.useinstructor.com/examples/examples/",
      "title": "Incorporating Examples in Pydantic Models - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/examples/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/examples.png",
      "ogTitle": "Incorporating Examples in Pydantic Models - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/examples.png",
      "og:title": "Incorporating Examples in Pydantic Models - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/examples/",
      "statusCode": 200,
      "description": "Learn how to enhance Pydantic models with practical examples for clarity and usability in JSON schemas.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to enhance Pydantic models with practical examples for clarity and usability in JSON schemas.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/examples.png",
      "twitter:title": "Incorporating Examples in Pydantic Models - Instructor",
      "og:description": "Learn how to enhance Pydantic models with practical examples for clarity and usability in JSON schemas.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to enhance Pydantic models with practical examples for clarity and usability in JSON schemas."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/groq/#structured-outputs-using-groq)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/groq.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/groq.md \"View source of this page\")\n\n* * *\n\ntitle: Using Groq for Inference: Setup and Example description: Learn how to use Groq for inference with the mixtral-8x7b model, including API setup and a practical Python example.\n\n* * *\n\n# Structured Outputs using Groq [¶](https://python.useinstructor.com/examples/groq/\\#structured-outputs-using-groq \"Permanent link\")\n\nInstead of using openai or antrophic you can now also use groq for inference by using from\\_groq.\n\nThe examples are using mixtral-8x7b model.\n\n## GroqCloud API [¶](https://python.useinstructor.com/examples/groq/\\#groqcloud-api \"Permanent link\")\n\nTo use groq you need to obtain a groq API key. Goto [groqcloud](https://console.groq.com) and login. Select API Keys from the left menu and then select Create API key to create a new key.\n\n## Use example [¶](https://python.useinstructor.com/examples/groq/\\#use-example \"Permanent link\")\n\nSome pip packages need to be installed to use the example:\n\n```md-code__content\npip install instructor groq pydantic openai anthropic\n\n```\n\nYou need to export the groq API key:\n\n```md-code__content\nexport GROQ_API_KEY=<your-api-key>\n\n```\n\nAn example:\n\n```md-code__content\nimport os\nfrom pydantic import BaseModel, Field\nfrom typing import List\nfrom groq import Groq\nimport instructor\n\nclass Character(BaseModel):\n    name: str\n    fact: List[str] = Field(..., description=\"A list of facts about the subject\")\n\nclient = Groq(\n    api_key=os.environ.get('GROQ_API_KEY'),\n)\n\nclient = instructor.from_groq(client, mode=instructor.Mode.TOOLS)\n\nresp = client.chat.completions.create(\n    model=\"mixtral-8x7b-32768\",\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": \"Tell me about the company Tesla\",\\\n        }\\\n    ],\n    response_model=Character,\n)\nprint(resp.model_dump_json(indent=2))\n\"\"\"\n{\n  \"name\": \"Tesla\",\n  \"fact\": [\\\n    \"electric vehicle manufacturer\",\\\n    \"solar panel producer\",\\\n    \"based in Palo Alto, California\",\\\n    \"founded in 2003 by Elon Musk\"\\\n  ]\n}\n\"\"\"\n\n```\n\nYou can find another example called groq\\_example2.py under examples/groq of this repository.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/groq/",
      "ogUrl": "https://python.useinstructor.com/examples/groq/",
      "title": "Structured Outputs with Groq - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/groq/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/groq.png",
      "ogTitle": "Structured Outputs with Groq - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/groq.png",
      "og:title": "Structured Outputs with Groq - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/groq/",
      "statusCode": 200,
      "description": "A lightweight library for structured outputs with LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "A lightweight library for structured outputs with LLMs.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/groq.png",
      "twitter:title": "Structured Outputs with Groq - Instructor",
      "og:description": "A lightweight library for structured outputs with LLMs.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "A lightweight library for structured outputs with LLMs."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/sqlmodel/#integrating-instructor-with-sqlmodel)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/sqlmodel.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/sqlmodel.md \"View source of this page\")\n\n# Integrating Instructor with SQLModel [¶](https://python.useinstructor.com/examples/sqlmodel/\\#integrating-instructor-with-sqlmodel \"Permanent link\")\n\n[SQLModel](https://sqlmodel.tiangolo.com/) is a library designed for interacting with SQL databases from Python code using Python objects. `SQLModel` is based on `Pydantic` and `SQLAlchemy` and was created by [tiangolo](https://twitter.com/tiangolo) who also developed `FastAPI`. So you can expect seamless integration across all these libraries, reducing code duplicating and improving your developer experience.\n\n# Example: Adding responses from Instructor directly to your DB [¶](https://python.useinstructor.com/examples/sqlmodel/\\#example-adding-responses-from-instructor-directly-to-your-db \"Permanent link\")\n\n## Defining the Models [¶](https://python.useinstructor.com/examples/sqlmodel/\\#defining-the-models \"Permanent link\")\n\nFirst we'll define a model that will serve as a table for our database and the structure of our outputs from `Instructor`\n\nModel Definition\n\nYou'll need to subclass your models with both `SQLModel` and `instructor.OpenAISchema` for them to work with SQLModel\n\n```md-code__content\nfrom typing import Optional\nfrom sqlmodel import Field, SQLModel\nimport instructor\n\nclass Hero(SQLModel, instructor.OpenAISchema, table=True):\n    id: Optional[int] = Field(default=None, primary_key=True)\n    name: str\n    secret_name: str\n    age: Optional[int] = None\n\n```\n\n## Generating a record [¶](https://python.useinstructor.com/examples/sqlmodel/\\#generating-a-record \"Permanent link\")\n\nThe `create_hero` function will query `OpenAI` for a `Hero` record\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\ndef create_hero() -> Hero:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Hero,\n        messages=[\\\n            {\"role\": \"user\", \"content\": \"Make a new superhero\"},\\\n        ],\n    )\n\n```\n\n## Inserting the response into the DB [¶](https://python.useinstructor.com/examples/sqlmodel/\\#inserting-the-response-into-the-db \"Permanent link\")\n\n```md-code__content\nengine = create_engine(\"sqlite:///database.db\")\nSQLModel.metadata.create_all(engine)\n\nhero = create_hero()\nprint(hero.model_dump())\n#> {'name': 'Superman', 'secret_name': 'Clark Kent', 'age': 30, 'id': None}\n\nwith Session(engine) as session:\n    session.add(hero)\n    session.commit()\n\n```\n\n![Image of hero record in the database](https://python.useinstructor.com/examples/db.png)\n\nAnd there you have it! You can now use the same models for your database and `Instructor` enabling them work seamlessly! Also checkout the [FastAPI](https://python.useinstructor.com/concepts/fastapi/) guide to see how you can use these models in an API as well.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/sqlmodel/",
      "ogUrl": "https://python.useinstructor.com/examples/sqlmodel/",
      "title": "Integrating Instructor with SQLModel in Python - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/sqlmodel/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/sqlmodel.png",
      "ogTitle": "Integrating Instructor with SQLModel in Python - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/sqlmodel.png",
      "og:title": "Integrating Instructor with SQLModel in Python - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/sqlmodel/",
      "statusCode": 200,
      "description": "Learn how to integrate Instructor with SQLModel for seamless database interactions and API development in Python.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to integrate Instructor with SQLModel for seamless database interactions and API development in Python.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/sqlmodel.png",
      "twitter:title": "Integrating Instructor with SQLModel in Python - Instructor",
      "og:description": "Learn how to integrate Instructor with SQLModel for seamless database interactions and API development in Python.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to integrate Instructor with SQLModel for seamless database interactions and API development in Python."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/pandas_df/#extracting-directly-to-a-dataframe)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/pandas_df.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/pandas_df.md \"View source of this page\")\n\n# Extracting directly to a DataFrame [¶](https://python.useinstructor.com/examples/pandas_df/\\#extracting-directly-to-a-dataframe \"Permanent link\")\n\nIn this example we'll show you how to extract directly to a `pandas.DataFrame`\n\n```md-code__content\nfrom io import StringIO\nfrom typing import Annotated, Any\nfrom pydantic import (\n    BaseModel,\n    BeforeValidator,\n    PlainSerializer,\n    InstanceOf,\n    WithJsonSchema,\n)\nimport pandas as pd\nimport instructor\nimport openai\n\ndef md_to_df(data: Any) -> Any:\n    # Convert markdown to DataFrame\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),  # Process data\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .applymap(lambda x: x.strip())\n        )\n    return data\n\nMarkdownDataFrame = Annotated[\\\n    # Validates final type\\\n    InstanceOf[pd.DataFrame],\\\n    # Converts markdown to DataFrame\\\n    BeforeValidator(md_to_df),\\\n    # Converts DataFrame to markdown on model_dump_json\\\n    PlainSerializer(lambda df: df.to_markdown()),\\\n    # Adds a description to the type\\\n    WithJsonSchema(\\\n        {\\\n            \"type\": \"string\",\\\n            \"description\": \"\"\"\\\n            The markdown representation of the table,\\\n            each one should be tidy, do not try to join\\\n            tables that should be seperate\"\"\",\\\n        }\\\n    ),\\\n]\n\nclient = instructor.from_openai(openai.OpenAI())\n\ndef extract_df(data: str) -> pd.DataFrame:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=MarkdownDataFrame,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a data extraction system, table of writing perfectly formatted markdown tables.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Extract the data into a table: {data}\",\\\n            },\\\n        ],\n    )\n\nclass Table(BaseModel):\n    title: str\n    data: MarkdownDataFrame\n\ndef extract_table(data: str) -> Table:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Table,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a data extraction system, table of writing perfectly formatted markdown tables.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Extract the data into a table: {data}\",\\\n            },\\\n        ],\n    )\n\nif __name__ == \"__main__\":\n    df = extract_df(\n        \"\"\"Create a table of the last 5 presidents of the United States,\n        including their party and the years they served.\"\"\"\n    )\n    assert isinstance(df, pd.DataFrame)\n    print(df)\n    \"\"\"\n                         Party          Years Served\n     President\n    Joe Biden                  Democrat  2021 - Present\n    Donald Trump             Republican     2017 - 2021\n    Barack Obama               Democrat     2009 - 2017\n    George W. Bush           Republican     2001 - 2009\n    Bill Clinton               Democrat     1993 - 2001\n    \"\"\"\n\n    table = extract_table(\n        \"\"\"Create a table of the last 5 presidents of the United States,\n        including their party and the years they served.\"\"\"\n    )\n    assert isinstance(table, Table)\n    assert isinstance(table.data, pd.DataFrame)\n    print(table.title)\n    #> Last 5 Presidents of the United States\n    print(table.data)\n    \"\"\"\n                         Party  Years Served\n     President\n    Joe Biden        Democratic     2021-2025\n    Donald Trump     Republican     2017-2021\n    Barack Obama     Democratic     2009-2017\n    George W. Bush   Republican     2001-2009\n    Bill Clinton     Democratic     1993-2001\n    \"\"\"\n\n```\n\nNotice that you can extract both the raw `MarkdownDataFrame` or a more complex structure like `Table` which includes a title and the data as a DataFrame. You can even request `Iterable[Table]` to get multiple tables in a single response!\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/pandas_df/",
      "ogUrl": "https://python.useinstructor.com/examples/pandas_df/",
      "title": "Extracting DataFrames from Markdown using Pandas - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/pandas_df/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/pandas_df.png",
      "ogTitle": "Extracting DataFrames from Markdown using Pandas - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/pandas_df.png",
      "og:title": "Extracting DataFrames from Markdown using Pandas - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/pandas_df/",
      "statusCode": 200,
      "description": "Learn how to extract and convert Markdown tables directly into Pandas DataFrames in Python.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to extract and convert Markdown tables directly into Pandas DataFrames in Python.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/pandas_df.png",
      "twitter:title": "Extracting DataFrames from Markdown using Pandas - Instructor",
      "og:description": "Learn how to extract and convert Markdown tables directly into Pandas DataFrames in Python.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to extract and convert Markdown tables directly into Pandas DataFrames in Python."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/multi_modal_gemini/#using-gemini-with-multi-modal-data)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/multi_modal_gemini.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/multi_modal_gemini.md \"View source of this page\")\n\n# Using Gemini with Multi Modal Data [¶](https://python.useinstructor.com/examples/multi_modal_gemini/\\#using-gemini-with-multi-modal-data \"Permanent link\")\n\nThis tutorial shows how to use `instructor` with `google-generativeai` to work with multi-modal data. In this example, we'll demonstrate three ways to work with audio files.\n\nWe'll be using this [recording](https://storage.googleapis.com/generativeai-downloads/data/State_of_the_Union_Address_30_January_1961.mp3) that's taken from the [Google Generative AI cookbook](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb).\n\n## Normal Message [¶](https://python.useinstructor.com/examples/multi_modal_gemini/\\#normal-message \"Permanent link\")\n\nThe first way to work with audio files is to upload the entire audio file and pass it into the LLM as a normal message. This is the easiest way to get started and doesn't require any special setup.\n\n```md-code__content\n\n```\n\n1. Make sure to set the mode to `GEMINI_JSON`, this is important because Tool Calling doesn't work with multi-modal inputs.\n2. Use `genai.upload_file` to upload your file. If you've already uploaded the file, you can get it by using `genai.get_file`\n3. Pass in the file object as any normal user message\n\n## Inline Audio Segment [¶](https://python.useinstructor.com/examples/multi_modal_gemini/\\#inline-audio-segment \"Permanent link\")\n\nMaximum File Size\n\nWhen uploading and working with audio, there is a maximum file size that we can upload to the api as an inline segment. You'll know when this error is thrown below.\n\n```md-code__content\ngoogle.api_core.exceptions.InvalidArgument: 400 Request payload size exceeds the limit: 20971520 bytes. Please upload your files with the File API instead.`f = genai.upload_file(path); m.generate_content(['tell me about this file:', f])`\n\n```\n\nWhen it comes to video files, we recommend using the file.upload method as shown in the example above.\n\nSecondly, we can also pass in a audio segment as a normal message as an inline object as shown below. This requires you to install the `pydub` library in order to do so.\n\n```md-code__content\nimport instructor\nimport google.generativeai as genai\nfrom pydantic import BaseModel\nfrom pydub import AudioSegment\n\nclient = instructor.from_gemini(\n    client=genai.GenerativeModel(\n        model_name=\"models/gemini-1.5-flash-latest\",\n    ),\n    mode=instructor.Mode.GEMINI_JSON,\n)\n\nsound = AudioSegment.from_mp3(\"sample.mp3\")\nsound = sound[:60000]\n\nclass Transcription(BaseModel):\n    summary: str\n    exact_transcription: str\n\nresp = client.create(\n    response_model=Transcription,\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": \"Please transcribe this recording\",\\\n        },\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": {\\\n                \"mime_type\": \"audio/mp3\",\\\n                \"data\": sound.export().read(),\\\n            },\\\n        },\\\n    ],\n)\n\nprint(resp)\n\"\"\"\nsummary='President addresses the joint session of Congress,  reflecting on his first time taking the oath of federal office and the knowledge and inspiration gained.' exact_transcription=\"The President's state of the union address to a joint session of the Congress from the rostrum of the House of Representatives, Washington D.C. January 30th 1961 Speaker, Mr Vice President members of the Congress It is a pleasure to return from whence I came You are among my oldest friends in Washington And this house is my oldest home It was here it was here more than 14 years ago that I first took the oath of federal office It was here for 14 years that I gained both knowledge and inspiration from members of both\"\n\"\"\"\n\n#> summary='President delivers a speech to a joint session of Congress,\n#> highlighting his history in the House of Representatives and thanking\n#> the members of Congress for their guidance.',\n# >\n#> exact_transcription=\"The President's State of the Union address to a\n#> joint session of the Congress from the rostrum of the House of\n#> Representatives, Washington DC, January 30th 1961. Mr. Speaker, Mr.\n#> Vice-President, members of the Congress, it is a pleasure to return\n#> from whence I came. You are among my oldest friends in Washington,\n#> and this house is my oldest home. It was here that I first took the\n#> oath of federal office. It was here for 14 years that I gained both\n#> knowledge and inspiration from members of both\"\n\n```\n\n## Lists of Content [¶](https://python.useinstructor.com/examples/multi_modal_gemini/\\#lists-of-content \"Permanent link\")\n\nWe also support passing in these as a single list as per the documentation for `google-generativeai`. Here's how to do so with a audio segment snippet from the same recording.\n\nNote that the list can contain normal user messages as well as file objects. It's incredibly flexible.\n\n```md-code__content\nimport instructor\nimport google.generativeai as genai\nfrom pydantic import BaseModel\n\nclient = instructor.from_gemini(\n    client=genai.GenerativeModel(\n        model_name=\"models/gemini-1.5-flash-latest\",\n    ),\n    mode=instructor.Mode.GEMINI_JSON,\n)\n\nmp3_file = genai.upload_file(\"./sample.mp3\")\n\nclass Description(BaseModel):\n    description: str\n\ncontent = [\\\n    \"Summarize what's happening in this audio file and who the main speaker is\",\\\n    mp3_file,\\\n]\n\nresp = client.create(\n    response_model=Description,\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": content,\\\n        }\\\n    ],\n)\n\nprint(resp)\n\"\"\"\ndescription = 'President John F. Kennedy delivers his State of the Union address to the Congress on January 30, 1961. The speech was delivered at the rostrum of the House of Representatives in Washington, D.C.'\n\"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/multi_modal_gemini/",
      "ogUrl": "https://python.useinstructor.com/examples/multi_modal_gemini/",
      "title": "Utilizing Gemini for Multi-Modal Data Processing with Audio Files - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/multi_modal_gemini/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/multi_modal_gemini.png",
      "ogTitle": "Utilizing Gemini for Multi-Modal Data Processing with Audio Files - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/multi_modal_gemini.png",
      "og:title": "Utilizing Gemini for Multi-Modal Data Processing with Audio Files - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/multi_modal_gemini/",
      "statusCode": 200,
      "description": "Learn how to use Gemini with Google Generative AI to process audio files efficiently in multi-modal applications.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use Gemini with Google Generative AI to process audio files efficiently in multi-modal applications.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/multi_modal_gemini.png",
      "twitter:title": "Utilizing Gemini for Multi-Modal Data Processing with Audio Files - Instructor",
      "og:description": "Learn how to use Gemini with Google Generative AI to process audio files efficiently in multi-modal applications.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use Gemini with Google Generative AI to process audio files efficiently in multi-modal applications."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/self_critique/#self-correction-with-llm_validator)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/self_critique.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/self_critique.md \"View source of this page\")\n\n# Self-Correction with `llm_validator` [¶](https://python.useinstructor.com/examples/self_critique/\\#self-correction-with-llm_validator \"Permanent link\")\n\n## Introduction [¶](https://python.useinstructor.com/examples/self_critique/\\#introduction \"Permanent link\")\n\nThis guide demonstrates how to use `llm_validator` for implementing self-healing. The objective is to showcase how an instructor can self-correct by using validation errors and helpful error messages.\n\n```md-code__content\nfrom openai import OpenAI\nfrom pydantic import BaseModel\nimport instructor\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\nclass QuestionAnswer(BaseModel):\n    question: str\n    answer: str\n\nquestion = \"What is the meaning of life?\"\ncontext = \"The according to the devil the meaning of live is to live a life of sin and debauchery.\"\n\nqa: QuestionAnswer = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    response_model=QuestionAnswer,\n    messages=[\\\n        {\\\n            \"role\": \"system\",\\\n            \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\\\n        },\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\\\n        },\\\n    ],\n)\n\n```\n\n### Output Before Validation [¶](https://python.useinstructor.com/examples/self_critique/\\#output-before-validation \"Permanent link\")\n\nWhile it calls out the objectionable content, it doesn't provide any details on how to correct it.\n\n```md-code__content\n{\n  \"question\": \"What is the meaning of life?\",\n  \"answer\": \"The meaning of life, according to the context, is to live a life of sin and debauchery.\"\n}\n\n```\n\n## Adding Custom Validation [¶](https://python.useinstructor.com/examples/self_critique/\\#adding-custom-validation \"Permanent link\")\n\nBy adding a validator to the `answer` field, we can try to catch the issue and correct it. Lets integrate `llm_validator` into the model and see the error message. Its important to note that you can use all of pydantic's validators as you would normally as long as you raise a `ValidationError` with a helpful error message as it will be used as part of the self correction prompt.\n\n```md-code__content\nfrom pydantic import BaseModel, BeforeValidator\nfrom typing_extensions import Annotated\nfrom instructor import llm_validator\nfrom openai import OpenAI\nimport instructor\n\nclient = instructor.from_openai(OpenAI())\n\nclass QuestionAnswerNoEvil(BaseModel):\n    question: str\n    answer: Annotated[\\\n        str,\\\n        BeforeValidator(\\\n            llm_validator(\\\n                \"don't say objectionable things\", client=client, allow_override=True\\\n            )\\\n        ),\\\n    ]\n\ntry:\n    qa: QuestionAnswerNoEvil = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=QuestionAnswerNoEvil,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\\\n            },\\\n        ],\n    )\nexcept Exception as e:\n    print(e)\n    #> name 'context' is not defined\n\n```\n\n### Output After Validation [¶](https://python.useinstructor.com/examples/self_critique/\\#output-after-validation \"Permanent link\")\n\nNow, we throw validation error that its objectionable and provide a helpful error message.\n\n```md-code__content\n1 validation error for QuestionAnswerNoEvil\nanswer\n  Assertion failed, The statement promotes sin and debauchery, which is objectionable.\n\n```\n\n## Retrying with Corrections [¶](https://python.useinstructor.com/examples/self_critique/\\#retrying-with-corrections \"Permanent link\")\n\nBy adding the `max_retries` parameter, we can retry the request with corrections. and use the error message to correct the output.\n\n```md-code__content\nqa: QuestionAnswerNoEvil = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    response_model=QuestionAnswerNoEvil,\n    messages=[\\\n        {\\\n            \"role\": \"system\",\\\n            \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\\\n        },\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\\\n        },\\\n    ],\n)\n\n```\n\n### Final Output [¶](https://python.useinstructor.com/examples/self_critique/\\#final-output \"Permanent link\")\n\nNow, we get a valid response that is not objectionable!\n\n```md-code__content\n{\n  \"question\": \"What is the meaning of life?\",\n  \"answer\": \"The meaning of life is subjective and can vary depending on individual beliefs and philosophies.\"\n}\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/self_critique/",
      "ogUrl": "https://python.useinstructor.com/examples/self_critique/",
      "title": "Implementing Self-Correction with LLM Validator - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/self_critique/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/self_critique.png",
      "ogTitle": "Implementing Self-Correction with LLM Validator - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/self_critique.png",
      "og:title": "Implementing Self-Correction with LLM Validator - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/self_critique/",
      "statusCode": 200,
      "description": "Learn how to use llm_validator for self-healing in NLP applications and improve response accuracy with validation errors.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use llm_validator for self-healing in NLP applications and improve response accuracy with validation errors.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/self_critique.png",
      "twitter:title": "Implementing Self-Correction with LLM Validator - Instructor",
      "og:description": "Learn how to use llm_validator for self-healing in NLP applications and improve response accuracy with validation errors.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use llm_validator for self-healing in NLP applications and improve response accuracy with validation errors."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/planning-tasks/#planning-and-executing-a-query-plan)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/planning-tasks.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/planning-tasks.md \"View source of this page\")\n\n* * *\n\ntitle: Query Planning with OpenAI: A Step-by-Step Guide description: Learn how to effectively plan and execute complex query plans using OpenAI's Function Call model for systematic information gathering.\n\n* * *\n\n# Planning and Executing a Query Plan [¶](https://python.useinstructor.com/examples/planning-tasks/\\#planning-and-executing-a-query-plan \"Permanent link\")\n\nThis example demonstrates how to use the OpenAI Function Call ChatCompletion model to plan and execute a query plan in a question-answering system. By breaking down a complex question into smaller sub-questions with defined dependencies using [lists](https://python.useinstructor.com/concepts/lists/), the system can systematically gather the necessary information to answer the main question similar to [knowledge graph extraction](https://python.useinstructor.com/examples/knowledge_graph/).\n\nMotivation\n\nThe goal of this example is to showcase how query planning can be used to handle complex questions, facilitate iterative information gathering, automate workflows, and optimize processes. By leveraging the OpenAI Function Call model, you can design and execute a structured plan to find answers effectively.\n\n**Use Cases:**\n\n- Complex question answering\n- Iterative information gathering\n- Workflow automation\n- Process optimization\n\nWith the OpenAI Function Call model, you can customize the planning process and integrate it into your specific application to meet your unique requirements.\n\n## Defining the Structures [¶](https://python.useinstructor.com/examples/planning-tasks/\\#defining-the-structures \"Permanent link\")\n\nLet's define the necessary Pydantic models to represent the query plan and the queries.\n\n```md-code__content\nfrom typing import List, Literal\nfrom pydantic import Field, BaseModel\n\nclass Query(BaseModel):\n    \"\"\"Class representing a single question in a query plan.\"\"\"\n\n    id: int = Field(..., description=\"Unique id of the query\")\n    question: str = Field(\n        ...,\n        description=\"Question asked using a question answering system\",\n    )\n    dependencies: List[int] = Field(\n        default_factory=list,\n        description=\"List of sub questions that need to be answered before asking this question\",\n    )\n    node_type: Literal[\"SINGLE\", \"MERGE_MULTIPLE_RESPONSES\"] = Field(\n        default=\"SINGLE\",\n        description=\"Type of question, either a single question or a multi-question merge\",\n    )\n\nclass QueryPlan(BaseModel):\n    \"\"\"Container class representing a tree of questions to ask a question answering system.\"\"\"\n\n    query_graph: List[Query] = Field(\n        ..., description=\"The query graph representing the plan\"\n    )\n\n    def _dependencies(self, ids: List[int]) -> List[Query]:\n        \"\"\"Returns the dependencies of a query given their ids.\"\"\"\n        return [q for q in self.query_graph if q.id in ids]\n\n```\n\nGraph Generation\n\nNotice that this example produces a flat list of items with dependencies that resemble a graph, while pydantic allows for recursive definitions, it's much easier and less confusing for the model to generate flat schemas rather than recursive schemas. If you want to see a recursive example, see [recursive schemas](https://python.useinstructor.com/examples/recursive/)\n\n## Planning a Query Plan [¶](https://python.useinstructor.com/examples/planning-tasks/\\#planning-a-query-plan \"Permanent link\")\n\nNow, let's demonstrate how to plan and execute a query plan using the defined models and the OpenAI API.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\ndef query_planner(question: str) -> QueryPlan:\n    PLANNING_MODEL = \"gpt-4o-mini\"\n\n    messages = [\\\n        {\\\n            \"role\": \"system\",\\\n            \"content\": \"You are a world class query planning algorithm capable ofbreaking apart questions into its dependency queries such that the answers can be used to inform the parent question. Do not answer the questions, simply provide a correct compute graph with good specific questions to ask and relevant dependencies. Before you call the function, think step-by-step to get a better understanding of the problem.\",\\\n        },\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": f\"Consider: {question}\\nGenerate the correct query plan.\",\\\n        },\\\n    ]\n\n    root = client.chat.completions.create(\n        model=PLANNING_MODEL,\n        temperature=0,\n        response_model=QueryPlan,\n        messages=messages,\n        max_tokens=1000,\n    )\n    return root\n\n```\n\n```md-code__content\nplan = query_planner(\n    \"What is the difference in populations of Canada and the Jason's home country?\"\n)\nplan.model_dump()\n\n```\n\nNo RAG\n\nWhile we build the query plan in this example, we do not propose a method to actually answer the question. You can implement your own answer function that perhaps makes a retrieval and calls openai for retrieval augmented generation. That step would also make use of function calls but goes beyond the scope of this example.\n\n```md-code__content\n{\n    \"query_graph\": [\\\n        {\\\n            \"dependencies\": [],\\\n            \"id\": 1,\\\n            \"node_type\": \"SINGLE\",\\\n            \"question\": \"Identify Jason's home country\",\\\n        },\\\n        {\\\n            \"dependencies\": [],\\\n            \"id\": 2,\\\n            \"node_type\": \"SINGLE\",\\\n            \"question\": \"Find the population of Canada\",\\\n        },\\\n        {\\\n            \"dependencies\": [1],\\\n            \"id\": 3,\\\n            \"node_type\": \"SINGLE\",\\\n            \"question\": \"Find the population of Jason's home country\",\\\n        },\\\n        {\\\n            \"dependencies\": [2, 3],\\\n            \"id\": 4,\\\n            \"node_type\": \"SINGLE\",\\\n            \"question\": \"Calculate the difference in populations between Canada and Jasons home country\",\\\n        },\\\n    ]\n}\n\n```\n\nIn the above code, we define a `query_planner` function that takes a question as input and generates a query plan using the OpenAI API.\n\n## Conclusion [¶](https://python.useinstructor.com/examples/planning-tasks/\\#conclusion \"Permanent link\")\n\nIn this example, we demonstrated how to use the OpenAI Function Call `ChatCompletion` model to plan a query using a question-answering system. We defined the necessary structures using Pydantic and created a query planner function that generates a structured plan for answering complex questions.\n\nThe query planner breaks down the main question into smaller, manageable sub-questions, establishing dependencies between them. This approach allows for a systematic and organized way to tackle multi-step queries.\n\nFor more advanced implementations and variations of this concept, you can explore:\n\n1. [Query planning and execution example](https://github.com/jxnl/instructor/blob/main/examples/query_planner_execution/query_planner_execution.py)\n2. [Task planning with topological sort](https://github.com/jxnl/instructor/blob/main/examples/task_planner/task_planner_topological_sort.py)\n\nThese examples provide additional insights into how you can leverage structured outputs for complex query planning and task management.\n\nFeel free to adapt this code to your specific use cases and explore the possibilities of using OpenAI Function Calls to plan and structure complex workflows in your applications.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/planning-tasks/",
      "ogUrl": "https://python.useinstructor.com/examples/planning-tasks/",
      "title": "RAG Query Planning - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/planning-tasks/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/planning-tasks.png",
      "ogTitle": "RAG Query Planning - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/planning-tasks.png",
      "og:title": "RAG Query Planning - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/planning-tasks/",
      "statusCode": 200,
      "description": "A lightweight library for structured outputs with LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "A lightweight library for structured outputs with LLMs.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/planning-tasks.png",
      "twitter:title": "RAG Query Planning - Instructor",
      "og:description": "A lightweight library for structured outputs with LLMs.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "A lightweight library for structured outputs with LLMs."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/extracting_tables/#extracting-tables-using-gpt-vision)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/extracting_tables.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/extracting_tables.md \"View source of this page\")\n\n# Extracting Tables using GPT-Vision [¶](https://python.useinstructor.com/examples/extracting_tables/\\#extracting-tables-using-gpt-vision \"Permanent link\")\n\nThis post demonstrates how to use Python's type annotations and OpenAI's new vision model to extract tables from images and convert them into markdown format. This method is particularly useful for data analysis and automation tasks.\n\nThe full code is available on [GitHub](https://github.com/jxnl/instructor/blob/main/examples/vision/run_table.py)\n\n## Building the Custom Type for Markdown Tables [¶](https://python.useinstructor.com/examples/extracting_tables/\\#building-the-custom-type-for-markdown-tables \"Permanent link\")\n\nFirst, we define a custom type, `MarkdownDataFrame`, to handle pandas DataFrames formatted in markdown. This type uses Python's `Annotated` and `InstanceOf` types, along with decorators `BeforeValidator` and `PlainSerializer`, to process and serialize the data.\n\n```\nfrom io import StringIO\nfrom typing import Annotated, Any\nfrom pydantic import BeforeValidator, PlainSerializer, InstanceOf, WithJsonSchema\nimport pandas as pd\n\ndef md_to_df(data: Any) -> Any:\n    # Convert markdown to DataFrame\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),  # Process data\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .applymap(lambda x: x.strip())\n        )\n    return data\n\nMarkdownDataFrame = Annotated[\\\n    InstanceOf[pd.DataFrame],\\\n    BeforeValidator(md_to_df),\\\n    PlainSerializer(lambda df: df.to_markdown()),\\\n    WithJsonSchema(\\\n        {\\\n            \"type\": \"string\",\\\n            \"description\": \"The markdown representation of the table, each one should be tidy, do not try to join tables that should be seperate\",\\\n        }\\\n    ),\\\n]\n\n```\n\n## Defining the Table Class [¶](https://python.useinstructor.com/examples/extracting_tables/\\#defining-the-table-class \"Permanent link\")\n\nThe `Table` class is essential for organizing the extracted data. It includes a caption and a dataframe, processed as a markdown table. Since most of the complexity is handled by the `MarkdownDataFrame` type, the `Table` class is straightforward!\n\n```\nfrom pydantic import BaseModel\n\nclass Table(BaseModel):\n    caption: str\n    dataframe: MarkdownDataFrame\n\n```\n\n## Extracting Tables from Images [¶](https://python.useinstructor.com/examples/extracting_tables/\\#extracting-tables-from-images \"Permanent link\")\n\nThe `extract_table` function uses OpenAI's vision model to process an image URL and extract tables in markdown format. We utilize the `instructor` library to patch the OpenAI client for this purpose.\n\n```\nimport instructor\nfrom openai import OpenAI\nfrom typing import Iterable\n\n# Apply the patch to the OpenAI client to support response_model\n# Also use MD_JSON mode since the vision model does not support any special structured output mode\nclient = instructor.from_openai(OpenAI(), mode=instructor.function_calls.Mode.MD_JSON)\n\ndef extract_table(url: str) -> Iterable[Table]:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=Iterable[Table],\n        max_tokens=1800,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": [\\\n                    {\"type\": \"text\", \"text\": \"Extract table from image.\"},\\\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": url}},\\\n                ],\\\n            }\\\n        ],\n    )\n\n```\n\n## Practical Example [¶](https://python.useinstructor.com/examples/extracting_tables/\\#practical-example \"Permanent link\")\n\nIn this example, we apply the method to extract data from an image showing the top grossing apps in Ireland for October 2023.\n\n```\nurl = \"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\"\ntables = extract_table(url)\nfor table in tables:\n\n    print(table.dataframe)\n    \"\"\"\n                                      Android App   ... Category\n     Android Rank                                   ...\n    1                                   Google One  ...    Social networking\n    2                                      Disney+  ...        Entertainment\n    3                TikTok - Videos, Music & LIVE  ...        Entertainment\n    4                             Candy Crush Saga  ...        Entertainment\n    5               Tinder: Dating, Chat & Friends  ...                Games\n    6                                  Coin Master  ...        Entertainment\n    7                                       Roblox  ...               Dating\n    8               Bumble - Dating & Make Friends  ...                Games\n    9                                  Royal Match  ...             Business\n    10                 Spotify: Music and Podcasts  ...            Education\n\n    [10 rows x 5 columns]\n    \"\"\"\n\n```\n\nExpand to see the output\n\n![Top 10 Grossing Apps in October 2023 for Ireland](https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png)\n\n### Top 10 Grossing Apps in October 2023 (Ireland) for Android Platforms [¶](https://python.useinstructor.com/examples/extracting_tables/\\#top-10-grossing-apps-in-october-2023-ireland-for-android-platforms \"Permanent link\")\n\n| Rank | App Name | Category |\n| --- | --- | --- |\n| 1 | Google One | Productivity |\n| 2 | Disney+ | Entertainment |\n| 3 | TikTok - Videos, Music & LIVE | Entertainment |\n| 4 | Candy Crush Saga | Games |\n| 5 | Tinder: Dating, Chat & Friends | Social networking |\n| 6 | Coin Master | Games |\n| 7 | Roblox | Games |\n| 8 | Bumble - Dating & Make Friends | Dating |\n| 9 | Royal Match | Games |\n| 10 | Spotify: Music and Podcasts | Music & Audio |\n\n### Top 10 Grossing Apps in October 2023 (Ireland) for iOS Platforms [¶](https://python.useinstructor.com/examples/extracting_tables/\\#top-10-grossing-apps-in-october-2023-ireland-for-ios-platforms \"Permanent link\")\n\n| Rank | App Name | Category |\n| --- | --- | --- |\n| 1 | Tinder: Dating, Chat & Friends | Social networking |\n| 2 | Disney+ | Entertainment |\n| 3 | YouTube: Watch, Listen, Stream | Entertainment |\n| 4 | Audible: Audio Entertainment | Entertainment |\n| 5 | Candy Crush Saga | Games |\n| 6 | TikTok - Videos, Music & LIVE | Entertainment |\n| 7 | Bumble - Dating & Make Friends | Dating |\n| 8 | Roblox | Games |\n| 9 | LinkedIn: Job Search & News | Business |\n| 10 | Duolingo - Language Lessons | Education |\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/extracting_tables/",
      "ogUrl": "https://python.useinstructor.com/examples/extracting_tables/",
      "title": "Extracting Tables from Images using GPT-Vision - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/extracting_tables/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/extracting_tables.png",
      "ogTitle": "Extracting Tables from Images using GPT-Vision - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/extracting_tables.png",
      "og:title": "Extracting Tables from Images using GPT-Vision - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/extracting_tables/",
      "statusCode": 200,
      "description": "Learn how to use Python and GPT-Vision to extract and convert tables from images into markdown for data analysis.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use Python and GPT-Vision to extract and convert tables from images into markdown for data analysis.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/extracting_tables.png",
      "twitter:title": "Extracting Tables from Images using GPT-Vision - Instructor",
      "og:description": "Learn how to use Python and GPT-Vision to extract and convert tables from images into markdown for data analysis.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use Python and GPT-Vision to extract and convert tables from images into markdown for data analysis."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/local_classification/#leveraging-local-models-for-classifying-private-data)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/local_classification.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/local_classification.md \"View source of this page\")\n\n# Leveraging Local Models for Classifying Private Data [¶](https://python.useinstructor.com/examples/local_classification/\\#leveraging-local-models-for-classifying-private-data \"Permanent link\")\n\nIn this article, we'll show you how to use Llama-cpp-python with instructor for classification. This is a perfect use-case for users who want to ensure that confidential documents are handled securely without ever leaving your own infrastructure.\n\n## Setup [¶](https://python.useinstructor.com/examples/local_classification/\\#setup \"Permanent link\")\n\nLet's start by installing the required libraries in your local python environment. This might take a while since we'll need to build and compile `llama-cpp` for your specific environment.\n\n```md-code__content\npip install instructor pydantic\n\n```\n\nNext, we'll install `llama-cpp-python` which is a python package that allows us to use llama-cpp with our python scripts.\n\nFor this tutorial, we'll be using `Mistral-7B-Instruct-v0.2-GGUF` by `TheBloke` to do our function calls. This will require around 6GB of RAM and a GPU.\n\nWe can install the package by running the following command\n\n```md-code__content\nCMAKE_ARGS=\"-DGGML_CUDA=on\" pip install llama-cpp-python\n\n```\n\nDon't have a GPU?\n\nIf you don't have a GPU, we recommend using the `Qwen2-0.5B-Instruct` model instead and compiling llama-cpp-python to use `OpenBLAS`. This allows you to run the program using your CPU instead.\n\nYou can compile `llama-cpp-python` with `OpenBLAS` support by running the command\n\n```md-code__content\nCMAKE_ARGS=\"-DGGML_BLAS=ON -DGGML_BLAS_VENDOR=OpenBLAS\" pip install llama-cpp-python\n\n```\n\n## Using `LLama-cpp-python` [¶](https://python.useinstructor.com/examples/local_classification/\\#using-llama-cpp-python \"Permanent link\")\n\nHere's an example of how to implement a system for handling confidential document queries using local models:\n\n```md-code__content\nfrom llama_cpp import Llama  # type: ignore\nimport instructor\nfrom pydantic import BaseModel\nfrom enum import Enum\nfrom typing import Optional\n\nllm = Llama.from_pretrained(  # type: ignore\n    repo_id=\"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\",\n    filename=\"*Q4_K_M.gguf\",\n    verbose=False,\n    n_gpu_layers=-1,\n)\n\ncreate = instructor.patch(\n    create=llm.create_chat_completion_openai_v1,\n)\n\n# Define query types for document-related inquiries\nclass QueryType(str, Enum):\n    DOCUMENT_CONTENT = \"document_content\"\n    LAST_MODIFIED = \"last_modified\"\n    ACCESS_PERMISSIONS = \"access_permissions\"\n    RELATED_DOCUMENTS = \"related_documents\"\n\n# Define the structure for query responses\nclass QueryResponse(BaseModel):\n    query_type: QueryType\n    response: str\n    additional_info: Optional[str] = None\n\ndef process_confidential_query(query: str) -> QueryResponse:\n    prompt = f\"\"\"Analyze the following confidential document query and provide an appropriate response:\n    Query: {query}\n\n    Determine the type of query (document content, last modified, access permissions, or related documents),\n    provide a response, and include a confidence score and any additional relevant information.\n    Remember, you're handling confidential data, so be cautious about specific details.\n    \"\"\"\n\n    return create(\n        response_model=QueryResponse,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a secure AI assistant trained to handle confidential document queries.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": prompt},\\\n        ],\n    )\n\n# Sample confidential document queries\nconfidential_queries = [\\\n    \"What are the key findings in the Q4 financial report?\",\\\n    \"Who last accessed the merger proposal document?\",\\\n    \"What are the access permissions for the new product roadmap?\",\\\n    \"Are there any documents related to Project X's budget forecast?\",\\\n    \"When was the board meeting minutes document last updated?\",\\\n]\n\n# Process each query and print the results\nfor query in confidential_queries:\n    response: QueryResponse = process_confidential_query(query)\n    print(f\"{query} : {response.query_type}\")\n    \"\"\"\n    #> What are the key findings in the Q4 financial report? : document_content\n    #> Who last accessed the merger proposal document? : access_permissions\n    #> What are the access permissions for the new product roadmap? : access_permissions\n    #> Are there any documents related to Project X's budget forecast? : document_content\n    #> When was the board meeting minutes document last updated? : last_modified\n    \"\"\"\n\n```\n\n## Conclusion [¶](https://python.useinstructor.com/examples/local_classification/\\#conclusion \"Permanent link\")\n\n`instructor` provides a robust solution for organizations needing to handle confidential document queries locally. By processing these queries on your own hardware, you can leverage advanced AI capabilities while maintaining the highest standards of data privacy and security.\n\nBut this goes far beyond just simple confidential documents, using local models unlocks a whole new world of interesting use-cases, fine-tuned specialist models and more!\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/local_classification/",
      "ogUrl": "https://python.useinstructor.com/examples/local_classification/",
      "title": "Classifying Confidential Data with Local AI Models - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/local_classification/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/local_classification.png",
      "ogTitle": "Classifying Confidential Data with Local AI Models - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/local_classification.png",
      "og:title": "Classifying Confidential Data with Local AI Models - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/local_classification/",
      "statusCode": 200,
      "description": "Learn to classify private documents securely using Llama-cpp-python with instructor while maintaining data privacy and local infrastructure.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to classify private documents securely using Llama-cpp-python with instructor while maintaining data privacy and local infrastructure.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/local_classification.png",
      "twitter:title": "Classifying Confidential Data with Local AI Models - Instructor",
      "og:description": "Learn to classify private documents securely using Llama-cpp-python with instructor while maintaining data privacy and local infrastructure.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to classify private documents securely using Llama-cpp-python with instructor while maintaining data privacy and local infrastructure."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/extract_slides/#data-extraction-from-slides)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/extract_slides.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/extract_slides.md \"View source of this page\")\n\n# Data extraction from slides [¶](https://python.useinstructor.com/examples/extract_slides/\\#data-extraction-from-slides \"Permanent link\")\n\nIn this guide, we demonstrate how to extract data from slides.\n\nMotivation\n\nWhen we want to translate key information from slides into structured data, simply isolating the text and running extraction might not be enough. Sometimes the important data is in the images on the slides, so we should consider including them in our extraction pipeline.\n\n## Defining the necessary Data Structures [¶](https://python.useinstructor.com/examples/extract_slides/\\#defining-the-necessary-data-structures \"Permanent link\")\n\nLet's say we want to extract the competitors from various presentations and categorize them according to their respective industries.\n\nOur data model will have `Industry` which will be a list of `Competitor`'s for a specific industry, and `Competition` which will aggregate the competitors for all the industries.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\nclass Competitor(BaseModel):\n    name: str\n    features: Optional[List[str]]\n\n# Define models\nclass Industry(BaseModel):\n    \"\"\"\n    Represents competitors from a specific industry extracted from an image using AI.\n    \"\"\"\n\n    name: str = Field(description=\"The name of the industry\")\n    competitor_list: List[Competitor] = Field(\n        description=\"A list of competitors for this industry\"\n    )\n\nclass Competition(BaseModel):\n    \"\"\"\n    This class serves as a structured representation of\n    competitors and their qualities.\n    \"\"\"\n\n    industry_list: List[Industry] = Field(\n        description=\"A list of industries and their competitors\"\n    )\n\n```\n\n## Competitors extraction [¶](https://python.useinstructor.com/examples/extract_slides/\\#competitors-extraction \"Permanent link\")\n\nTo extract competitors from slides we will define a function which will read images from urls and extract the relevant information from them.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\n# Define functions\ndef read_images(image_urls: List[str]) -> Competition:\n    \"\"\"\n    Given a list of image URLs, identify the competitors in the images.\n    \"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=Competition,\n        max_tokens=2048,\n        temperature=0,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": [\\\n                    {\\\n                        \"type\": \"text\",\\\n                        \"text\": \"Identify competitors and generate key features for each competitor.\",\\\n                    },\\\n                    *[\\\n                        {\"type\": \"image_url\", \"image_url\": {\"url\": url}}\\\n                        for url in image_urls\\\n                    ],\\\n                ],\\\n            }\\\n        ],\n    )\n\n```\n\n## Execution [¶](https://python.useinstructor.com/examples/extract_slides/\\#execution \"Permanent link\")\n\nFinally, we will run the previous function with a few sample slides to see the data extractor in action.\n\nAs we can see, our model extracted the relevant information for each competitor regardless of how this information was formatted in the original presentations.\n\n```md-code__content\nurl = [\\\n    'https://miro.medium.com/v2/resize:fit:1276/0*h1Rsv-fZWzQUyOkt',\\\n]\nmodel = read_images(url)\nprint(model.model_dump_json(indent=2))\n\"\"\"\n{\n  \"industry_list\": [\\\n    {\\\n      \"name\": \"Accommodation Services\",\\\n      \"competitor_list\": [\\\n        {\\\n          \"name\": \"CouchSurfing\",\\\n          \"features\": [\\\n            \"Free accommodation\",\\\n            \"Cultural exchange\",\\\n            \"Community-driven\",\\\n            \"User profiles and reviews\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"Craigslist\",\\\n          \"features\": [\\\n            \"Local listings\",\\\n            \"Variety of accommodation types\",\\\n            \"Direct communication with hosts\",\\\n            \"No booking fees\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"BedandBreakfast.com\",\\\n          \"features\": [\\\n            \"Specialized in B&Bs\",\\\n            \"User reviews\",\\\n            \"Booking options\",\\\n            \"Local experiences\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"AirBed & Breakfast (Airbnb)\",\\\n          \"features\": [\\\n            \"Wide range of accommodations\",\\\n            \"User reviews\",\\\n            \"Instant booking\",\\\n            \"Host profiles\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"Hostels.com\",\\\n          \"features\": [\\\n            \"Budget-friendly hostels\",\\\n            \"User reviews\",\\\n            \"Booking options\",\\\n            \"Global reach\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"RentDigs.com\",\\\n          \"features\": [\\\n            \"Rental listings\",\\\n            \"User-friendly interface\",\\\n            \"Local listings\",\\\n            \"Direct communication with landlords\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"VRBO\",\\\n          \"features\": [\\\n            \"Vacation rentals\",\\\n            \"Family-friendly options\",\\\n            \"User reviews\",\\\n            \"Booking protection\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"Hotels.com\",\\\n          \"features\": [\\\n            \"Wide range of hotels\",\\\n            \"Rewards program\",\\\n            \"User reviews\",\\\n            \"Price match guarantee\"\\\n          ]\\\n        }\\\n      ]\\\n    }\\\n  ]\n}\n\"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/extract_slides/",
      "ogUrl": "https://python.useinstructor.com/examples/extract_slides/",
      "title": "Extracting Competitor Data from Slides Using AI - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/extract_slides/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/extract_slides.png",
      "ogTitle": "Extracting Competitor Data from Slides Using AI - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/extract_slides.png",
      "og:title": "Extracting Competitor Data from Slides Using AI - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/extract_slides/",
      "statusCode": 200,
      "description": "Learn how to extract competitor data from presentation slides, leveraging AI for comprehensive information gathering.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to extract competitor data from presentation slides, leveraging AI for comprehensive information gathering.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/extract_slides.png",
      "twitter:title": "Extracting Competitor Data from Slides Using AI - Instructor",
      "og:description": "Learn how to extract competitor data from presentation slides, leveraging AI for comprehensive information gathering.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to extract competitor data from presentation slides, leveraging AI for comprehensive information gathering."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/search/?q=#example-segmenting-search-queries)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/search.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/search.md \"View source of this page\")\n\n# Example: Segmenting Search Queries [¶](https://python.useinstructor.com/examples/search/?q=\\#example-segmenting-search-queries \"Permanent link\")\n\nIn this example, we will demonstrate how to leverage the `MultiTask` and `enum.Enum` features of OpenAI Function Call to segment search queries. We will define the necessary structures using Pydantic and demonstrate how segment queries into multiple sub queries and execute them in parallel with `asyncio`.\n\nMotivation\n\nExtracting a list of tasks from text is a common use case for leveraging language models. This pattern can be applied to various applications, such as virtual assistants like Siri or Alexa, where understanding user intent and breaking down requests into actionable tasks is crucial. In this example, we will demonstrate how to use OpenAI Function Call to segment search queries and execute them in parallel.\n\n## Structure of the Data [¶](https://python.useinstructor.com/examples/search/?q=\\#structure-of-the-data \"Permanent link\")\n\nThe `Search` class is a Pydantic model that defines the structure of the search query. It has three fields: `title`, `query`, and `type`. The `title` field is the title of the request, the `query` field is the query to search for relevant content, and the `type` field is the type of search. The `execute` method is used to execute the search query.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\nfrom typing import Iterable, Literal\nfrom pydantic import BaseModel, Field\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\nclass Search(BaseModel):\n    query: str = Field(..., description=\"Query to search for relevant content\")\n    type: Literal[\"web\", \"image\", \"video\"] = Field(..., description=\"Type of search\")\n\n    async def execute(self):\n        print(\n            f\"Searching for `{self.title}` with query `{self.query}` using `{self.type}`\"\n        )\n\ndef segment(data: str) -> Search:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=Iterable[Search],\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Consider the data below: '\\n{data}' and segment it into multiple search queries\",\\\n            },\\\n        ],\n        max_tokens=1000,\n    )\n\nfor search in segment(\"Search for a picture of a cat and a video of a dog\"):\n    print(search.model_dump_json())\n    #> {\"query\":\"picture of a cat\",\"type\":\"image\"}\n    #> {\"query\":\"video of a dog\",\"type\":\"video\"}\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/search/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/search/",
      "title": "Segmenting Search Queries with OpenAI and Pydantic - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/search/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/search.png",
      "ogTitle": "Segmenting Search Queries with OpenAI and Pydantic - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/search.png",
      "og:title": "Segmenting Search Queries with OpenAI and Pydantic - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/search/?q=",
      "statusCode": 200,
      "description": "Learn to segment search queries into actionable tasks using OpenAI Function Call and Pydantic for efficient execution.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to segment search queries into actionable tasks using OpenAI Function Call and Pydantic for efficient execution.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/search.png",
      "twitter:title": "Segmenting Search Queries with OpenAI and Pydantic - Instructor",
      "og:description": "Learn to segment search queries into actionable tasks using OpenAI Function Call and Pydantic for efficient execution.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to segment search queries into actionable tasks using OpenAI Function Call and Pydantic for efficient execution."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/knowledge_graph/?q=#visualizing-knowledge-graphs-for-complex-topics)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/knowledge_graph.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/knowledge_graph.md \"View source of this page\")\n\n* * *\n\ntitle: Visualizing Knowledge Graphs: A Guide to Complex Topics description: Learn how to create and update knowledge graphs using Python, OpenAI's API, Pydantic, and Graphviz for enhanced understanding of complex subjects.\n\n* * *\n\n# Visualizing Knowledge Graphs for Complex Topics [¶](https://python.useinstructor.com/examples/knowledge_graph/?q=\\#visualizing-knowledge-graphs-for-complex-topics \"Permanent link\")\n\nIn this guide, you'll discover how to visualise a detailed knowledge graph when dealing with complex topics. We'll then move on to iteratively updating our knowledge graph with new information through a series of sequential api calls using only the Instructor library, Pydantic and Graphviz to visualise our graph.\n\nMotivation\n\nKnowledge graphs offer a visually appealing and coherent way to understand complicated topics like quantum mechanics. By generating these graphs automatically, you can accelerate the learning process and make it easier to digest complex information.\n\n## Defining the Structures [¶](https://python.useinstructor.com/examples/knowledge_graph/?q=\\#defining-the-structures \"Permanent link\")\n\nLet's model a knowledge graph with **`Node`** and **`Edge`** objects. **`Node`** objects represent key concepts or entities, while **`Edge`** objects indicate the relationships between them.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass Node(BaseModel, frozen=True):\n    id: int\n    label: str\n    color: str\n\nclass Edge(BaseModel, frozen=True):\n    source: int\n    target: int\n    label: str\n    color: str = \"black\"\n\nclass KnowledgeGraph(BaseModel):\n    nodes: List[Node] = Field(..., default_factory=list)\n    edges: List[Edge] = Field(..., default_factory=list)\n\n```\n\n## Generating Knowledge Graphs [¶](https://python.useinstructor.com/examples/knowledge_graph/?q=\\#generating-knowledge-graphs \"Permanent link\")\n\nThe **`generate_graph`** function leverages OpenAI's API to generate a knowledge graph based on the input query.\n\n```md-code__content\nfrom openai import OpenAI\nimport instructor\n\n# Adds response_model to ChatCompletion\n# Allows the return of Pydantic model rather than raw JSON\nclient = instructor.from_openai(OpenAI())\n\ndef generate_graph(input) -> KnowledgeGraph:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Help me understand the following by describing it as a detailed knowledge graph: {input}\",\\\n            }\\\n        ],\n        response_model=KnowledgeGraph,\n    )  # type: ignore\n\n```\n\n## Visualizing the Graph [¶](https://python.useinstructor.com/examples/knowledge_graph/?q=\\#visualizing-the-graph \"Permanent link\")\n\nThe **`visualize_knowledge_graph`** function uses the Graphviz library to render the generated knowledge graph.\n\n```md-code__content\nfrom graphviz import Digraph\n\ndef visualize_knowledge_graph(kg: KnowledgeGraph):\n    dot = Digraph(comment=\"Knowledge Graph\")\n\n    # Add nodes\n    for node in kg.nodes:\n        dot.node(str(node.id), node.label, color=node.color)\n\n    # Add edges\n    for edge in kg.edges:\n        dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n\n    # Render the graph\n    dot.render(\"knowledge_graph.gv\", view=True)\n\ngraph = generate_graph(\"Teach me about quantum mechanics\")\nvisualize_knowledge_graph(graph)\n\n```\n\n![Knowledge Graph](https://python.useinstructor.com/examples/knowledge_graph.png)\n\nThis will produce a visual representation of the knowledge graph, stored as \"knowledge\\_graph.gv\". You can open this file to explore the key concepts and their relationships in quantum mechanics.\n\n## Iterative Updates [¶](https://python.useinstructor.com/examples/knowledge_graph/?q=\\#iterative-updates \"Permanent link\")\n\nNow that we've seen how to generate a knowledge graph from a single input, let's see how we can iteratively update our knowledge graph with new information, or when information does not fit into a single prompt.\n\nLet's take an easy example where we want to visualise the combined knowledge graph that the following sentences represent.\n\n```md-code__content\ntext_chunks = [\\\n    \"Jason knows a lot about quantum mechanics. He is a physicist. He is a professor\",\\\n    \"Professors are smart.\",\\\n    \"Sarah knows Jason and is a student of his.\",\\\n    \"Sarah is a student at the University of Toronto. and UofT is in Canada\",\\\n]\n\n```\n\n### Updating Our Data Model [¶](https://python.useinstructor.com/examples/knowledge_graph/?q=\\#updating-our-data-model \"Permanent link\")\n\nTo support our new iterative approach, we need to update our data model. We can do this by adding helper methods `update` and `draw` to our Pydantic models. These methods will simplify our code and allow us to easily visualize the knowledge graph.\n\nIn the `KnowledgeGraph` class, we have migrated the code from the `visualize_knowledge_graph` method and added new lists for nodes and edges.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Node(BaseModel, frozen=True):\n    id: int\n    label: str\n    color: str\n\nclass Edge(BaseModel, frozen=True):\n    source: int\n    target: int\n    label: str\n    color: str = \"black\"\n\nclass KnowledgeGraph(BaseModel):\n    nodes: Optional[List[Node]] = Field(..., default_factory=list)\n    edges: Optional[List[Edge]] = Field(..., default_factory=list)\n\n    def update(self, other: \"KnowledgeGraph\") -> \"KnowledgeGraph\":\n        \"\"\"Updates the current graph with the other graph, deduplicating nodes and edges.\"\"\"\n        return KnowledgeGraph(\n            nodes=list(set(self.nodes + other.nodes)),\n            edges=list(set(self.edges + other.edges)),\n        )\n\n    def draw(self, prefix: str = None):\n        dot = Digraph(comment=\"Knowledge Graph\")\n\n        for node in self.nodes:\n            dot.node(str(node.id), node.label, color=node.color)\n\n        for edge in self.edges:\n            dot.edge(\n                str(edge.source), str(edge.target), label=edge.label, color=edge.color\n            )\n        dot.render(prefix, format=\"png\", view=True)\n\n```\n\nWe can modify our `generate_graph` function to now take in a list of strings. At each step, it'll extract out the key insights from the sentences in the form of edges and nodes like we've seen before. We can then combine these new edges and nodes with our existing knowledge graph through iterative updates to our graph before arriving at our final result.\n\n```md-code__content\nfrom typing import List\n\ndef generate_graph(input: List[str]) -> KnowledgeGraph:\n    cur_state = KnowledgeGraph()\n    num_iterations = len(input)\n    for i, inp in enumerate(input):\n        new_updates = client.chat.completions.create(\n            model=\"gpt-3.5-turbo-16k\",\n            messages=[\\\n                {\\\n                    \"role\": \"system\",\\\n                    \"content\": \"\"\"You are an iterative knowledge graph builder.\\\n                    You are given the current state of the graph, and you must append the nodes and edges\\\n                    to it Do not procide any duplcates and try to reuse nodes as much as possible.\"\"\",\\\n                },\\\n                {\\\n                    \"role\": \"user\",\\\n                    \"content\": f\"\"\"Extract any new nodes and edges from the following:\\\n                    # Part {i}/{num_iterations} of the input:\\\n\\\n                    {inp}\"\"\",\\\n                },\\\n                {\\\n                    \"role\": \"user\",\\\n                    \"content\": f\"\"\"Here is the current state of the graph:\\\n                    {cur_state.model_dump_json(indent=2)}\"\"\",\\\n                },\\\n            ],\n            response_model=KnowledgeGraph,\n        )  # type: ignore\n\n        # Update the current state\n        cur_state = cur_state.update(new_updates)\n        cur_state.draw(prefix=f\"iteration_{i}\")\n    return cur_state\n\n```\n\nOnce we've done this, we can now run this new `generate_graph` function with the following two lines.\n\n```md-code__content\ntext_chunks = [\\\n    \"Jason knows a lot about quantum mechanics. He is a physicist. He is a professor\",\\\n    \"Professors are smart.\",\\\n    \"Sarah knows Jason and is a student of his.\",\\\n    \"Sarah is a student at the University of Toronto. and UofT is in Canada\",\\\n]\ngraph: KnowledgeGraph = generate_graph(text_chunks)\ngraph.draw(prefix=\"final\")\n\n```\n\n## Conclusion [¶](https://python.useinstructor.com/examples/knowledge_graph/?q=\\#conclusion \"Permanent link\")\n\nWe've seen how we can use `Instructor` to obtain structured outputs from the OpenAI LLM API but you could use that for any of the other open-source models that the library is compatible with. If you enjoy the content or want to try out `Instructor` check out the [github](https://github.com/jxnl/instructor) and don't forget to give us a star!\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/knowledge_graph/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/knowledge_graph/",
      "title": "Extracting Knowledge Graphs - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/knowledge_graph/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/knowledge_graph.png",
      "ogTitle": "Extracting Knowledge Graphs - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/knowledge_graph.png",
      "og:title": "Extracting Knowledge Graphs - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/knowledge_graph/?q=",
      "statusCode": 200,
      "description": "A lightweight library for structured outputs with LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "A lightweight library for structured outputs with LLMs.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/knowledge_graph.png",
      "twitter:title": "Extracting Knowledge Graphs - Instructor",
      "og:description": "A lightweight library for structured outputs with LLMs.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "A lightweight library for structured outputs with LLMs."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/pii/?q=#pii-data-extraction-and-scrubbing)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/pii.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/pii.md \"View source of this page\")\n\n# PII Data Extraction and Scrubbing [¶](https://python.useinstructor.com/examples/pii/?q=\\#pii-data-extraction-and-scrubbing \"Permanent link\")\n\n## Overview [¶](https://python.useinstructor.com/examples/pii/?q=\\#overview \"Permanent link\")\n\nThis example demonstrates the usage of OpenAI's ChatCompletion model for the extraction and scrubbing of Personally Identifiable Information (PII) from a document. The code defines Pydantic models to manage the PII data and offers methods for both extraction and sanitation.\n\n## Defining the Structures [¶](https://python.useinstructor.com/examples/pii/?q=\\#defining-the-structures \"Permanent link\")\n\nFirst, Pydantic models are defined to represent the PII data and the overall structure for PII data extraction.\n\n```md-code__content\nfrom typing import List\nfrom pydantic import BaseModel\n\n# Define Schemas for PII data\nclass Data(BaseModel):\n    index: int\n    data_type: str\n    pii_value: str\n\nclass PIIDataExtraction(BaseModel):\n    \"\"\"\n    Extracted PII data from a document, all data_types should try to have consistent property names\n    \"\"\"\n\n    private_data: List[Data]\n\n    def scrub_data(self, content: str) -> str:\n        \"\"\"\n        Iterates over the private data and replaces the value with a placeholder in the form of\n        <{data_type}_{i}>\n        \"\"\"\n        for i, data in enumerate(self.private_data):\n            content = content.replace(data.pii_value, f\"<{data.data_type}_{i}>\")\n        return content\n\n```\n\n## Extracting PII Data [¶](https://python.useinstructor.com/examples/pii/?q=\\#extracting-pii-data \"Permanent link\")\n\nThe OpenAI API is utilized to extract PII information from a given document.\n\n```md-code__content\nfrom openai import OpenAI\nimport instructor\n\nclient = instructor.from_openai(OpenAI())\n\nEXAMPLE_DOCUMENT = \"\"\"\n# Fake Document with PII for Testing PII Scrubbing Model\n# (The content here)\n\"\"\"\n\npii_data = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    response_model=PIIDataExtraction,\n    messages=[\\\n        {\\\n            \"role\": \"system\",\\\n            \"content\": \"You are a world class PII scrubbing model, Extract the PII data from the following document\",\\\n        },\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": EXAMPLE_DOCUMENT,\\\n        },\\\n    ],\n)  # type: ignore\n\nprint(\"Extracted PII Data:\")\n#> Extracted PII Data:\nprint(pii_data.model_dump_json())\n\"\"\"\n{\"private_data\":[{\"index\":1,\"data_type\":\"Name\",\"pii_value\":\"John Doe\"},{\"index\":2,\"data_type\":\"Email\",\"pii_value\":\"john.doe@example.com\"},{\"index\":3,\"data_type\":\"Phone\",\"pii_value\":\"+1234567890\"},{\"index\":4,\"data_type\":\"Address\",\"pii_value\":\"1234 Elm Street, Springfield, IL 62704\"},{\"index\":5,\"data_type\":\"SSN\",\"pii_value\":\"123-45-6789\"}]}\n\"\"\"\n\n```\n\n### Output of Extracted PII Data [¶](https://python.useinstructor.com/examples/pii/?q=\\#output-of-extracted-pii-data \"Permanent link\")\n\n```md-code__content\n{\n  \"private_data\": [\\\n    {\\\n      \"index\": 0,\\\n      \"data_type\": \"date\",\\\n      \"pii_value\": \"01/02/1980\"\\\n    },\\\n    {\\\n      \"index\": 1,\\\n      \"data_type\": \"ssn\",\\\n      \"pii_value\": \"123-45-6789\"\\\n    },\\\n    {\\\n      \"index\": 2,\\\n      \"data_type\": \"email\",\\\n      \"pii_value\": \"john.doe@email.com\"\\\n    },\\\n    {\\\n      \"index\": 3,\\\n      \"data_type\": \"phone\",\\\n      \"pii_value\": \"555-123-4567\"\\\n    },\\\n    {\\\n      \"index\": 4,\\\n      \"data_type\": \"address\",\\\n      \"pii_value\": \"123 Main St, Springfield, IL, 62704\"\\\n    }\\\n  ]\n}\n\n```\n\n## Scrubbing PII Data [¶](https://python.useinstructor.com/examples/pii/?q=\\#scrubbing-pii-data \"Permanent link\")\n\nAfter extracting the PII data, the `scrub_data` method is used to sanitize the document.\n\n```md-code__content\nprint(\"Scrubbed Document:\")\n#> Scrubbed Document:\nprint(pii_data.scrub_data(EXAMPLE_DOCUMENT))\n\"\"\"\n# Fake Document with PII for Testing PII Scrubbing Model\n# He was born on <date_0>. His social security number is <ssn_1>. He has been using the email address <email_2> for years, and he can always be reached at <phone_3>.\n\"\"\"\n\n```\n\n### Output of Scrubbed Document [¶](https://python.useinstructor.com/examples/pii/?q=\\#output-of-scrubbed-document \"Permanent link\")\n\n```md-code__content\n# Fake Document with PII for Testing PII Scrubbing Model\n\n## Personal Story\n\nJohn Doe was born on <date_0>. His social security number is <ssn_1>. He has been using the email address <email_2> for years, and he can always be reached at <phone_3>.\n\n## Residence\n\nJohn currently resides at <address_4>. He's been living there for about 5 years now.\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/pii/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/pii/",
      "title": "Extracting and Scrubbing PII Data with OpenAI - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/pii/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/pii.png",
      "ogTitle": "Extracting and Scrubbing PII Data with OpenAI - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/pii.png",
      "og:title": "Extracting and Scrubbing PII Data with OpenAI - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/pii/?q=",
      "statusCode": 200,
      "description": "Learn to extract and sanitize Personally Identifiable Information (PII) from documents using OpenAI's ChatCompletion model and Python.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to extract and sanitize Personally Identifiable Information (PII) from documents using OpenAI's ChatCompletion model and Python.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/pii.png",
      "twitter:title": "Extracting and Scrubbing PII Data with OpenAI - Instructor",
      "og:description": "Learn to extract and sanitize Personally Identifiable Information (PII) from documents using OpenAI's ChatCompletion model and Python.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to extract and sanitize Personally Identifiable Information (PII) from documents using OpenAI's ChatCompletion model and Python."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/action_items/?q=#extracting-action-items-from-meeting-transcripts)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/action_items.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/action_items.md \"View source of this page\")\n\n# Extracting Action Items from Meeting Transcripts [¶](https://python.useinstructor.com/examples/action_items/?q=\\#extracting-action-items-from-meeting-transcripts \"Permanent link\")\n\nIn this guide, we'll walk through how to extract action items from meeting transcripts using OpenAI's API and Pydantic. This use case is essential for automating project management tasks, such as task assignment and priority setting.\n\nFor multi-label classification, we introduce a new enum class and a different Pydantic model to handle multiple labels.\n\nMotivation\n\nSignificant amount of time is dedicated to meetings, where action items are generated as the actionable outcomes of these discussions. Automating the extraction of action items can save time and guarantee that no critical tasks are overlooked.\n\n## Defining the Structures [¶](https://python.useinstructor.com/examples/action_items/?q=\\#defining-the-structures \"Permanent link\")\n\nWe'll model a meeting transcript as a collection of **`Ticket`** objects, each representing an action item. Every **`Ticket`** can have multiple **`Subtask`** objects, representing smaller, manageable pieces of the main task.\n\n## Extracting Action Items [¶](https://python.useinstructor.com/examples/action_items/?q=\\#extracting-action-items \"Permanent link\")\n\nTo extract action items from a meeting transcript, we use the **`generate`** function. It calls OpenAI's API, processes the text, and returns a set of action items modeled as **`ActionItems`**.\n\n## Evaluation and Testing [¶](https://python.useinstructor.com/examples/action_items/?q=\\#evaluation-and-testing \"Permanent link\")\n\nTo test the **`generate`** function, we provide it with a sample transcript, and then print the JSON representation of the extracted action items.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\nfrom typing import Iterable, List, Optional\nfrom enum import Enum\nfrom pydantic import BaseModel\n\nclass PriorityEnum(str, Enum):\n    high = \"High\"\n    medium = \"Medium\"\n    low = \"Low\"\n\nclass Subtask(BaseModel):\n    \"\"\"Correctly resolved subtask from the given transcript\"\"\"\n\n    id: int\n    name: str\n\nclass Ticket(BaseModel):\n    \"\"\"Correctly resolved ticket from the given transcript\"\"\"\n\n    id: int\n    name: str\n    description: str\n    priority: PriorityEnum\n    assignees: List[str]\n    subtasks: Optional[List[Subtask]]\n    dependencies: Optional[List[int]]\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\ndef generate(data: str) -> Iterable[Ticket]:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        response_model=Iterable[Ticket],\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"The following is a transcript of a meeting...\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Create the action items for the following transcript: {data}\",\\\n            },\\\n        ],\n    )\n\nprediction = generate(\n    \"\"\"\nAlice: Hey team, we have several critical tasks we need to tackle for the upcoming release. First, we need to work on improving the authentication system. It's a top priority.\nBob: Got it, Alice. I can take the lead on the authentication improvements. Are there any specific areas you want me to focus on?\nAlice: Good question, Bob. We need both a front-end revamp and back-end optimization. So basically, two sub-tasks.\nCarol: I can help with the front-end part of the authentication system.\nBob: Great, Carol. I'll handle the back-end optimization then.\nAlice: Perfect. Now, after the authentication system is improved, we have to integrate it with our new billing system. That's a medium priority task.\nCarol: Is the new billing system already in place?\nAlice: No, it's actually another task. So it's a dependency for the integration task. Bob, can you also handle the billing system?\nBob: Sure, but I'll need to complete the back-end optimization of the authentication system first, so it's dependent on that.\nAlice: Understood. Lastly, we also need to update our user documentation to reflect all these changes. It's a low-priority task but still important.\nCarol: I can take that on once the front-end changes for the authentication system are done. So, it would be dependent on that.\nAlice: Sounds like a plan. Let's get these tasks modeled out and get started.\"\"\"\n)\n\n```\n\n## Visualizing the tasks [¶](https://python.useinstructor.com/examples/action_items/?q=\\#visualizing-the-tasks \"Permanent link\")\n\nIn order to quickly visualize the data we used code interpreter to create a graphviz export of the json version of the ActionItems array.\n\n![action items](https://python.useinstructor.com/img/action_items.png)\n\n```md-code__content\n[\\\n  {\\\n    \"id\": 1,\\\n    \"name\": \"Improve Authentication System\",\\\n    \"description\": \"Revamp the front-end and optimize the back-end of the authentication system\",\\\n    \"priority\": \"High\",\\\n    \"assignees\": [\"Bob\", \"Carol\"],\\\n    \"subtasks\": [\\\n      {\\\n        \"id\": 2,\\\n        \"name\": \"Front-end Revamp\"\\\n      },\\\n      {\\\n        \"id\": 3,\\\n        \"name\": \"Back-end Optimization\"\\\n      }\\\n    ],\\\n    \"dependencies\": []\\\n  },\\\n  {\\\n    \"id\": 4,\\\n    \"name\": \"Integrate Authentication System with Billing System\",\\\n    \"description\": \"Integrate the improved authentication system with the new billing system\",\\\n    \"priority\": \"Medium\",\\\n    \"assignees\": [\"Bob\"],\\\n    \"subtasks\": [],\\\n    \"dependencies\": [1]\\\n  },\\\n  {\\\n    \"id\": 5,\\\n    \"name\": \"Update User Documentation\",\\\n    \"description\": \"Update the user documentation to reflect the changes in the authentication system\",\\\n    \"priority\": \"Low\",\\\n    \"assignees\": [\"Carol\"],\\\n    \"subtasks\": [],\\\n    \"dependencies\": [2]\\\n  }\\\n]\n\n```\n\nIn this example, the **`generate`** function successfully identifies and segments the action items, assigning them priorities, assignees, subtasks, and dependencies as discussed in the meeting.\n\nBy automating this process, you can ensure that important tasks and details are not lost in the sea of meeting minutes, making project management more efficient and effective.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/action_items/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/action_items/",
      "title": "Automating Action Item Extraction from Meeting Transcripts - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/action_items/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/action_items.png",
      "ogTitle": "Automating Action Item Extraction from Meeting Transcripts - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/action_items.png",
      "og:title": "Automating Action Item Extraction from Meeting Transcripts - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/action_items/?q=",
      "statusCode": 200,
      "description": "Learn to extract actionable items from meeting transcripts using OpenAI's API and Pydantic for efficient project management.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to extract actionable items from meeting transcripts using OpenAI's API and Pydantic for efficient project management.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/action_items.png",
      "twitter:title": "Automating Action Item Extraction from Meeting Transcripts - Instructor",
      "og:description": "Learn to extract actionable items from meeting transcripts using OpenAI's API and Pydantic for efficient project management.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to extract actionable items from meeting transcripts using OpenAI's API and Pydantic for efficient project management."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/entity_resolution/?q=#entity-resolution-and-visualization-for-legal-documents)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/entity_resolution.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/entity_resolution.md \"View source of this page\")\n\n# Entity Resolution and Visualization for Legal Documents [¶](https://python.useinstructor.com/examples/entity_resolution/?q=\\#entity-resolution-and-visualization-for-legal-documents \"Permanent link\")\n\nIn this guide, we demonstrate how to extract and resolve entities from a sample legal contract. Then, we visualize these entities and their dependencies as an entity graph. This approach can be invaluable for legal tech applications, aiding in the understanding of complex documents.\n\nMotivation\n\nLegal contracts are full of intricate details and interconnected clauses. Automatically extracting and visualizing these elements can make it easier to understand the document's overall structure and terms.\n\n## Defining the Data Structures [¶](https://python.useinstructor.com/examples/entity_resolution/?q=\\#defining-the-data-structures \"Permanent link\")\n\nThe **`Entity`** and **`Property`** classes model extracted entities and their attributes. **`DocumentExtraction`** encapsulates a list of these entities.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass Property(BaseModel):\n    key: str\n    value: str\n    resolved_absolute_value: str\n\nclass Entity(BaseModel):\n    id: int = Field(\n        ...,\n        description=\"Unique identifier for the entity, used for deduplication, design a scheme allows multiple entities\",\n    )\n    subquote_string: List[str] = Field(\n        ...,\n        description=\"Correctly resolved value of the entity, if the entity is a reference to another entity, this should be the id of the referenced entity, include a few more words before and after the value to allow for some context to be used in the resolution\",\n    )\n    entity_title: str\n    properties: List[Property] = Field(\n        ..., description=\"List of properties of the entity\"\n    )\n    dependencies: List[int] = Field(\n        ...,\n        description=\"List of entity ids that this entity depends  or relies on to resolve it\",\n    )\n\nclass DocumentExtraction(BaseModel):\n    entities: List[Entity] = Field(\n        ...,\n        description=\"Body of the answer, each fact should be a separate object with a body and a list of sources\",\n    )\n\n```\n\n## Entity Extraction and Resolution [¶](https://python.useinstructor.com/examples/entity_resolution/?q=\\#entity-extraction-and-resolution \"Permanent link\")\n\nThe **`ask_ai`** function utilizes OpenAI's API to extract and resolve entities from the input content.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\ndef ask_ai(content) -> DocumentExtraction:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        response_model=DocumentExtraction,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"Extract and resolve a list of entities from the following document:\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": content,\\\n            },\\\n        ],\n    )  # type: ignore\n\n```\n\n## Graph Visualization [¶](https://python.useinstructor.com/examples/entity_resolution/?q=\\#graph-visualization \"Permanent link\")\n\n**`generate_graph`** takes the extracted entities and visualizes them using Graphviz. It creates nodes for each entity and edges for their dependencies.\n\n```md-code__content\nfrom graphviz import Digraph\n\ndef generate_html_label(entity: Entity) -> str:\n    rows = [\\\n        f\"<tr><td>{prop.key}</td><td>{prop.resolved_absolute_value}</td></tr>\"\\\n        for prop in entity.properties\\\n    ]\n    table_rows = \"\".join(rows)\n    return f\"<<table border='0' cellborder='1' cellspacing='0'><tr><td colspan='2'><b>{entity.entity_title}</b></td></tr>{table_rows}</table>>\"\n\ndef generate_graph(data: DocumentExtraction):\n    dot = Digraph(comment=\"Entity Graph\", node_attr={\"shape\": \"plaintext\"})\n\n    for entity in data.entities:\n        label = generate_html_label(entity)\n        dot.node(str(entity.id), label)\n\n    for entity in data.entities:\n        for dep_id in entity.dependencies:\n            dot.edge(str(entity.id), str(dep_id))\n\n    dot.render(\"entity.gv\", view=True)\n\n```\n\n## Execution [¶](https://python.useinstructor.com/examples/entity_resolution/?q=\\#execution \"Permanent link\")\n\nFinally, execute the code to visualize the entity graph for the sample legal contract.\n\n```md-code__content\ncontent = \"\"\"\nSample Legal Contract\nAgreement Contract\n\nThis Agreement is made and entered into on 2020-01-01 by and between Company A (\"the Client\") and Company B (\"the Service Provider\").\n\nArticle 1: Scope of Work\n\nThe Service Provider will deliver the software product to the Client 30 days after the agreement date.\n\nArticle 2: Payment Terms\n\nThe total payment for the service is $50,000.\nAn initial payment of $10,000 will be made within 7 days of the the signed date.\nThe final payment will be due 45 days after [SignDate].\n\nArticle 3: Confidentiality\n\nThe parties agree not to disclose any confidential information received from the other party for 3 months after the final payment date.\n\nArticle 4: Termination\n\nThe contract can be terminated with a 30-day notice, unless there are outstanding obligations that must be fulfilled after the [DeliveryDate].\n\"\"\"  # Your legal contract here\nmodel = ask_ai(content)\ngenerate_graph(model)\n\n```\n\nThis will produce a graphical representation of the entities and their dependencies, stored as \"entity.gv\".\n\n![Entity Graph](https://python.useinstructor.com/examples/entity_resolution.png)\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/entity_resolution/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/entity_resolution/",
      "title": "Entity Resolution and Visualization for Legal Documents - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/entity_resolution/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/entity_resolution.png",
      "ogTitle": "Entity Resolution and Visualization for Legal Documents - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/entity_resolution.png",
      "og:title": "Entity Resolution and Visualization for Legal Documents - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/entity_resolution/?q=",
      "statusCode": 200,
      "description": "Learn how to extract, resolve, and visualize entities from legal contracts for better understanding and analysis.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to extract, resolve, and visualize entities from legal contracts for better understanding and analysis.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/entity_resolution.png",
      "twitter:title": "Entity Resolution and Visualization for Legal Documents - Instructor",
      "og:description": "Learn how to extract, resolve, and visualize entities from legal contracts for better understanding and analysis.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to extract, resolve, and visualize entities from legal contracts for better understanding and analysis."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/classification/?q=#text-classification-using-openai-and-pydantic)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/classification.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/classification.md \"View source of this page\")\n\n# Text Classification using OpenAI and Pydantic [¶](https://python.useinstructor.com/examples/classification/?q=\\#text-classification-using-openai-and-pydantic \"Permanent link\")\n\nThis tutorial showcases how to implement text classification tasks—specifically, single-label and multi-label classifications—using the OpenAI API and Pydantic models. For complete examples, check out our [single classification](https://python.useinstructor.com/examples/bulk_classification/#single-label-classification) and [multi-label classification](https://python.useinstructor.com/examples/bulk_classification/#multi-label-classification) examples in the cookbook.\n\nMotivation\n\nText classification is a common problem in many NLP applications, such as spam detection or support ticket categorization. The goal is to provide a systematic way to handle these cases using OpenAI's GPT models in combination with Python data structures.\n\n## Single-Label Classification [¶](https://python.useinstructor.com/examples/classification/?q=\\#single-label-classification \"Permanent link\")\n\n### Defining the Structures [¶](https://python.useinstructor.com/examples/classification/?q=\\#defining-the-structures \"Permanent link\")\n\nFor single-label classification, we define a Pydantic model with a [Literal](https://python.useinstructor.com/concepts/prompting/#literals) field for the possible labels.\n\nLiterals vs Enums\n\nWe prefer using `Literal` types over `enum` for classification labels. Literals provide better type checking and are more straightforward to use with Pydantic models.\n\nFew-Shot Examples\n\nIncluding few-shot examples in the model's docstring is crucial for improving the model's classification accuracy. These examples guide the AI in understanding the task and expected outputs.\n\nIf you want to learn more prompting tips check out our [prompting guide](https://python.useinstructor.com/prompting/)\n\nChain of Thought\n\nUsing [Chain of Thought](https://python.useinstructor.com/concepts/prompting/#chain-of-thought) has been shown to improve the quality of the predictions by ~ 10%\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\nfrom openai import OpenAI\nimport instructor\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\nclass ClassificationResponse(BaseModel):\n    \"\"\"\n    A few-shot example of text classification:\n\n    Examples:\n    - \"Buy cheap watches now!\": SPAM\n    - \"Meeting at 3 PM in the conference room\": NOT_SPAM\n    - \"You've won a free iPhone! Click here\": SPAM\n    - \"Can you pick up some milk on your way home?\": NOT_SPAM\n    - \"Increase your followers by 10000 overnight!\": SPAM\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        ...,\n        description=\"The chain of thought that led to the prediction.\",\n    )\n    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n        ...,\n        description=\"The predicted class label.\",\n    )\n\n```\n\n### Classifying Text [¶](https://python.useinstructor.com/examples/classification/?q=\\#classifying-text \"Permanent link\")\n\nThe function **`classify`** will perform the single-label classification.\n\n```md-code__content\ndef classify(data: str) -> ClassificationResponse:\n    \"\"\"Perform single-label classification on the input text.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=ClassificationResponse,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Classify the following text: <text>{data}</text>\",\\\n            },\\\n        ],\n    )\n\n```\n\n### Testing and Evaluation [¶](https://python.useinstructor.com/examples/classification/?q=\\#testing-and-evaluation \"Permanent link\")\n\nLet's run examples to see if it correctly identifies spam and non-spam messages.\n\n```md-code__content\nif __name__ == \"__main__\":\n    for text, label in [\\\n        (\"Hey Jason! You're awesome\", \"NOT_SPAM\"),\\\n        (\"I am a nigerian prince and I need your help.\", \"SPAM\"),\\\n    ]:\n        prediction = classify(text)\n        assert prediction.label == label\n        print(f\"Text: {text}, Predicted Label: {prediction.label}\")\n        #> Text: Hey Jason! You're awesome, Predicted Label: NOT_SPAM\n        #> Text: I am a nigerian prince and I need your help., Predicted Label: SPAM\n\n```\n\n## Multi-Label Classification [¶](https://python.useinstructor.com/examples/classification/?q=\\#multi-label-classification \"Permanent link\")\n\n### Defining the Structures [¶](https://python.useinstructor.com/examples/classification/?q=\\#defining-the-structures_1 \"Permanent link\")\n\nFor multi-label classification, we'll update our approach to use Literals instead of enums, and include few-shot examples in the model's docstring.\n\n```md-code__content\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass MultiClassPrediction(BaseModel):\n    \"\"\"\n    Class for a multi-class label prediction.\n\n    Examples:\n    - \"My account is locked\": [\"TECH_ISSUE\"]\n    - \"I can't access my billing info\": [\"TECH_ISSUE\", \"BILLING\"]\n    - \"When do you close for holidays?\": [\"GENERAL_QUERY\"]\n    - \"My payment didn't go through and now I can't log in\": [\"BILLING\", \"TECH_ISSUE\"]\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        ...,\n        description=\"The chain of thought that led to the prediction.\",\n    )\n\n    class_labels: List[Literal[\"TECH_ISSUE\", \"BILLING\", \"GENERAL_QUERY\"]] = Field(\n        ...,\n        description=\"The predicted class labels for the support ticket.\",\n    )\n\n```\n\n### Classifying Text [¶](https://python.useinstructor.com/examples/classification/?q=\\#classifying-text_1 \"Permanent link\")\n\nThe function **`multi_classify`** is responsible for multi-label classification.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\ndef multi_classify(data: str) -> MultiClassPrediction:\n    \"\"\"Perform multi-label classification on the input text.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=MultiClassPrediction,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Classify the following support ticket: <ticket>{data}</ticket>\",\\\n            },\\\n        ],\n    )\n\n```\n\n### Testing and Evaluation [¶](https://python.useinstructor.com/examples/classification/?q=\\#testing-and-evaluation_1 \"Permanent link\")\n\nFinally, we test the multi-label classification function using a sample support ticket.\n\n```md-code__content\n# Test multi-label classification\nticket = \"My account is locked and I can't access my billing info.\"\nprediction = multi_classify(ticket)\nassert \"TECH_ISSUE\" in prediction.class_labels\nassert \"BILLING\" in prediction.class_labels\nprint(f\"Ticket: {ticket}\")\n#> Ticket: My account is locked and I can't access my billing info.\nprint(f\"Predicted Labels: {prediction.class_labels}\")\n#> Predicted Labels: ['TECH_ISSUE', 'BILLING']\n\n```\n\nBy using Literals and including few-shot examples, we've improved both the single-label and multi-label classification implementations. These changes enhance type safety and provide better guidance for the AI model, potentially leading to more accurate classifications.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/classification/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/classification/",
      "title": "Text Classification with OpenAI and Pydantic - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/classification/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/classification.png",
      "ogTitle": "Text Classification with OpenAI and Pydantic - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/classification.png",
      "og:title": "Text Classification with OpenAI and Pydantic - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/classification/?q=",
      "statusCode": 200,
      "description": "Learn to implement single-label and multi-label text classification using OpenAI API and Pydantic models in Python.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to implement single-label and multi-label text classification using OpenAI API and Pydantic models in Python.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/classification.png",
      "twitter:title": "Text Classification with OpenAI and Pydantic - Instructor",
      "og:description": "Learn to implement single-label and multi-label text classification using OpenAI API and Pydantic models in Python.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to implement single-label and multi-label text classification using OpenAI API and Pydantic models in Python."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/moderation/?q=#openai-moderation)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/moderation.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/moderation.md \"View source of this page\")\n\n# OpenAI Moderation [¶](https://python.useinstructor.com/examples/moderation/?q=\\#openai-moderation \"Permanent link\")\n\nThis example uses OpenAI's moderation endpoint to check content compliance with OpenAI's usage policies. It can identify and filter harmful content that violates the policies.\n\nThe model flags content and classifies it into categories including hate, harassment, self-harm, sexual content, and violence. Each category has subcategories for detailed classification.\n\nThis validator is to be used for monitoring OpenAI API inputs and outputs, other use cases are currently [not allowed](https://platform.openai.com/docs/guides/moderation/overview).\n\n## Incorporating OpenAI moderation validator [¶](https://python.useinstructor.com/examples/moderation/?q=\\#incorporating-openai-moderation-validator \"Permanent link\")\n\nThe following code defines a function to validate content using OpenAI's Moderation endpoint. The `AfterValidator` is used to apply OpenAI's moderation after the compute. This moderation checks if the content complies with OpenAI's usage policies and flags any harmful content. Here's how it works:\n\n1. Generate the OpenAI client and patch it with the `instructor`. Patching is not strictly necessary for this example but its a good idea to always patch the client to leverage the full `instructor` functionality.\n\n2. Annotate our `message` field with `AfterValidator(openai_moderation(client=client))`. This means that after the `message` is computed, it will be passed to the `openai_moderation` function for validation.\n\n\n```md-code__content\nimport instructor\n\nfrom instructor import openai_moderation\n\nfrom typing_extensions import Annotated\nfrom pydantic import BaseModel, AfterValidator\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\nclass Response(BaseModel):\n    message: Annotated[str, AfterValidator(openai_moderation(client=client))]\n\ntry:\n    Response(message=\"I want to make them suffer the consequences\")\nexcept Exception as e:\n    print(e)\n    \"\"\"\n    1 validation error for Response\n    message\n      Value error, `I want to make them suffer the consequences` was flagged for violence [type=value_error, input_value='I want to make them suffer the consequences', input_type=str]\n        For further information visit https://errors.pydantic.dev/2.9/v/value_error\n    \"\"\"\n\ntry:\n    Response(message=\"I want to hurt myself.\")\nexcept Exception as e:\n    print(e)\n    \"\"\"\n    1 validation error for Response\n    message\n      Value error, `I want to hurt myself.` was flagged for self_harm, self_harm_intent, self-harm, self-harm/intent [type=value_error, input_value='I want to hurt myself.', input_type=str]\n        For further information visit https://errors.pydantic.dev/2.9/v/value_error\n    \"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/moderation/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/moderation/",
      "title": "OpenAI Moderation Example for Content Compliance - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/moderation/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/moderation.png",
      "ogTitle": "OpenAI Moderation Example for Content Compliance - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/moderation.png",
      "og:title": "OpenAI Moderation Example for Content Compliance - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/moderation/?q=",
      "statusCode": 200,
      "description": "Learn how to use OpenAI's moderation endpoint to filter harmful content and ensure compliance with usage policies.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use OpenAI's moderation endpoint to filter harmful content and ensure compliance with usage policies.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/moderation.png",
      "twitter:title": "OpenAI Moderation Example for Content Compliance - Instructor",
      "og:description": "Learn how to use OpenAI's moderation endpoint to filter harmful content and ensure compliance with usage policies.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use OpenAI's moderation endpoint to filter harmful content and ensure compliance with usage policies."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/mistral/?q=#structured-outputs-using-mistral)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/mistral.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/mistral.md \"View source of this page\")\n\n# Structured Outputs using Mistral [¶](https://python.useinstructor.com/examples/mistral/?q=\\#structured-outputs-using-mistral \"Permanent link\")\n\nYou can now also use mistralai models for inference by using from\\_mistral.\n\nThe examples are using mistral-large-latest.\n\n## MistralAI API [¶](https://python.useinstructor.com/examples/mistral/?q=\\#mistralai-api \"Permanent link\")\n\nTo use mistral you need to obtain a mistral API key. Goto [mistralai](https://mistral.ai/) click on Build Now and login. Select API Keys from the left menu and then select Create API key to create a new key.\n\n## Use example [¶](https://python.useinstructor.com/examples/mistral/?q=\\#use-example \"Permanent link\")\n\nSome pip packages need to be installed to use the example:\n\n```md-code__content\npip install instructor mistralai pydantic\n\n```\n\nYou need to export the mistral API key:\n\n```md-code__content\nexport MISTRAL_API_KEY=<your-api-key>\n\n```\n\nAn example:\n\n```md-code__content\nimport os\nfrom pydantic import BaseModel\nfrom mistralai import Mistral\nfrom instructor import from_mistral, Mode\n\nclass UserDetails(BaseModel):\n    name: str\n    age: int\n\n# enables `response_model` in chat call\nclient = Mistral(api_key=os.environ.get(\"MISTRAL_API_KEY\"))\n\ninstructor_client = from_mistral(\n    client=client,\n    model=\"mistral-large-latest\",\n    mode=Mode.MISTRAL_TOOLS,\n    max_tokens=1000,\n)\n\nresp = instructor_client.messages.create(\n    response_model=UserDetails,\n    messages=[{\"role\": \"user\", \"content\": \"Jason is 10\"}],\n    temperature=0,\n)\n\nprint(resp)\n#> name='Jason' age=10\n\n# output: UserDetails(name='Jason', age=10)\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/mistral/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/mistral/",
      "title": "Using MistralAI for Structured Outputs - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/mistral/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/mistral.png",
      "ogTitle": "Using MistralAI for Structured Outputs - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/mistral.png",
      "og:title": "Using MistralAI for Structured Outputs - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/mistral/?q=",
      "statusCode": 200,
      "description": "Learn how to use MistralAI models for inference, including setup, API key generation, and example code.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use MistralAI models for inference, including setup, API key generation, and example code.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/mistral.png",
      "twitter:title": "Using MistralAI for Structured Outputs - Instructor",
      "og:description": "Learn how to use MistralAI models for inference, including setup, API key generation, and example code.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use MistralAI models for inference, including setup, API key generation, and example code."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/batch_job_oai/?q=#bulk-generation-of-synthetic-data)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/batch_job_oai.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/batch_job_oai.md \"View source of this page\")\n\n# Bulk Generation of Synthetic Data [¶](https://python.useinstructor.com/examples/batch_job_oai/?q=\\#bulk-generation-of-synthetic-data \"Permanent link\")\n\nThis tutorial shows how to use `instructor` to generate large quantities of synthetic data at scale using Open AI's new Batch API. In this example, we'll be generating synthetic questions using the `ms-marco` dataset to evaluate RAG retrieval.\n\nWhy use the batch API?\n\nThere are a few reasons why you might want to use the Batch API\n\n1. Batch Jobs are 50% cheaper than running an inference job on demand ( see Open AI's pricing page [here](https://openai.com/api/pricing/) )\n\n2. Batch Jobs have higher rate limits than normal api calls\n\n3. Batch Jobs support both normal models **and fine-tuned models**\n\n\nThis makes them perfect for non time-sensitive tasks that involve large quantities of data.\n\n## Getting Started [¶](https://python.useinstructor.com/examples/batch_job_oai/?q=\\#getting-started \"Permanent link\")\n\nLet's first see how we can generate a Question and Answer Pair using Instructor with a normal OpenAI function call.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom openai import OpenAI\nfrom instructor import from_openai\n\nclient = from_openai(OpenAI())\n\nclass QuestionAnswerPair(BaseModel):\n    \"\"\"\n    This model represents a pair of a question generated from a text chunk, its corresponding answer,\n    and the chain of thought leading to the answer. The chain of thought provides insight into how the answer\n    was derived from the question.\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        description=\"The reasoning process leading to the answer.\"\n    )\n    question: str = Field(description=\"The generated question from the text chunk.\")\n    answer: str = Field(description=\"The answer to the generated question.\")\n\ndef generate_question(chunk: str) -> QuestionAnswerPair:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a world class AI that excels at generating hypothethical search queries. You're about to be given a text snippet and asked to generate a search query which is specific to the specific text chunk that you'll be given. Make sure to use information from the text chunk.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": f\"Here is the text chunk: {chunk}\"},\\\n        ],\n        response_model=QuestionAnswerPair,\n    )\n\ntext_chunk = \"\"\"\nThe Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia 's central bank and banknote issuing authority, when the Reserve Bank Act 1959 removed the central banking functions from the Commonwealth Bank. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\n\"\"\"\nprint(generate_question(text_chunk).model_dump_json(indent=2))\n\"\"\"\n{\n  \"chain_of_thought\": \"The text discusses the formation of the Reserve Bank of Australia (RBA) and provides key details about its establishment date, the removal of central banking functions from the Commonwealth Bank, its asset worth, and its employee distribution. By focusing on these details, a search query can be framed around the establishment date and purpose of the RBA.\",\n  \"question\": \"When was the Reserve Bank of Australia established and what are its main functions?\",\n  \"answer\": \"The Reserve Bank of Australia was established on 14 January 1960 as Australia's central bank and banknote issuing authority.\"\n}\n\"\"\"\n\n```\n\nAs the number of chunks we'd like to generate these synthetic questions for increases, the cost will grow proportionally.\n\nLet's see how we can use the `BatchJob` object to create a `.jsonl` file which is compatible with the Batch API.\n\n```md-code__content\nfrom datasets import load_dataset\nfrom instructor.batch import BatchJob\nfrom pydantic import BaseModel, Field\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ms_marco\", \"v1.1\", split=\"train\", streaming=True).take(200)\n\ndef get_messages(dataset):\n    for row in dataset:\n        for passage in row['passages']['passage_text']:\n            yield [\\\n                {\\\n                    \"role\": \"system\",\\\n                    \"content\": \"You are a world class AI that excels at generating hypothethical search queries. You're about to be given a text snippet and asked to generate a search query which is specific to the specific text chunk that you'll be given. Make sure to use information from the text chunk.\",\\\n                },\\\n                {\"role\": \"user\", \"content\": f\"Here is the text chunk: {passage}\"},\\\n            ]\n\nclass QuestionAnswerPair(BaseModel):\n    \"\"\"\n    This model represents a pair of a question generated from a text chunk, its corresponding answer,\n    and the chain of thought leading to the answer. The chain of thought provides insight into how the answer\n    was derived from the question.\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        description=\"The reasoning process leading to the answer.\"\n    )\n    question: str = Field(description=\"The generated question from the text chunk.\")\n    answer: str = Field(description=\"The answer to the generated question.\")\n\nBatchJob.create_from_messages(\n    messages_batch=get_messages(dataset),\n    model=\"gpt-4o\",\n    file_path=\"./test.jsonl\",\n    response_model=QuestionAnswerPair,\n)\n\n```\n\nOnce we've got this new `.jsonl` file, we can then use the new `instructor` cli's `batch` command to create a new batch job.\n\n```md-code__content\n> % ls -a | grep test.jsonl\ntest.jsonl\n\n> % instructor batch create-from-file --file-path test.jsonl\n\n```\n\nThis will create a table like what you see below. In my case, my batch job took around 6 minutes to complete and cost me $2.72 to run.\n\n| Batch ID | Created At | Status | Failed | Completed | Total |\n| --- | --- | --- | --- | --- | --- |\n| batch\\_Z8XUudoweH43R9c4sr4wRYub | 2024-07-16 12:45:22 | in\\_progress | 0 | 483 | 1627 |\n\nOnce our batch job is complete, the status will change to `completed`.\n\nCancelling A Job\n\nIf you'd like to cancel a batch job midway, you can do so too with the instructor `batch` cli command\n\n```md-code__content\ninstructor batch cancel --batch-id <batch id here>\n\n```\n\nWe can then download the file generated by the batch job using the cli command\n\n```md-code__content\ninstructor batch download-file --download-file-path output.jsonl --batch-id batch_Z8XUudoweH43R9c4sr4wRYub\n\n```\n\nThis will then create a `.jsonl` file with the generated content at the path that you specify.\n\n## Parsing the generated response [¶](https://python.useinstructor.com/examples/batch_job_oai/?q=\\#parsing-the-generated-response \"Permanent link\")\n\nWe can then parse the generated response by using the `.parse_from_file` command provided by the `BatchJob` class.\n\n```md-code__content\nfrom instructor.batch import BatchJob\nfrom pydantic import BaseModel, Field\n\nclass QuestionAnswerPair(BaseModel):\n    \"\"\"\n    This model represents a pair of a question generated from a text chunk, its corresponding answer,\n    and the chain of thought leading to the answer. The chain of thought provides insight into how the answer\n    was derived from the question.\n    \"\"\"\n\n    chain_of_thought: str = Field(\n        description=\"The reasoning process leading to the answer.\"\n    )\n    question: str = Field(description=\"The generated question from the text chunk.\")\n    answer: str = Field(description=\"The answer to the generated question.\")\n\nparsed, unparsed = BatchJob.parse_from_file(\n    file_path=\"./output.jsonl\", response_model=QuestionAnswerPair\n)\n\nprint(len(parsed))\n#> 0\nprint(len(unparsed))\n#> 0\n\n```\n\nThis will then return a list of two elements\n\n- `parsed` is a list of responses that have been succesfully parsed into the `QuestionAnswerPair` Base Model class\n- `unparsed` is a second list which contains responses which were not able to be parsed into the `QuestionAnswerPair` Base Model class\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/batch_job_oai/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/batch_job_oai/",
      "title": "Generating Synthetic Data with OpenAI's Batch API - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/batch_job_oai/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/batch_job_oai.png",
      "ogTitle": "Generating Synthetic Data with OpenAI's Batch API - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/batch_job_oai.png",
      "og:title": "Generating Synthetic Data with OpenAI's Batch API - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/batch_job_oai/?q=",
      "statusCode": 200,
      "description": "Learn to use OpenAI's Batch API for large-scale synthetic data generation, focusing on question-answer pairs from the ms-marco dataset.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to use OpenAI's Batch API for large-scale synthetic data generation, focusing on question-answer pairs from the ms-marco dataset.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/batch_job_oai.png",
      "twitter:title": "Generating Synthetic Data with OpenAI's Batch API - Instructor",
      "og:description": "Learn to use OpenAI's Batch API for large-scale synthetic data generation, focusing on question-answer pairs from the ms-marco dataset.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to use OpenAI's Batch API for large-scale synthetic data generation, focusing on question-answer pairs from the ms-marco dataset."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/partial_streaming/?q=#streaming-partial-responses)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/partial_streaming.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/partial_streaming.md \"View source of this page\")\n\n# Streaming Partial Responses [¶](https://python.useinstructor.com/examples/partial_streaming/?q=\\#streaming-partial-responses \"Permanent link\")\n\nField level streaming provides incremental snapshots of the current state of the response model that are immediately useable. This approach is particularly relevant in contexts like rendering UI components.\n\nInstructor supports this pattern by making use of `Partial[T]`. This lets us dynamically create a new class that treats all of the original model's fields as `Optional`.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\nfrom typing import List\n\nclient = instructor.from_openai(OpenAI())\n\ntext_block = \"\"\"\nIn our recent online meeting, participants from various backgrounds joined to discuss the upcoming tech conference. The names and contact details of the participants were as follows:\n- Name: John Doe, Email: johndoe@email.com, Twitter: @TechGuru44\n- Name: Jane Smith, Email: janesmith@email.com, Twitter: @DigitalDiva88\n- Name: Alex Johnson, Email: alexj@email.com, Twitter: @CodeMaster2023\nDuring the meeting, we agreed on several key points. The conference will be held on March 15th, 2024, at the Grand Tech Arena located at 4521 Innovation Drive. Dr. Emily Johnson, a renowned AI researcher, will be our keynote speaker.\nThe budget for the event is set at $50,000, covering venue costs, speaker fees, and promotional activities. Each participant is expected to contribute an article to the conference blog by February 20th.\nA follow-up meetingis scheduled for January 25th at 3 PM GMT to finalize the agenda and confirm the list of speakers.\n\"\"\"\n\nclass User(BaseModel):\n    name: str\n    email: str\n    twitter: str\n\nclass MeetingInfo(BaseModel):\n    users: List[User]\n    date: str\n    location: str\n    budget: int\n    deadline: str\n\nPartialMeetingInfo = instructor.Partial[MeetingInfo]\n\nextraction_stream = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=PartialMeetingInfo,\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": f\"Get the information about the meeting and the users {text_block}\",\\\n        },\\\n    ],\n    stream=True,\n)  # type: ignore\n\nfrom rich.console import Console\n\nconsole = Console()\n\nfor extraction in extraction_stream:\n    obj = extraction.model_dump()\n    console.clear()\n    console.print(obj)\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/partial_streaming/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/partial_streaming/",
      "title": "Streaming Partial Responses with Instructor - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/partial_streaming/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/partial_streaming.png",
      "ogTitle": "Streaming Partial Responses with Instructor - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/partial_streaming.png",
      "og:title": "Streaming Partial Responses with Instructor - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/partial_streaming/?q=",
      "statusCode": 200,
      "description": "Learn how to implement field-level streaming in Python using the Instructor library for dynamic UI rendering.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to implement field-level streaming in Python using the Instructor library for dynamic UI rendering.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/partial_streaming.png",
      "twitter:title": "Streaming Partial Responses with Instructor - Instructor",
      "og:description": "Learn how to implement field-level streaming in Python using the Instructor library for dynamic UI rendering.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to implement field-level streaming in Python using the Instructor library for dynamic UI rendering."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/open_source/?q=#instructor-with-open-source-models)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/open_source.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/open_source.md \"View source of this page\")\n\n# Instructor with open source models [¶](https://python.useinstructor.com/examples/open_source/?q=\\#instructor-with-open-source-models \"Permanent link\")\n\nInstructor works with Open source model providers that support the [OpenAI API chat endpoint](https://platform.openai.com/docs/api-reference/chat)\n\nSee examples README [here](https://github.com/jxnl/instructor/tree/main/examples/open_source_examples)\n\n# Currently tested open source model providers [¶](https://python.useinstructor.com/examples/open_source/?q=\\#currently-tested-open-source-model-providers \"Permanent link\")\n\n- [OpenRouter](https://openrouter.ai/)\n- [Perplexity](https://www.perplexity.ai/)\n- [RunPod TheBloke LLMs](https://github.com/TheBlokeAI/dockerLLM/blob/main/README_Runpod_LocalLLMsUI.md) \\*\\*\n\n\\\\*\\\\* This utilizes text-generation-webui w/ Openai plugin under the hood.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/open_source/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/open_source/",
      "title": "Open Source Model Providers for Chat API - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/open_source/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/open_source.png",
      "ogTitle": "Open Source Model Providers for Chat API - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/open_source.png",
      "og:title": "Open Source Model Providers for Chat API - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/open_source/?q=",
      "statusCode": 200,
      "description": "Explore tested open source models compatible with the OpenAI chat API, including OpenRouter, Perplexity, and RunPod LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Explore tested open source models compatible with the OpenAI chat API, including OpenRouter, Perplexity, and RunPod LLMs.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/open_source.png",
      "twitter:title": "Open Source Model Providers for Chat API - Instructor",
      "og:description": "Explore tested open source models compatible with the OpenAI chat API, including OpenRouter, Perplexity, and RunPod LLMs.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Explore tested open source models compatible with the OpenAI chat API, including OpenRouter, Perplexity, and RunPod LLMs."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/tables_from_vision/?q=#extracting-tables-from-images-with-openais-gpt-4-vision-model)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/tables_from_vision.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/tables_from_vision.md \"View source of this page\")\n\n# Extracting Tables from Images with OpenAI's GPT-4 Vision Model [¶](https://python.useinstructor.com/examples/tables_from_vision/?q=\\#extracting-tables-from-images-with-openais-gpt-4-vision-model \"Permanent link\")\n\nFirst, we define a custom type, `MarkdownDataFrame`, to handle pandas DataFrames formatted in markdown. This type uses Python's `Annotated` and `InstanceOf` types, along with decorators `BeforeValidator` and `PlainSerializer`, to process and serialize the data.\n\n## Defining the Table Class [¶](https://python.useinstructor.com/examples/tables_from_vision/?q=\\#defining-the-table-class \"Permanent link\")\n\nThe `Table` class is essential for organizing the extracted data. It includes a caption and a dataframe, processed as a markdown table. Since most of the complexity is handled by the `MarkdownDataFrame` type, the `Table` class is straightforward!\n\nThis requires additional dependencies `pip install pandas tabulate`.\n\n```md-code__content\nfrom openai import OpenAI\nfrom io import StringIO\nfrom typing import Annotated, Any, List\nfrom pydantic import (\n    BaseModel,\n    BeforeValidator,\n    PlainSerializer,\n    InstanceOf,\n    WithJsonSchema,\n)\nimport instructor\nimport pandas as pd\nfrom rich.console import Console\n\nconsole = Console()\nclient = instructor.from_openai(\n    client=OpenAI(),\n    mode=instructor.Mode.TOOLS,\n)\n\ndef md_to_df(data: Any) -> Any:\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),  # Get rid of whitespaces\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .map(lambda x: x.strip())\n        )  # type: ignore\n    return data\n\nMarkdownDataFrame = Annotated[\\\n    InstanceOf[pd.DataFrame],\\\n    BeforeValidator(md_to_df),\\\n    PlainSerializer(lambda x: x.to_markdown()),\\\n    WithJsonSchema(\\\n        {\\\n            \"type\": \"string\",\\\n            \"description\": \"\"\"\\\n                The markdown representation of the table,\\\n                each one should be tidy, do not try to join tables\\\n                that should be seperate\"\"\",\\\n        }\\\n    ),\\\n]\n\nclass Table(BaseModel):\n    caption: str\n    dataframe: MarkdownDataFrame\n\nclass MultipleTables(BaseModel):\n    tables: List[Table]\n\nexample = MultipleTables(\n    tables=[\\\n        Table(\\\n            caption=\"This is a caption\",\\\n            dataframe=pd.DataFrame(\\\n                {\\\n                    \"Chart A\": [10, 40],\\\n                    \"Chart B\": [20, 50],\\\n                    \"Chart C\": [30, 60],\\\n                }\\\n            ),\\\n        )\\\n    ]\n)\n\ndef extract(url: str) -> MultipleTables:\n    return client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        max_tokens=4000,\n        response_model=MultipleTables,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": [\\\n                    {\\\n                        \"type\": \"image_url\",\\\n                        \"image_url\": {\"url\": url},\\\n                    },\\\n                    {\\\n                        \"type\": \"text\",\\\n                        \"text\": \"\"\"\\\n                            First, analyze the image to determine the most appropriate headers for the tables.\\\n                            Generate a descriptive h1 for the overall image, followed by a brief summary of the data it contains.\\\n                            For each identified table, create an informative h2 title and a concise description of its contents.\\\n                            Finally, output the markdown representation of each table.\\\n                            Make sure to escape the markdown table properly, and make sure to include the caption and the dataframe.\\\n                            including escaping all the newlines and quotes. Only return a markdown table in dataframe, nothing else.\\\n                        \"\"\",\\\n                    },\\\n                ],\\\n            }\\\n        ],\n    )\n\nurls = [\\\n    \"https://a.storyblok.com/f/47007/2400x1260/f816b031cb/uk-ireland-in-three-charts_chart_a.png/m/2880x0\",\\\n    \"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png/m/2880x0\",\\\n]\n\nfor url in urls:\n    for table in extract(url).tables:\n        console.print(table.caption, \"\\n\", table.dataframe)\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/tables_from_vision/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/tables_from_vision/",
      "title": "Extracting Tables from Images Using OpenAI GPT-4 - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/tables_from_vision/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/tables_from_vision.png",
      "ogTitle": "Extracting Tables from Images Using OpenAI GPT-4 - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/tables_from_vision.png",
      "og:title": "Extracting Tables from Images Using OpenAI GPT-4 - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/tables_from_vision/?q=",
      "statusCode": 200,
      "description": "Learn how to convert images into markdown tables using OpenAI's GPT-4 Vision model for data extraction and analysis.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to convert images into markdown tables using OpenAI's GPT-4 Vision model for data extraction and analysis.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/tables_from_vision.png",
      "twitter:title": "Extracting Tables from Images Using OpenAI GPT-4 - Instructor",
      "og:description": "Learn how to convert images into markdown tables using OpenAI's GPT-4 Vision model for data extraction and analysis.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to convert images into markdown tables using OpenAI's GPT-4 Vision model for data extraction and analysis."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/extracting_receipts/?q=#extracting-receipt-data-using-gpt-4-and-python)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/extracting_receipts.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/extracting_receipts.md \"View source of this page\")\n\n# Extracting Receipt Data using GPT-4 and Python [¶](https://python.useinstructor.com/examples/extracting_receipts/?q=\\#extracting-receipt-data-using-gpt-4-and-python \"Permanent link\")\n\nThis post demonstrates how to use Python's Pydantic library and OpenAI's GPT-4 model to extract receipt data from images and validate the total amount. This method is particularly useful for automating expense tracking and financial analysis tasks.\n\n## Defining the Item and Receipt Classes [¶](https://python.useinstructor.com/examples/extracting_receipts/?q=\\#defining-the-item-and-receipt-classes \"Permanent link\")\n\nFirst, we define two Pydantic models, `Item` and `Receipt`, to structure the extracted data. The `Item` class represents individual items on the receipt, with fields for name, price, and quantity. The `Receipt` class contains a list of `Item` objects and the total amount.\n\n```md-code__content\nfrom pydantic import BaseModel\n\nclass Item(BaseModel):\n    name: str\n    price: float\n    quantity: int\n\nclass Receipt(BaseModel):\n    items: list[Item]\n    total: float\n\n```\n\n## Validating the Total Amount [¶](https://python.useinstructor.com/examples/extracting_receipts/?q=\\#validating-the-total-amount \"Permanent link\")\n\nTo ensure the accuracy of the extracted data, we use Pydantic's `model_validator` decorator to define a custom validation function, `check_total`. This function calculates the sum of item prices and compares it to the extracted total amount. If there's a discrepancy, it raises a `ValueError`.\n\n```md-code__content\nfrom pydantic import model_validator\n\n@model_validator(mode=\"after\")\ndef check_total(self):\n    items = self.items\n    total = self.total\n    calculated_total = sum(item.price * item.quantity for item in items)\n    if calculated_total != total:\n        raise ValueError(\n            f\"Total {total} does not match the sum of item prices {calculated_total}\"\n        )\n    return self\n\n```\n\n## Extracting Receipt Data from Images [¶](https://python.useinstructor.com/examples/extracting_receipts/?q=\\#extracting-receipt-data-from-images \"Permanent link\")\n\nThe `extract_receipt` function uses OpenAI's GPT-4 model to process an image URL and extract receipt data. We utilize the `instructor` library to configure the OpenAI client for this purpose.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\ndef extract(url: str) -> Receipt:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        max_tokens=4000,\n        response_model=Receipt,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": [\\\n                    {\\\n                        \"type\": \"image_url\",\\\n                        \"image_url\": {\"url\": url},\\\n                    },\\\n                    {\\\n                        \"type\": \"text\",\\\n                        \"text\": \"Analyze the image and return the items in the receipt and the total amount.\",\\\n                    },\\\n                ],\\\n            }\\\n        ],\n    )\n\n```\n\n## Practical Examples [¶](https://python.useinstructor.com/examples/extracting_receipts/?q=\\#practical-examples \"Permanent link\")\n\nIn these examples, we apply the method to extract receipt data from two different images. The custom validation function ensures that the extracted total amount matches the sum of item prices.\n\n```md-code__content\nurl = \"https://templates.mediamodifier.com/645124ff36ed2f5227cbf871/supermarket-receipt-template.jpg\"\n\nreceipt = extract(url)\nprint(receipt)\n\"\"\"\nitems=[Item(name='Lorem ipsum', price=9.2, quantity=1), Item(name='Lorem ipsum dolor sit', price=19.2, quantity=1), Item(name='Lorem ipsum dolor sit amet', price=15.0, quantity=1), Item(name='Lorem ipsum', price=15.0, quantity=1), Item(name='Lorem ipsum', price=15.0, quantity=1), Item(name='Lorem ipsum dolor sit', price=15.0, quantity=1), Item(name='Lorem ipsum', price=19.2, quantity=1)] total=107.6\n\"\"\"\n\n```\n\nBy combining the power of GPT-4 and Python's Pydantic library, we can accurately extract and validate receipt data from images, streamlining expense tracking and financial analysis tasks.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/extracting_receipts/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/extracting_receipts/",
      "title": "Extracting Receipt Data with GPT-4 and Python - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/extracting_receipts/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/extracting_receipts.png",
      "ogTitle": "Extracting Receipt Data with GPT-4 and Python - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/extracting_receipts.png",
      "og:title": "Extracting Receipt Data with GPT-4 and Python - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/extracting_receipts/?q=",
      "statusCode": 200,
      "description": "Learn how to use Python and GPT-4 to extract and validate receipt data from images for efficient expense tracking.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use Python and GPT-4 to extract and validate receipt data from images for efficient expense tracking.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/extracting_receipts.png",
      "twitter:title": "Extracting Receipt Data with GPT-4 and Python - Instructor",
      "og:description": "Learn how to use Python and GPT-4 to extract and validate receipt data from images for efficient expense tracking.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use Python and GPT-4 to extract and validate receipt data from images for efficient expense tracking."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/ollama/?q=#structured-outputs-with-ollama)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/ollama.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/ollama.md \"View source of this page\")\n\n# Structured Outputs with Ollama [¶](https://python.useinstructor.com/examples/ollama/?q=\\#structured-outputs-with-ollama \"Permanent link\")\n\nOpen-source Large Language Models (LLMs) are rapidly gaining popularity in the AI community. With the recent release of Ollama's OpenAI compatibility layer, it has become possible to obtain structured outputs using JSON schema from these open-source models. This development opens up exciting possibilities for developers and researchers alike.\n\nIn this blog post, we'll explore how to effectively utilize the Instructor library with Ollama to harness the power of structured outputs with [Pydantic models](https://python.useinstructor.com/concepts/models/). We'll cover everything from setup to implementation, providing you with practical insights and code examples.\n\n## Why use Instructor? [¶](https://python.useinstructor.com/examples/ollama/?q=\\#why-use-instructor \"Permanent link\")\n\nInstructor offers several key benefits:\n\n- **Simple API with Full Prompt Control**: Instructor provides a straightforward API that gives you complete ownership and control over your prompts. This allows for fine-tuned customization and optimization of your LLM interactions. [Explore Concepts](https://python.useinstructor.com/concepts/models/)\n\n- **Reasking and Validation**: Automatically reask the model when validation fails, ensuring high-quality outputs. Leverage Pydantic's validation for robust error handling. [Learn about Reasking](https://python.useinstructor.com/concepts/reask_validation/)\n\n- **Streaming Support**: Stream partial results and iterables with ease, allowing for real-time processing and improved responsiveness in your applications. [Learn about Streaming](https://python.useinstructor.com/concepts/partial/)\n\n- **Powered by Type Hints**: Leverage Pydantic for schema validation, prompting control, less code, and IDE integration. [Learn more](https://docs.pydantic.dev/)\n\n- **Simplified LLM Interactions**: Support for various LLM providers including OpenAI, Anthropic, Google, Vertex AI, Mistral/Mixtral, Anyscale, Ollama, llama-cpp-python, Cohere, and LiteLLM. [See Examples](https://python.useinstructor.com/examples/)\n\n\nFor more details on these features, check out the [Concepts](https://python.useinstructor.com/concepts/models/) section of the documentation.\n\n## Patching [¶](https://python.useinstructor.com/examples/ollama/?q=\\#patching \"Permanent link\")\n\nInstructor's [patch](https://python.useinstructor.com/concepts/patching/) enhances an openai api with the following features:\n\n- `response_model` in `create` calls that returns a pydantic model\n- `max_retries` in `create` calls that retries the call if it fails by using a backoff strategy\n\nLearn More\n\nTo learn more, please refer to the [docs](https://python.useinstructor.com/). To understand the benefits of using Pydantic with Instructor, visit the tips and tricks section of the [why use Pydantic](https://python.useinstructor.com/why/) page.\n\n## Ollama [¶](https://python.useinstructor.com/examples/ollama/?q=\\#ollama \"Permanent link\")\n\nStart by downloading [Ollama](https://ollama.ai/download), and then pull a model such as Llama 3 or Mistral.\n\nMake sure you update your `ollama` to the latest version!\n\n```md-code__content\nollama pull llama3\n\n```\n\n```md-code__content\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nimport instructor\n\nclass Character(BaseModel):\n    name: str\n    age: int\n    fact: List[str] = Field(..., description=\"A list of facts about the character\")\n\n# enables `response_model` in create call\nclient = instructor.from_openai(\n    OpenAI(\n        base_url=\"http://localhost:11434/v1\",\n        api_key=\"ollama\",  # required, but unused\n    ),\n    mode=instructor.Mode.JSON,\n)\n\nresp = client.chat.completions.create(\n    model=\"llama3\",\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": \"Tell me about the Harry Potter\",\\\n        }\\\n    ],\n    response_model=Character,\n)\nprint(resp.model_dump_json(indent=2))\n\"\"\"\n{\n  \"name\": \"Harry James Potter\",\n  \"age\": 37,\n  \"fact\": [\\\n    \"He is the chosen one.\",\\\n    \"He has a lightning-shaped scar on his forehead.\",\\\n    \"He is the son of James and Lily Potter.\",\\\n    \"He attended Hogwarts School of Witchcraft and Wizardry.\",\\\n    \"He is a skilled wizard and sorcerer.\",\\\n    \"He fought against Lord Voldemort and his followers.\",\\\n    \"He has a pet owl named Snowy.\"\\\n  ]\n}\n\"\"\"\n\n```\n\nThis example demonstrates how to use Instructor with Ollama, a local LLM server, to generate structured outputs. By leveraging Instructor's capabilities, we can easily extract structured information from the LLM's responses, making it simpler to work with the generated data in our applications.\n\n## Further Reading [¶](https://python.useinstructor.com/examples/ollama/?q=\\#further-reading \"Permanent link\")\n\nTo explore more about Instructor and its various applications, consider checking out the following resources:\n\n1. [Why use Instructor?](https://python.useinstructor.com/why/) \\- Learn about the benefits and use cases of Instructor.\n\n2. [Concepts](https://python.useinstructor.com/concepts/models/) \\- Dive deeper into the core concepts of Instructor, including models, retrying, and validation.\n\n3. [Examples](https://python.useinstructor.com/examples/) \\- Explore our comprehensive collection of examples and integrations with various LLM providers.\n\n4. [Tutorials](https://python.useinstructor.com/tutorials/1-introduction/) \\- Step-by-step tutorials to help you get started with Instructor.\n\n5. [Learn Prompting](https://python.useinstructor.com/prompting/) \\- Techniques and strategies for effective prompt engineering with Instructor.\n\n\nBy exploring these resources, you'll gain a comprehensive understanding of Instructor's capabilities and how to leverage them in your projects.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/ollama/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/ollama/",
      "title": "Harnessing Structured Outputs with Ollama and Instructor - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/ollama/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/ollama.png",
      "ogTitle": "Harnessing Structured Outputs with Ollama and Instructor - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/ollama.png",
      "og:title": "Harnessing Structured Outputs with Ollama and Instructor - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/ollama/?q=",
      "statusCode": 200,
      "description": "Discover how to utilize Ollama's Instructor library for structured outputs in LLM applications using Pydantic models.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Discover how to utilize Ollama's Instructor library for structured outputs in LLM applications using Pydantic models.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/ollama.png",
      "twitter:title": "Harnessing Structured Outputs with Ollama and Instructor - Instructor",
      "og:description": "Discover how to utilize Ollama's Instructor library for structured outputs in LLM applications using Pydantic models.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Discover how to utilize Ollama's Instructor library for structured outputs in LLM applications using Pydantic models."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/?q=#cookbooks)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/index.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/index.md \"View source of this page\")\n\n# Cookbooks [¶](https://python.useinstructor.com/examples/?q=\\#cookbooks \"Permanent link\")\n\nWelcome to our collection of cookbooks showcasing the power of structured outputs in AI applications. These examples demonstrate how to effectively use instructor with various models and APIs to solve real-world problems.\n\n## Quick Links [¶](https://python.useinstructor.com/examples/?q=\\#quick-links \"Permanent link\")\n\n01. [Enum-Based Classification](https://python.useinstructor.com/examples/classification/): Implement structured classification using Python enums with AI models.\n02. [AI Self-Assessment and Correction](https://python.useinstructor.com/examples/self_critique/): Explore techniques for AI models to evaluate and improve their own outputs.\n03. [Efficient Batch Classification](https://python.useinstructor.com/examples/bulk_classification/): Process multiple items simultaneously for improved performance.\n04. [Precise Citation Extraction](https://python.useinstructor.com/examples/exact_citations/): Accurately retrieve and format citations from text using AI.\n05. [Search Query Segmentation](https://python.useinstructor.com/examples/search/): Break down complex search queries into structured components for better understanding.\n06. [Dynamic Knowledge Graph Generation](https://python.useinstructor.com/examples/knowledge_graph/): Create visual representations of information relationships using AI.\n07. [Complex Query Decomposition](https://python.useinstructor.com/examples/planning-tasks/): Break down intricate queries into manageable subtasks for thorough analysis.\n08. [Entity Extraction and Resolution](https://python.useinstructor.com/examples/entity_resolution/): Identify and disambiguate named entities in text.\n09. [PII Sanitization](https://python.useinstructor.com/examples/pii/): Detect and redact sensitive personal information from text data.\n10. [Action Item Extraction](https://python.useinstructor.com/examples/planning-tasks/): Generate structured task lists and relationships from meeting transcripts.\n11. [OpenAI Content Moderation Integration](https://python.useinstructor.com/examples/moderation/): Implement content filtering using OpenAI's moderation API.\n12. [Table Extraction with GPT-Vision](https://python.useinstructor.com/examples/extracting_tables/): Convert image-based tables into structured data using AI vision capabilities.\n13. [AI-Powered Ad Copy Generation from Images](https://python.useinstructor.com/examples/image_to_ad_copy/): Create compelling advertising text based on visual content.\n14. [Local AI with Ollama Integration](https://python.useinstructor.com/examples/ollama/): Utilize open-source language models for on-device processing.\n15. [Database Integration with SQLModel](https://python.useinstructor.com/examples/sqlmodel/): Seamlessly store AI-generated responses in SQL databases.\n16. [LLM-Based Document Segmentation](https://python.useinstructor.com/examples/document_segmentation/): Intelligently divide long documents into meaningful sections.\n17. [Cost Optimization with OpenAI's Batch API](https://python.useinstructor.com/examples/batch_job_oai/): Reduce API costs by processing multiple requests efficiently.\n18. [Groq Cloud API Integration](https://python.useinstructor.com/examples/groq/): Leverage Groq's high-performance AI inference platform.\n19. [Mistral and Mixtral Model Usage](https://python.useinstructor.com/examples/mistral/): Implement state-of-the-art open-source language models in your projects.\n20. [Multi-Modal AI with Gemini](https://python.useinstructor.com/examples/multi_modal_gemini/): Process and analyze text, images, and other data types simultaneously.\n21. [IBM watsonx.ai Integration](https://python.useinstructor.com/examples/watsonx/): Utilize IBM's enterprise AI platform for advanced language processing tasks.\n22. [Receipt Information Extraction with GPT-4 Vision](https://python.useinstructor.com/examples/extracting_receipts/): Extract structured data from receipt images using advanced AI vision capabilities.\n23. [Slide Content Extraction with GPT-4 Vision](https://python.useinstructor.com/examples/extract_slides/): Convert presentation slide images into structured, analyzable text data.\n24. [Few-Shot Learning with Examples](https://python.useinstructor.com/examples/examples/): Improve AI model performance by providing contextual examples in prompts.\n25. [Local Classification without API](https://python.useinstructor.com/examples/local_classification/): Perform text classification tasks locally without relying on external API calls.\n26. [Action Items Extraction](https://python.useinstructor.com/examples/action_items/): Extract structured action items and tasks from text content.\n27. [Batch Classification with LangSmith](https://python.useinstructor.com/examples/batch_classification_langsmith/): Efficiently classify content in batches using LangSmith integration.\n28. [Contact Information Extraction](https://python.useinstructor.com/examples/extract_contact_info/): Extract structured contact details from unstructured text.\n29. [Knowledge Graph Building](https://python.useinstructor.com/examples/building_knowledge_graph.md): Create and manipulate knowledge graphs from textual data.\n30. [Multiple Classification Tasks](https://python.useinstructor.com/examples/multiple_classification/): Handle multiple classification categories simultaneously.\n31. [Pandas DataFrame Integration](https://python.useinstructor.com/examples/pandas_df/): Work with structured data using Pandas DataFrames.\n32. [Partial Response Streaming](https://python.useinstructor.com/examples/partial_streaming/): Stream partial results for real-time processing.\n33. [Single Classification Tasks](https://python.useinstructor.com/examples/single_classification/): Implement focused single-category classification.\n34. [Table Extraction from Images](https://python.useinstructor.com/examples/tables_from_vision/): Convert visual tables into structured data formats.\n35. [YouTube Clip Analysis](https://python.useinstructor.com/examples/youtube_clips/): Extract and analyze information from YouTube video clips.\n\n## Subscribe to our Newsletter for Updates and Tips [¶](https://python.useinstructor.com/examples/?q=\\#subscribe-to-our-newsletter-for-updates-and-tips \"Permanent link\")\n\nIf you want to get updates on new features and tips on how to use Instructor, you can subscribe to our newsletter below to get notified when we publish new content.\n\nEmail\n\nSubscribe\n\nWas this page helpful?",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/",
      "title": "Comprehensive AI Cookbook Collection - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/",
      "robots": "noindex",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/index.png",
      "ogTitle": "Comprehensive AI Cookbook Collection - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/index.png",
      "og:title": "Comprehensive AI Cookbook Collection - Instructor",
      "viewport": [
        "width=device-width,initial-scale=1",
        "width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"
      ],
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/?q=",
      "statusCode": 200,
      "description": "Explore diverse AI applications with cookbooks showcasing structured techniques for improved performance and efficiency.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Explore diverse AI applications with cookbooks showcasing structured techniques for improved performance and efficiency.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/index.png",
      "twitter:title": "Comprehensive AI Cookbook Collection - Instructor",
      "og:description": "Explore diverse AI applications with cookbooks showcasing structured techniques for improved performance and efficiency.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Explore diverse AI applications with cookbooks showcasing structured techniques for improved performance and efficiency."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/building_knowledge_graphs/?q=#building-knowledge-graphs-from-textual-data)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/building_knowledge_graphs.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/building_knowledge_graphs.md \"View source of this page\")\n\n# Building Knowledge Graphs from Textual Data [¶](https://python.useinstructor.com/examples/building_knowledge_graphs/?q=\\#building-knowledge-graphs-from-textual-data \"Permanent link\")\n\nIn this tutorial, we will explore the process of constructing knowledge graphs from textual data using OpenAI's API and Pydantic. This approach is crucial for efficiently automating the extraction of structured information from unstructured text.\n\n```md-code__content\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom openai import OpenAI\nimport instructor\n\nclass Node(BaseModel):\n    id: int\n    label: str\n    color: str = \"blue\"  # Default color set to blue\n\nclass Edge(BaseModel):\n    source: int\n    target: int\n    label: str\n    color: str = \"black\"  # Default color for edges\n\nclass KnowledgeGraph(BaseModel):\n    nodes: List[Node] = Field(default_factory=list)\n    edges: List[Edge] = Field(default_factory=list)\n\n# Patch the OpenAI client to add response_model support\nclient = instructor.from_openai(OpenAI())\n\ndef generate_graph(input_text: str) -> KnowledgeGraph:\n    \"\"\"Generates a knowledge graph from the input text.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Help me understand the following by describing it as a detailed knowledge graph: {input_text}\",\\\n            }\\\n        ],\n        response_model=KnowledgeGraph,\n    )\n\nif __name__ == \"__main__\":\n    input_text = \"Jason is Sarah's friend and he is a doctor\"\n    graph = generate_graph(input_text)\n    print(graph.model_dump_json(indent=2))\n    \"\"\"\n    {\n      \"nodes\": [\\\n        {\\\n          \"id\": 1,\\\n          \"label\": \"Jason\",\\\n          \"color\": \"blue\"\\\n        },\\\n        {\\\n          \"id\": 2,\\\n          \"label\": \"Sarah\",\\\n          \"color\": \"blue\"\\\n        },\\\n        {\\\n          \"id\": 3,\\\n          \"label\": \"Doctor\",\\\n          \"color\": \"blue\"\\\n        }\\\n      ],\n      \"edges\": [\\\n        {\\\n          \"source\": 1,\\\n          \"target\": 2,\\\n          \"label\": \"is a friend of\",\\\n          \"color\": \"black\"\\\n        },\\\n        {\\\n          \"source\": 1,\\\n          \"target\": 3,\\\n          \"label\": \"is a\",\\\n          \"color\": \"black\"\\\n        }\\\n      ]\n    }\n    \"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/building_knowledge_graphs/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/building_knowledge_graphs/",
      "title": "Building Knowledge Graphs from Text - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/building_knowledge_graphs/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/building_knowledge_graphs.png",
      "ogTitle": "Building Knowledge Graphs from Text - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/building_knowledge_graphs.png",
      "og:title": "Building Knowledge Graphs from Text - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/building_knowledge_graphs/?q=",
      "statusCode": 200,
      "description": "Learn to construct knowledge graphs from textual data using OpenAI's API and Pydantic in this comprehensive tutorial.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to construct knowledge graphs from textual data using OpenAI's API and Pydantic in this comprehensive tutorial.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/building_knowledge_graphs.png",
      "twitter:title": "Building Knowledge Graphs from Text - Instructor",
      "og:description": "Learn to construct knowledge graphs from textual data using OpenAI's API and Pydantic in this comprehensive tutorial.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to construct knowledge graphs from textual data using OpenAI's API and Pydantic in this comprehensive tutorial."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/document_segmentation/?q=#document-segmentation)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/document_segmentation.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/document_segmentation.md \"View source of this page\")\n\n* * *\n\ntitle: Document Segmentation with LLMs: A Comprehensive Guide description: Learn effective document segmentation techniques using Cohere's LLM, enhancing comprehension of complex texts.\n\n* * *\n\n# Document Segmentation [¶](https://python.useinstructor.com/examples/document_segmentation/?q=\\#document-segmentation \"Permanent link\")\n\nIn this guide, we demonstrate how to do document segmentation using structured output from an LLM. We'll be using [command-r-plus](https://docs.cohere.com/docs/command-r-plus) \\- one of Cohere's latest LLMs with 128k context length and testing the approach on an article explaining the Transformer architecture. Same approach to document segmentation can be applied to any other domain where we need to break down a complex long document into smaller chunks.\n\nMotivation\n\nSometimes we need a way to split the document into meaningful parts that center around a single key concept/idea. Simple length-based / rule-based text-splitters are not reliable enough. Consider the cases where documents contain code snippets or math equations - we don't want to split those on `'\\n\\n'` or have to write extensive rules for different types of documents. It turns out that LLMs with sufficiently long context length are well suited for this task.\n\n## Defining the Data Structures [¶](https://python.useinstructor.com/examples/document_segmentation/?q=\\#defining-the-data-structures \"Permanent link\")\n\nFirst, we need to define a **`Section`** class for each of the document's segments. **`StructuredDocument`** class will then encapsulate a list of these sections.\n\nNote that in order to avoid LLM regenerating the content of each section, we can simply enumerate each line of the input document and then ask LLM to segment it by providing start-end line numbers for each section.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass Section(BaseModel):\n    title: str = Field(description=\"main topic of this section of the document\")\n    start_index: int = Field(description=\"line number where the section begins\")\n    end_index: int = Field(description=\"line number where the section ends\")\n\nclass StructuredDocument(BaseModel):\n    \"\"\"obtains meaningful sections, each centered around a single concept/topic\"\"\"\n\n    sections: List[Section] = Field(description=\"a list of sections of the document\")\n\n```\n\n## Document Preprocessing [¶](https://python.useinstructor.com/examples/document_segmentation/?q=\\#document-preprocessing \"Permanent link\")\n\nPreprocess the input `document` by prepending each line with its number.\n\n```md-code__content\ndef doc_with_lines(document):\n    document_lines = document.split(\"\\n\")\n    document_with_line_numbers = \"\"\n    line2text = {}\n    for i, line in enumerate(document_lines):\n        document_with_line_numbers += f\"[{i}] {line}\\n\"\n        line2text[i] = line\n    return document_with_line_numbers, line2text\n\n```\n\n## Segmentation [¶](https://python.useinstructor.com/examples/document_segmentation/?q=\\#segmentation \"Permanent link\")\n\nNext use a Cohere client to extract `StructuredDocument` from the preprocessed doc.\n\n```md-code__content\nimport instructor\nimport cohere\n\n# Apply the patch to the cohere client\n# enables response_model keyword\nclient = instructor.from_cohere(cohere.Client())\n\nsystem_prompt = f\"\"\"\\\nYou are a world class educator working on organizing your lecture notes.\nRead the document below and extract a StructuredDocument object from it where each section of the document is centered around a single concept/topic that can be taught in one lesson.\nEach line of the document is marked with its line number in square brackets (e.g. [1], [2], [3], etc). Use the line numbers to indicate section start and end.\n\"\"\"\n\ndef get_structured_document(document_with_line_numbers) -> StructuredDocument:\n    return client.chat.completions.create(\n        model=\"command-r-plus\",\n        response_model=StructuredDocument,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": system_prompt,\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": document_with_line_numbers,\\\n            },\\\n        ],\n    )  # type: ignore\n\n```\n\nNext, we need to get back the section text based on the start/end indices and our `line2text` dict from the preprocessing step.\n\n```md-code__content\ndef get_sections_text(structured_doc, line2text):\n    segments = []\n    for s in structured_doc.sections:\n        contents = []\n        for line_id in range(s.start_index, s.end_index):\n            contents.append(line2text.get(line_id, ''))\n        segments.append(\n            {\n                \"title\": s.title,\n                \"content\": \"\\n\".join(contents),\n                \"start\": s.start_index,\n                \"end\": s.end_index,\n            }\n        )\n    return segments\n\n```\n\n## Example [¶](https://python.useinstructor.com/examples/document_segmentation/?q=\\#example \"Permanent link\")\n\nHere's an example of using these classes and functions to segment a tutorial on Transformers from [Sebastian Raschka](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html). We can use `trafilatura` package to scrape the web page content of the article.\n\n```md-code__content\nfrom trafilatura import fetch_url, extract\n\nurl = 'https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html'\ndownloaded = fetch_url(url)\ndocument = extract(downloaded)\n\ndocument_with_line_numbers, line2text = doc_with_lines(document)\nstructured_doc = get_structured_document(document_with_line_numbers)\nsegments = get_sections_text(structured_doc, line2text)\n\n```\n\n```md-code__content\nprint(segments[5]['title'])\n\"\"\"\nIntroduction to Multi-Head Attention\n\"\"\"\nprint(segments[5]['content'])\n\"\"\"\nMulti-Head Attention\nIn the very first figure, at the top of this article, we saw that transformers use a module called multi-head attention. How does that relate to the self-attention mechanism (scaled-dot product attention) we walked through above?\nIn the scaled dot-product attention, the input sequence was transformed using three matrices representing the query, key, and value. These three matrices can be considered as a single attention head in the context of multi-head attention. The figure below summarizes this single attention head we covered previously:\nAs its name implies, multi-head attention involves multiple such heads, each consisting of query, key, and value matrices. This concept is similar to the use of multiple kernels in convolutional neural networks.\nTo illustrate this in code, suppose we have 3 attention heads, so we now extend the \\(d' \\times d\\) dimensional weight matrices so \\(3 \\times d' \\times d\\):\nIn:\nh = 3\nmultihead_W_query = torch.nn.Parameter(torch.rand(h, d_q, d))\nmultihead_W_key = torch.nn.Parameter(torch.rand(h, d_k, d))\nmultihead_W_value = torch.nn.Parameter(torch.rand(h, d_v, d))\nConsequently, each query element is now \\(3 \\times d_q\\) dimensional, where \\(d_q=24\\) (here, let’s keep the focus on the 3rd element corresponding to index position 2):\nIn:\nmultihead_query_2 = multihead_W_query.matmul(x_2)\nprint(multihead_query_2.shape)\nOut:\ntorch.Size([3, 24])\n\"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/document_segmentation/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/document_segmentation/",
      "title": "Intelligent Document Segmentation - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/document_segmentation/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/document_segmentation.png",
      "ogTitle": "Intelligent Document Segmentation - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/document_segmentation.png",
      "og:title": "Intelligent Document Segmentation - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/document_segmentation/?q=",
      "statusCode": 200,
      "description": "A lightweight library for structured outputs with LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "A lightweight library for structured outputs with LLMs.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/document_segmentation.png",
      "twitter:title": "Intelligent Document Segmentation - Instructor",
      "og:description": "A lightweight library for structured outputs with LLMs.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "A lightweight library for structured outputs with LLMs."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/multi_modal_gemini/?q=#using-gemini-with-multi-modal-data)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/multi_modal_gemini.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/multi_modal_gemini.md \"View source of this page\")\n\n# Using Gemini with Multi Modal Data [¶](https://python.useinstructor.com/examples/multi_modal_gemini/?q=\\#using-gemini-with-multi-modal-data \"Permanent link\")\n\nThis tutorial shows how to use `instructor` with `google-generativeai` to work with multi-modal data. In this example, we'll demonstrate three ways to work with audio files.\n\nWe'll be using this [recording](https://storage.googleapis.com/generativeai-downloads/data/State_of_the_Union_Address_30_January_1961.mp3) that's taken from the [Google Generative AI cookbook](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb).\n\n## Normal Message [¶](https://python.useinstructor.com/examples/multi_modal_gemini/?q=\\#normal-message \"Permanent link\")\n\nThe first way to work with audio files is to upload the entire audio file and pass it into the LLM as a normal message. This is the easiest way to get started and doesn't require any special setup.\n\n```md-code__content\n\n```\n\n1. Make sure to set the mode to `GEMINI_JSON`, this is important because Tool Calling doesn't work with multi-modal inputs.\n2. Use `genai.upload_file` to upload your file. If you've already uploaded the file, you can get it by using `genai.get_file`\n3. Pass in the file object as any normal user message\n\n## Inline Audio Segment [¶](https://python.useinstructor.com/examples/multi_modal_gemini/?q=\\#inline-audio-segment \"Permanent link\")\n\nMaximum File Size\n\nWhen uploading and working with audio, there is a maximum file size that we can upload to the api as an inline segment. You'll know when this error is thrown below.\n\n```md-code__content\ngoogle.api_core.exceptions.InvalidArgument: 400 Request payload size exceeds the limit: 20971520 bytes. Please upload your files with the File API instead.`f = genai.upload_file(path); m.generate_content(['tell me about this file:', f])`\n\n```\n\nWhen it comes to video files, we recommend using the file.upload method as shown in the example above.\n\nSecondly, we can also pass in a audio segment as a normal message as an inline object as shown below. This requires you to install the `pydub` library in order to do so.\n\n```md-code__content\nimport instructor\nimport google.generativeai as genai\nfrom pydantic import BaseModel\nfrom pydub import AudioSegment\n\nclient = instructor.from_gemini(\n    client=genai.GenerativeModel(\n        model_name=\"models/gemini-1.5-flash-latest\",\n    ),\n    mode=instructor.Mode.GEMINI_JSON,\n)\n\nsound = AudioSegment.from_mp3(\"sample.mp3\")\nsound = sound[:60000]\n\nclass Transcription(BaseModel):\n    summary: str\n    exact_transcription: str\n\nresp = client.create(\n    response_model=Transcription,\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": \"Please transcribe this recording\",\\\n        },\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": {\\\n                \"mime_type\": \"audio/mp3\",\\\n                \"data\": sound.export().read(),\\\n            },\\\n        },\\\n    ],\n)\n\nprint(resp)\n\"\"\"\nsummary='President addresses the joint session of Congress,  reflecting on his first time taking the oath of federal office and the knowledge and inspiration gained.' exact_transcription=\"The President's state of the union address to a joint session of the Congress from the rostrum of the House of Representatives, Washington D.C. January 30th 1961 Speaker, Mr Vice President members of the Congress It is a pleasure to return from whence I came You are among my oldest friends in Washington And this house is my oldest home It was here it was here more than 14 years ago that I first took the oath of federal office It was here for 14 years that I gained both knowledge and inspiration from members of both\"\n\"\"\"\n\n#> summary='President delivers a speech to a joint session of Congress,\n#> highlighting his history in the House of Representatives and thanking\n#> the members of Congress for their guidance.',\n# >\n#> exact_transcription=\"The President's State of the Union address to a\n#> joint session of the Congress from the rostrum of the House of\n#> Representatives, Washington DC, January 30th 1961. Mr. Speaker, Mr.\n#> Vice-President, members of the Congress, it is a pleasure to return\n#> from whence I came. You are among my oldest friends in Washington,\n#> and this house is my oldest home. It was here that I first took the\n#> oath of federal office. It was here for 14 years that I gained both\n#> knowledge and inspiration from members of both\"\n\n```\n\n## Lists of Content [¶](https://python.useinstructor.com/examples/multi_modal_gemini/?q=\\#lists-of-content \"Permanent link\")\n\nWe also support passing in these as a single list as per the documentation for `google-generativeai`. Here's how to do so with a audio segment snippet from the same recording.\n\nNote that the list can contain normal user messages as well as file objects. It's incredibly flexible.\n\n```md-code__content\nimport instructor\nimport google.generativeai as genai\nfrom pydantic import BaseModel\n\nclient = instructor.from_gemini(\n    client=genai.GenerativeModel(\n        model_name=\"models/gemini-1.5-flash-latest\",\n    ),\n    mode=instructor.Mode.GEMINI_JSON,\n)\n\nmp3_file = genai.upload_file(\"./sample.mp3\")\n\nclass Description(BaseModel):\n    description: str\n\ncontent = [\\\n    \"Summarize what's happening in this audio file and who the main speaker is\",\\\n    mp3_file,\\\n]\n\nresp = client.create(\n    response_model=Description,\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": content,\\\n        }\\\n    ],\n)\n\nprint(resp)\n\"\"\"\ndescription = 'President John F. Kennedy delivers his State of the Union address to the Congress on January 30, 1961. The speech was delivered at the rostrum of the House of Representatives in Washington, D.C.'\n\"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/multi_modal_gemini/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/multi_modal_gemini/",
      "title": "Utilizing Gemini for Multi-Modal Data Processing with Audio Files - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/multi_modal_gemini/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/multi_modal_gemini.png",
      "ogTitle": "Utilizing Gemini for Multi-Modal Data Processing with Audio Files - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/multi_modal_gemini.png",
      "og:title": "Utilizing Gemini for Multi-Modal Data Processing with Audio Files - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/multi_modal_gemini/?q=",
      "statusCode": 200,
      "description": "Learn how to use Gemini with Google Generative AI to process audio files efficiently in multi-modal applications.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use Gemini with Google Generative AI to process audio files efficiently in multi-modal applications.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/multi_modal_gemini.png",
      "twitter:title": "Utilizing Gemini for Multi-Modal Data Processing with Audio Files - Instructor",
      "og:description": "Learn how to use Gemini with Google Generative AI to process audio files efficiently in multi-modal applications.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use Gemini with Google Generative AI to process audio files efficiently in multi-modal applications."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/batch_classification_langsmith/?q=#seamless-support-with-langsmith)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/batch_classification_langsmith.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/batch_classification_langsmith.md \"View source of this page\")\n\n# Seamless Support with Langsmith [¶](https://python.useinstructor.com/examples/batch_classification_langsmith/?q=\\#seamless-support-with-langsmith \"Permanent link\")\n\nIts a common misconception that LangChain's [LangSmith](https://www.langchain.com/langsmith) is only compatible with LangChain's models. In reality, LangSmith is a unified DevOps platform for developing, collaborating, testing, deploying, and monitoring LLM applications. In this blog we will explore how LangSmith can be used to enhance the OpenAI client alongside `instructor`.\n\nFirst, install the necessary packages:\n\n```md-code__content\npip install -U langsmith\n\n```\n\n## LangSmith [¶](https://python.useinstructor.com/examples/batch_classification_langsmith/?q=\\#langsmith \"Permanent link\")\n\nIn order to use langsmith, you first need to set your LangSmith API key.\n\n```md-code__content\nexport LANGCHAIN_API_KEY=<your-api-key>\n\n```\n\nNext, you will need to install the LangSmith SDK:\n\n```md-code__content\npip install -U langsmith\npip install -U instructor\n\n```\n\nIn this example we'll use the `wrap_openai` function to wrap the OpenAI client with LangSmith. This will allow us to use LangSmith's observability and monitoring features with the OpenAI client. Then we'll use `instructor` to patch the client with the `TOOLS` mode. This will allow us to use `instructor` to add additional functionality to the client.\n\n```md-code__content\nimport instructor\nimport asyncio\n\nfrom langsmith import traceable\nfrom langsmith.wrappers import wrap_openai\n\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field, field_validator\nfrom typing import List\nfrom enum import Enum\n\n# Wrap the OpenAI client with LangSmith\nclient = wrap_openai(AsyncOpenAI())\n\n# Patch the client with instructor\nclient = instructor.from_openai(client)\n\n# Rate limit the number of requests\nsem = asyncio.Semaphore(5)\n\n# Use an Enum to define the types of questions\nclass QuestionType(Enum):\n    CONTACT = \"CONTACT\"\n    TIMELINE_QUERY = \"TIMELINE_QUERY\"\n    DOCUMENT_SEARCH = \"DOCUMENT_SEARCH\"\n    COMPARE_CONTRAST = \"COMPARE_CONTRAST\"\n    EMAIL = \"EMAIL\"\n    PHOTOS = \"PHOTOS\"\n    SUMMARY = \"SUMMARY\"\n\n# You can add more instructions and examples in the description\n# or you can put it in the prompt in `messages=[...]`\nclass QuestionClassification(BaseModel):\n    \"\"\"\n    Predict the type of question that is being asked.\n    Here are some tips on how to predict the question type:\n    CONTACT: Searches for some contact information.\n    TIMELINE_QUERY: \"When did something happen?\n    DOCUMENT_SEARCH: \"Find me a document\"\n    COMPARE_CONTRAST: \"Compare and contrast two things\"\n    EMAIL: \"Find me an email, search for an email\"\n    PHOTOS: \"Find me a photo, search for a photo\"\n    SUMMARY: \"Summarize a large amount of data\"\n    \"\"\"\n\n    # If you want only one classification, just change it to\n    #   `classification: QuestionType` rather than `classifications: List[QuestionType]``\n    chain_of_thought: str = Field(\n        ..., description=\"The chain of thought that led to the classification\"\n    )\n    classification: List[QuestionType] = Field(\n        description=f\"An accuracy and correct prediction predicted class of question. Only allowed types: {[t.value for t in QuestionType]}, should be used\",\n    )\n\n    @field_validator(\"classification\", mode=\"before\")\n    def validate_classification(cls, v):\n        # sometimes the API returns a single value, just make sure it's a list\n        if not isinstance(v, list):\n            v = [v]\n        return v\n\n@traceable(name=\"classify-question\")\nasync def classify(data: str) -> QuestionClassification:\n    \"\"\"\n    Perform multi-label classification on the input text.\n    Change the prompt to fit your use case.\n    Args:\n        data (str): The input text to classify.\n    \"\"\"\n    async with sem:  # some simple rate limiting\n        return data, await client.chat.completions.create(\n            model=\"gpt-4-turbo-preview\",\n            response_model=QuestionClassification,\n            max_retries=2,\n            messages=[\\\n                {\\\n                    \"role\": \"user\",\\\n                    \"content\": f\"Classify the following question: {data}\",\\\n                },\\\n            ],\n        )\n\nasync def main(questions: List[str]):\n    tasks = [classify(question) for question in questions]\n\n    for task in asyncio.as_completed(tasks):\n        question, label = await task\n        resp = {\n            \"question\": question,\n            \"classification\": [c.value for c in label.classification],\n            \"chain_of_thought\": label.chain_of_thought,\n        }\n        resps.append(resp)\n    return resps\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    questions = [\\\n        \"What was that ai app that i saw on the news the other day?\",\\\n        \"Can you find the trainline booking email?\",\\\n        \"what did I do on Monday?\",\\\n        \"Tell me about todays meeting and how it relates to the email on Monday\",\\\n    ]\n\n    resp = asyncio.run(main(questions))\n\n    for r in resp:\n        print(\"q:\", r[\"question\"])\n        #> q: what did I do on Monday?\n        print(\"c:\", r[\"classification\"])\n        #> c: ['SUMMARY']\n\n```\n\nIf you follow what we've done is wrapped the client and proceeded to quickly use asyncio to classify a list of questions. This is a simple example of how you can use LangSmith to enhance the OpenAI client. You can use LangSmith to monitor and observe the client, and use `instructor` to add additional functionality to the client.\n\nTo take a look at trace of this run check out this shareable [link](https://smith.langchain.com/public/eaae9f95-3779-4bbb-824d-97aa8a57a4e0/r).\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/batch_classification_langsmith/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/batch_classification_langsmith/",
      "title": "Enhancing OpenAI Client with LangSmith and Instructor - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/batch_classification_langsmith/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/batch_classification_langsmith.png",
      "ogTitle": "Enhancing OpenAI Client with LangSmith and Instructor - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/batch_classification_langsmith.png",
      "og:title": "Enhancing OpenAI Client with LangSmith and Instructor - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/batch_classification_langsmith/?q=",
      "statusCode": 200,
      "description": "Discover how to integrate LangSmith with the OpenAI client for improved observability and functionality using instructor.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Discover how to integrate LangSmith with the OpenAI client for improved observability and functionality using instructor.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/batch_classification_langsmith.png",
      "twitter:title": "Enhancing OpenAI Client with LangSmith and Instructor - Instructor",
      "og:description": "Discover how to integrate LangSmith with the OpenAI client for improved observability and functionality using instructor.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Discover how to integrate LangSmith with the OpenAI client for improved observability and functionality using instructor."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/youtube_clips/?q=#generating-youtube-clips-from-transcripts)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/youtube_clips.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/youtube_clips.md \"View source of this page\")\n\n# Generating YouTube Clips from Transcripts [¶](https://python.useinstructor.com/examples/youtube_clips/?q=\\#generating-youtube-clips-from-transcripts \"Permanent link\")\n\nThis guide demonstrates how to generate concise, informative clips from YouTube video transcripts using the `instructor` library. By leveraging the power of OpenAI's models, we can extract meaningful segments from a video's transcript, which can then be recut into smaller, standalone videos. This process involves identifying key moments within a transcript and summarizing them into clips with specific titles and descriptions.\n\nFirst, install the necessary packages:\n\n```md-code__content\npip install youtube_transcript_api instructor rich\n\n```\n\n![youtube clip streaming](https://python.useinstructor.com/img/youtube.gif)\n\n```md-code__content\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom pydantic import BaseModel, Field\nfrom typing import List, Generator, Iterable\nimport instructor\nimport openai\n\nclient = instructor.from_openai(openai.OpenAI())\n\ndef extract_video_id(url: str) -> str | None:\n    import re\n\n    match = re.search(r\"v=([a-zA-Z0-9_-]+)\", url)\n    if match:\n        return match.group(1)\n\nclass TranscriptSegment(BaseModel):\n    source_id: int\n    start: float\n    text: str\n\ndef get_transcript_with_timing(\n    video_id: str,\n) -> Generator[TranscriptSegment, None, None]:\n    \"\"\"\n    Fetches the transcript of a YouTube video along with the start and end times\n    for each text segment, and returns them as a list of Pydantic models.\n    \"\"\"\n    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n    for ii, segment in enumerate(transcript):\n        yield TranscriptSegment(\n            source_id=ii, start=segment[\"start\"], text=segment[\"text\"]\n        )\n\nclass YoutubeClip(BaseModel):\n    title: str = Field(description=\"Specific and informative title for the clip.\")\n    description: str = Field(\n        description=\"A detailed description of the clip, including notable quotes or phrases.\"\n    )\n    start: float\n    end: float\n\nclass YoutubeClips(BaseModel):\n    clips: List[YoutubeClip]\n\ndef yield_clips(segments: Iterable[TranscriptSegment]) -> Iterable[YoutubeClips]:\n    return client.chat.completions.create(\n        model=\"gpt-4-turbo-preview\",\n        stream=True,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"\"\"You are given a sequence of YouTube transcripts and your job\\\n                is to return notable clips that can be recut as smaller videos. Give very\\\n                specific titles and descriptions. Make sure the length of clips is proportional\\\n                to the length of the video. Note that this is a transcript and so there might\\\n                be spelling errors. Note that and correct any spellings. Use the context to\\\n                make sure you're spelling things correctly.\"\"\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Let's use the following transcript segments.\\n{segments}\",\\\n            },\\\n        ],\n        response_model=instructor.Partial[YoutubeClips],\n        validation_context={\"segments\": segments},\n    )  # type: ignore\n\n# Example usage\nif __name__ == \"__main__\":\n    from rich.table import Table\n    from rich.console import Console\n    from rich.prompt import Prompt\n\n    console = Console()\n    url = Prompt.ask(\"Enter a YouTube URL\")\n\n    with console.status(\"[bold green]Processing YouTube URL...\") as status:\n        video_id = extract_video_id(url)\n\n        if video_id is None:\n            raise ValueError(\"Invalid YouTube video URL\")\n\n        transcript = list(get_transcript_with_timing(video_id))\n        status.update(\"[bold green]Generating clips...\")\n\n        for clip in yield_clips(transcript):\n            console.clear()\n\n            table = Table(title=\"Extracted YouTube Clips\", padding=(0, 1))\n\n            table.add_column(\"Title\", style=\"cyan\")\n            table.add_column(\"Description\", style=\"magenta\")\n            table.add_column(\"Start\", justify=\"right\", style=\"green\")\n            table.add_column(\"End\", justify=\"right\", style=\"green\")\n            for youtube_clip in clip.clips or []:\n                table.add_row(\n                    youtube_clip.title,\n                    youtube_clip.description,\n                    str(youtube_clip.start),\n                    str(youtube_clip.end),\n                )\n            console.print(table)\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/youtube_clips/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/youtube_clips/",
      "title": "Generating YouTube Clips from Transcripts Using Instructor - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/youtube_clips/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/youtube_clips.png",
      "ogTitle": "Generating YouTube Clips from Transcripts Using Instructor - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/youtube_clips.png",
      "og:title": "Generating YouTube Clips from Transcripts Using Instructor - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/youtube_clips/?q=",
      "statusCode": 200,
      "description": "Learn to create concise YouTube clips from video transcripts with `instructor` and OpenAI, enhancing your content engagement.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to create concise YouTube clips from video transcripts with `instructor` and OpenAI, enhancing your content engagement.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/youtube_clips.png",
      "twitter:title": "Generating YouTube Clips from Transcripts Using Instructor - Instructor",
      "og:description": "Learn to create concise YouTube clips from video transcripts with `instructor` and OpenAI, enhancing your content engagement.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to create concise YouTube clips from video transcripts with `instructor` and OpenAI, enhancing your content engagement."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/image_to_ad_copy/?q=#use-vision-api-to-detect-products-and-generate-advertising-copy)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/image_to_ad_copy.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/image_to_ad_copy.md \"View source of this page\")\n\n# Use Vision API to detect products and generate advertising copy [¶](https://python.useinstructor.com/examples/image_to_ad_copy/?q=\\#use-vision-api-to-detect-products-and-generate-advertising-copy \"Permanent link\")\n\nThis post demonstrates how to use GPT-4 Vision API and the Chat API to automatically generate advertising copy from product images. This method can be useful for marketing and advertising teams, as well as for e-commerce platforms.\n\nThe full code is available on [GitHub](https://www.github.com/jxnl/instructor/tree/main/examples/vision/image_to_ad_copy.py).\n\n## Building the models [¶](https://python.useinstructor.com/examples/image_to_ad_copy/?q=\\#building-the-models \"Permanent link\")\n\n### Product [¶](https://python.useinstructor.com/examples/image_to_ad_copy/?q=\\#product \"Permanent link\")\n\nFor the `Product` model, we define a class that represents a product extracted from an image and store the name, key features, and description. The product attributes are dynamically determined based on the content of the image.\n\nNote that it is easy to add [Validators](https://jxnl.github.io/instructor/concepts/reask_validation/) and other Pydantic features to the model to ensure that the data is valid and consistent.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Product(BaseModel):\n    \"\"\"\n    Represents a product extracted from an image using AI.\n\n    The product attributes are dynamically determined based on the content\n    of the image and the AI's interpretation. This class serves as a structured\n    representation of the identified product characteristics.\n    \"\"\"\n\n    name: str = Field(\n        description=\"A generic name for the product.\", example=\"Headphones\"\n    )\n    key_features: Optional[List[str]] = Field(\n        description=\"A list of key features of the product that stand out.\",\n        default=None,\n    )\n\n    description: Optional[str] = Field(\n        description=\"A description of the product.\",\n        default=None,\n    )\n\n    # Can be customized and automatically generated\n    def generate_prompt(self):\n        prompt = f\"Product: {self.name}\\n\"\n        if self.description:\n            prompt += f\"Description: {self.description}\\n\"\n        if self.key_features:\n            prompt += f\"Key Features: {', '.join(self.key_features)}\\n\"\n        return prompt\n\n```\n\n### Identified Product [¶](https://python.useinstructor.com/examples/image_to_ad_copy/?q=\\#identified-product \"Permanent link\")\n\nWe also define a class that represents a list of products identified in the images. We also add an error flag and message to indicate if there was an error in the processing of the image.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\nclass IdentifiedProduct(BaseModel):\n    \"\"\"\n    Represents a list of products identified in the images.\n    \"\"\"\n\n    products: Optional[List[Product]] = Field(\n        description=\"A list of products identified by the AI.\",\n        example=[\\\n            Product(\\\n                name=\"Headphones\",\\\n                description=\"Wireless headphones with noise cancellation.\",\\\n                key_features=[\"Wireless\", \"Noise Cancellation\"],\\\n            )\\\n        ],\n        default=None,\n    )\n\n    error: bool = Field(default=False)\n    message: Optional[str] = Field(default=None)\n\n```\n\n### Advertising Copy [¶](https://python.useinstructor.com/examples/image_to_ad_copy/?q=\\#advertising-copy \"Permanent link\")\n\nFinally, the `AdCopy` models stores the output in a structured format with a headline and the text.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\n\nclass AdCopy(BaseModel):\n    \"\"\"\n    Represents a generated ad copy.\n    \"\"\"\n\n    headline: str = Field(\n        description=\"A short, catchy, and memorable headline for the given product. The headline should invoke curiosity and interest in the product.\",\n    )\n    ad_copy: str = Field(\n        description=\"A long-form advertisement copy for the given product. This will be used in campaigns to promote the product with a persuasive message and a call-to-action with the objective of driving sales.\",\n    )\n    name: str = Field(description=\"The name of the product being advertised.\")\n\n```\n\n## Calling the API [¶](https://python.useinstructor.com/examples/image_to_ad_copy/?q=\\#calling-the-api \"Permanent link\")\n\n### Product Detection [¶](https://python.useinstructor.com/examples/image_to_ad_copy/?q=\\#product-detection \"Permanent link\")\n\nThe `read_images` function uses OpenAI's vision model to process a list of image URLs and identify products in each of them. We utilize the `instructor` library to patch the OpenAI client for this purpose.\n\n```md-code__content\ndef read_images(image_urls: list[str]) -> IdentifiedProduct:\n    \"\"\"\n    Given a list of image URLs, identify the products in the images.\n    \"\"\"\n\n    logger.info(f\"Identifying products in images... {len(image_urls)} images\")\n\n    return client_image.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=IdentifiedProduct,\n        max_tokens=1024,  # can be changed\n        temperature=0,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": [\\\n                    {\\\n                        \"type\": \"text\",\\\n                        \"text\": \"Identify products using the given images and generate key features for each product.\",\\\n                    },\\\n                    *[\\\n                        {\"type\": \"image_url\", \"image_url\": {\"url\": url}}\\\n                        for url in image_urls\\\n                    ],\\\n                ],\\\n            }\\\n        ],\n    )\n\n```\n\nThis gives us a list of products identified in all the images.\n\n### Generate advertising copy [¶](https://python.useinstructor.com/examples/image_to_ad_copy/?q=\\#generate-advertising-copy \"Permanent link\")\n\nThen, we can use the `generate_ad_copy` function to generate advertising copy for each of the products identified in the images.\n\nTwo clients are defined for the two different models. This is because the `gpt-4-vision-preview` model is not compatible with the `gpt-4-1106-preview` model in terms of their response format.\n\n```md-code__content\ndef generate_ad_copy(product: Product) -> AdCopy:\n    \"\"\"\n    Given a product, generate an ad copy for the product.\n    \"\"\"\n\n    logger.info(f\"Generating ad copy for product: {product.name}\")\n\n    return client_copy.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=AdCopy,\n        temperature=0.3,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are an expert marketing assistant for all products. Your task is to generate an advertisement copy for a product using the name, description, and key features.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": product.generate_prompt()},\\\n        ],\n    )\n\n```\n\n### Putting it all together [¶](https://python.useinstructor.com/examples/image_to_ad_copy/?q=\\#putting-it-all-together \"Permanent link\")\n\nFinally, we can put it all together in a single function that takes a list of image URLs and generates advertising copy for the products identified in the images. Please refer to the [full code](https://www.github.com/jxnl/instructor/tree/main/examples/vision/image_to_ad_copy.py) for the complete implementation.\n\n## Input file [¶](https://python.useinstructor.com/examples/image_to_ad_copy/?q=\\#input-file \"Permanent link\")\n\nThe input file is currently a list of image URLs, but this trivial to change to any required format.\n\n```md-code__content\nhttps://contents.mediadecathlon.com/p1279823/9a1c59ad97a4084a346c014740ae4d3ff860ea70b485ee65f34017ff5e9ae5f7/recreational-ice-skates-fit-50-black.jpg?format=auto\nhttps://contents.mediadecathlon.com/p1279822/a730505231dbd6747c14ee93e8f89e824d3fa2a5b885ec26de8d7feb5626638a/recreational-ice-skates-fit-50-black.jpg?format=auto\nhttps://contents.mediadecathlon.com/p2329893/1ed75517602a5e00245b89ab6a1c6be6d8968a5a227c932b10599f857f3ed4cd/mens-hiking-leather-boots-sh-100-x-warm.jpg?format=auto\nhttps://contents.mediadecathlon.com/p2047870/8712c55568dd9928c83b19c6a4067bf161811a469433dc89244f0ff96a50e3e9/men-s-winter-hiking-boots-sh-100-x-warm-grey.jpg?format=auto\n\n```\n\nExpand to see the output\n\n![](https://contents.mediadecathlon.com/p1279823/9a1c59ad97a4084a346c014740ae4d3ff860ea70b485ee65f34017ff5e9ae5f7/recreational-ice-skates-fit-50-black.jpg?format=auto)![](https://contents.mediadecathlon.com/p2329893/1ed75517602a5e00245b89ab6a1c6be6d8968a5a227c932b10599f857f3ed4cd/mens-hiking-leather-boots-sh-100-x-warm.jpg?format=auto)\n\n```md-code__content\n{\n    \"products\":\n    [\\\n        {\\\n            \"name\": \"Ice Skates\",\\\n            \"key_features\": [\\\n                \"Lace-up closure\",\\\n                \"Durable blade\",\\\n                \"Ankle support\"\\\n            ],\\\n            \"description\": \"A pair of ice skates with lace-up closure for secure fit, durable blade for ice skating, and reinforced ankle support.\"\\\n        },\\\n        {\\\n            \"name\": \"Hiking Boots\",\\\n            \"key_features\": [\\\n                \"High-top design\",\\\n                \"Rugged outsole\",\\\n                \"Water-resistant\"\\\n            ],\\\n            \"description\": \"Sturdy hiking boots featuring a high-top design for ankle support, rugged outsole for grip on uneven terrain, and water-resistant construction.\"\\\n        },\\\n        {\\\n            \"name\": \"Winter Boots\",\\\n            \"key_features\": [\\\n                \"Insulated lining\",\\\n                \"Waterproof lower\",\\\n                \"Slip-resistant sole\"\\\n            ],\\\n            \"description\": \"Warm winter boots with insulated lining for cold weather, waterproof lower section to keep feet dry, and a slip-resistant sole for stability.\"\\\n        }\\\n    ],\n    \"ad_copies\": [\\\n        {\\\n            \"headline\": \"Glide with Confidence - Discover the Perfect Ice Skates!\",\\\n            \"ad_copy\": \"Step onto the ice with poise and precision with our premium Ice Skates. Designed for both beginners and seasoned skaters, these skates offer a perfect blend of comfort and performance. The lace-up closure ensures a snug fit that keeps you stable as you carve through the ice. With a durable blade that withstands the test of time, you can focus on perfecting your moves rather than worrying about your equipment. The reinforced ankle support provides the necessary protection and aids in preventing injuries, allowing you to skate with peace of mind. Whether you're practicing your spins, jumps, or simply enjoying a leisurely glide across the rink, our Ice Skates are the ideal companion for your ice adventures. Lace up and get ready to experience the thrill of ice skating like never before!\",\\\n            \"name\": \"Ice Skates\"\\\n        },\\\n        {\\\n            \"headline\": \"Conquer Every Trail with Confidence!\",\\\n            \"ad_copy\": \"Embark on your next adventure with our top-of-the-line Hiking Boots! Designed for the trail-blazing spirits, these boots boast a high-top design that provides unparalleled ankle support to keep you steady on any path. The rugged outsole ensures a firm grip on the most uneven terrains, while the water-resistant construction keeps your feet dry as you traverse through streams and muddy trails. Whether you're a seasoned hiker or just starting out, our Hiking Boots are the perfect companion for your outdoor escapades. Lace up and step into the wild with confidence - your journey awaits!\",\\\n            \"name\": \"Hiking Boots\"\\\n        },\\\n        {\\\n            \"headline\": \"Conquer the Cold with Comfort!\",\\\n            \"ad_copy\": \"Step into the season with confidence in our Winter Boots, the ultimate ally against the chill. Designed for those who don't let the cold dictate their moves, these boots feature an insulated lining that wraps your feet in a warm embrace, ensuring that the biting cold is a worry of the past. But warmth isn't their only virtue. With a waterproof lower section, your feet will remain dry and cozy, come rain, snow, or slush. And let's not forget the slip-resistant sole that stands between you and the treacherous ice, offering stability and peace of mind with every step you take. Whether you're braving a blizzard or just nipping out for a coffee, our Winter Boots are your trusty companions, keeping you warm, dry, and upright. Don't let winter slow you down. Lace up and embrace the elements!\",\\\n            \"name\": \"Winter Boots\"\\\n        }\\\n    ]\n}\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/image_to_ad_copy/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/image_to_ad_copy/",
      "title": "Automatically Generate Advertising Copy from Product Images Using GPT-4 Vision - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/image_to_ad_copy/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/image_to_ad_copy.png",
      "ogTitle": "Automatically Generate Advertising Copy from Product Images Using GPT-4 Vision - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/image_to_ad_copy.png",
      "og:title": "Automatically Generate Advertising Copy from Product Images Using GPT-4 Vision - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/image_to_ad_copy/?q=",
      "statusCode": 200,
      "description": "Learn how to use GPT-4 Vision API to create engaging advertising copy from product images, ideal for e-commerce and marketing teams.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use GPT-4 Vision API to create engaging advertising copy from product images, ideal for e-commerce and marketing teams.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/image_to_ad_copy.png",
      "twitter:title": "Automatically Generate Advertising Copy from Product Images Using GPT-4 Vision - Instructor",
      "og:description": "Learn how to use GPT-4 Vision API to create engaging advertising copy from product images, ideal for e-commerce and marketing teams.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use GPT-4 Vision API to create engaging advertising copy from product images, ideal for e-commerce and marketing teams."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/bulk_classification/?q=#bulk-classification-from-user-provided-tags)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/bulk_classification.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/bulk_classification.md \"View source of this page\")\n\n# Bulk Classification from User-Provided Tags. [¶](https://python.useinstructor.com/examples/bulk_classification/?q=\\#bulk-classification-from-user-provided-tags \"Permanent link\")\n\nThis tutorial shows how to do classification from user provided tags. This is valuable when you want to provide services that allow users to do some kind of classification.\n\nMotivation\n\nImagine allowing the user to upload documents as part of a RAG application. Oftentimes, we might want to allow the user to specify an existing set of tags, give descriptions, and do the classification for them.\n\n## Defining the Structures [¶](https://python.useinstructor.com/examples/bulk_classification/?q=\\#defining-the-structures \"Permanent link\")\n\nOne of the easy things to do is to allow users to define a set of tags in some kind of schema and save that in a database. Here's an example of a schema that we might use:\n\n| tag\\_id | name | instructions |\n| --- | --- | --- |\n| 0 | personal | Personal information |\n| 1 | phone | Phone number |\n| 2 | email | Email address |\n| 3 | address | Address |\n| 4 | Other | Other information |\n\n1. **tag\\_id** — The unique identifier for the tag.\n2. **name** — The name of the tag.\n3. **instructions** — A description of the tag, which can be used as a prompt to describe the tag.\n\n## Implementing the Classification [¶](https://python.useinstructor.com/examples/bulk_classification/?q=\\#implementing-the-classification \"Permanent link\")\n\nIn order to do this we'll do a couple of things:\n\n1. We'll use the `instructor` library to patch the `openai` library to use the `AsyncOpenAI` client.\n2. Implement a `Tag` model that will be used to validate the tags from the context. (This will allow us to avoid hallucinating tags that are not in the context.)\n3. Helper models for the request and response.\n4. An async function to do the classification.\n5. A main function to run the classification using the `asyncio.gather` function to run the classification in parallel.\n\nIf you want to learn more about how to do bad computations, check out our post on AsyncIO [here](https://python.useinstructor.com/blog/2023/11/13/learn-async/).\n\n```md-code__content\nimport openai\nimport instructor\n\nclient = instructor.from_openai(\n    openai.AsyncOpenAI(),\n)\n\n```\n\nFirst, we'll need to import all of our Pydantic and instructor code and use the AsyncOpenAI client. Then, we'll define the tag model along with the tag instructions to provide input and output.\n\nThis is very helpful because once we use something like FastAPI to create endpoints, the Pydantic functions will serve as multiple tools:\n\n1. A description for the developer\n2. Type hints for the IDE\n3. OpenAPI documentation for the FastAPI endpoint\n4. Schema and Response Model for the language model.\n\n```md-code__content\nfrom typing import List\nfrom pydantic import BaseModel, ValidationInfo, model_validator\n\nclass Tag(BaseModel):\n    id: int\n    name: str\n\n    @model_validator(mode=\"after\")\n    def validate_ids(self, info: ValidationInfo):\n        context = info.context\n        if context:\n            tags: List[Tag] = context.get(\"tags\")\n            assert self.id in {\n                tag.id for tag in tags\n            }, f\"Tag ID {self.id} not found in context\"\n            assert self.name in {\n                tag.name for tag in tags\n            }, f\"Tag name {self.name} not found in context\"\n        return self\n\nclass TagWithInstructions(Tag):\n    instructions: str\n\nclass TagRequest(BaseModel):\n    texts: List[str]\n    tags: List[TagWithInstructions]\n\nclass TagResponse(BaseModel):\n    texts: List[str]\n    predictions: List[Tag]\n\n```\n\nLet's delve deeper into what the `validate_ids` function does. Notice that its purpose is to extract tags from the context and ensure that each ID and name exists in the set of tags. This approach helps minimize hallucinations. If we mistakenly identify either the ID or the tag, an error will be thrown, and the instructor will prompt the language model to retry until the correct item is successfully extracted.\n\n```md-code__content\nfrom pydantic import model_validator, ValidationInfo\n\n@model_validator(mode=\"after\")\ndef validate_ids(self, info: ValidationInfo):\n    context = info.context\n    if context:\n        tags: List[Tag] = context.get(\"tags\")\n        assert self.id in {\n            tag.id for tag in tags\n        }, f\"Tag ID {self.id} not found in context\"\n        assert self.name in {\n            tag.name for tag in tags\n        }, f\"Tag name {self.name} not found in context\"\n    return self\n\n```\n\nNow, let's implement the function to do the classification. This function will take a single text and a list of tags and return the predicted tag.\n\n```md-code__content\nasync def tag_single_request(text: str, tags: List[Tag]) -> Tag:\n    allowed_tags = [(tag.id, tag.name) for tag in tags]\n    allowed_tags_str = \", \".join([f\"`{tag}`\" for tag in allowed_tags])\n\n    return await client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a world-class text tagging system.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": f\"Describe the following text: `{text}`\"},\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Here are the allowed tags: {allowed_tags_str}\",\\\n            },\\\n        ],\n        response_model=Tag,  # Minimizes the hallucination of tags that are not in the allowed tags.\n        validation_context={\"tags\": tags},\n    )\n\nasync def tag_request(request: TagRequest) -> TagResponse:\n    predictions = await asyncio.gather(\n        *[tag_single_request(text, request.tags) for text in request.texts]\n    )\n    return TagResponse(\n        texts=request.texts,\n        predictions=predictions,\n    )\n\n```\n\nNotice that we first define a single async function that makes a prediction of a tag, and we pass it into the validation context in order to minimize hallucinations.\n\nFinally, we'll implement the main function to run the classification using the `asyncio.gather` function to run the classification in parallel.\n\n```md-code__content\nimport asyncio\n\ntags = [\\\n    TagWithInstructions(id=0, name=\"personal\", instructions=\"Personal information\"),\\\n    TagWithInstructions(id=1, name=\"phone\", instructions=\"Phone number\"),\\\n    TagWithInstructions(id=2, name=\"email\", instructions=\"Email address\"),\\\n    TagWithInstructions(id=3, name=\"address\", instructions=\"Address\"),\\\n    TagWithInstructions(id=4, name=\"Other\", instructions=\"Other information\"),\\\n]\n\n# Texts will be a range of different questions.\n# Such as \"How much does it cost?\", \"What is your privacy policy?\", etc.\ntexts = [\\\n    \"What is your phone number?\",\\\n    \"What is your email address?\",\\\n    \"What is your address?\",\\\n    \"What is your privacy policy?\",\\\n]\n\n# The request will contain the texts and the tags.\nrequest = TagRequest(texts=texts, tags=tags)\n\n# The response will contain the texts, the predicted tags, and the confidence.\nresponse = asyncio.run(tag_request(request))\nprint(response.model_dump_json(indent=2))\n\"\"\"\n{\n  \"texts\": [\\\n    \"What is your phone number?\",\\\n    \"What is your email address?\",\\\n    \"What is your address?\",\\\n    \"What is your privacy policy?\"\\\n  ],\n  \"predictions\": [\\\n    {\\\n      \"id\": 1,\\\n      \"name\": \"phone\"\\\n    },\\\n    {\\\n      \"id\": 2,\\\n      \"name\": \"email\"\\\n    },\\\n    {\\\n      \"id\": 3,\\\n      \"name\": \"address\"\\\n    },\\\n    {\\\n      \"id\": 4,\\\n      \"name\": \"Other\"\\\n    }\\\n  ]\n}\n\"\"\"\n\n```\n\nWhich would result in:\n\n```md-code__content\n{\n  \"texts\": [\\\n    \"What is your phone number?\",\\\n    \"What is your email address?\",\\\n    \"What is your address?\",\\\n    \"What is your privacy policy?\"\\\n  ],\n  \"predictions\": [\\\n    {\\\n      \"id\": 1,\\\n      \"name\": \"phone\"\\\n    },\\\n    {\\\n      \"id\": 2,\\\n      \"name\": \"email\"\\\n    },\\\n    {\\\n      \"id\": 3,\\\n      \"name\": \"address\"\\\n    },\\\n    {\\\n      \"id\": 4,\\\n      \"name\": \"Other\"\\\n    }\\\n  ]\n}\n\n```\n\n## What happens in production? [¶](https://python.useinstructor.com/examples/bulk_classification/?q=\\#what-happens-in-production \"Permanent link\")\n\nIf we were to use this in production, we might expect to have some kind of fast API endpoint.\n\n```md-code__content\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.post(\"/tag\", response_model=TagResponse)\nasync def tag(request: TagRequest) -> TagResponse:\n    return await tag_request(request)\n\n```\n\nSince everything is already annotated with Pydantic, this code is very simple to write!\n\nWhere do tags come from?\n\nI just want to call out that here you can also imagine the tag spec IDs and names and instructions for example could come from a database or somewhere else. I'll leave this as an exercise to the reader, but I hope this gives us a clear understanding of how we can do something like user-defined classification.\n\n## Improving the Model [¶](https://python.useinstructor.com/examples/bulk_classification/?q=\\#improving-the-model \"Permanent link\")\n\nThere's a couple things we could do to make this system a little bit more robust.\n\n1. Use confidence score:\n\n```md-code__content\nclass TagWithConfidence(Tag):\n    confidence: float = Field(\n        ...,\n        ge=0,\n        le=1,\n        description=\"The confidence of the prediction, 0 is low, 1 is high\",\n    )\n\n```\n\n1. Use multiclass classification:\n\nNotice in the example we use Iterable\\[Tag\\] vs Tag. This is because we might want to use a multiclass classification model that returns multiple tag!\n\n```md-code__content\nimport instructor\nimport openai\nimport asyncio\nfrom typing import Iterable\n\nclient = instructor.from_openai(\n    openai.AsyncOpenAI(),\n)\n\ntags = [\\\n    Tag(id=0, name=\"personal\"),\\\n    Tag(id=1, name=\"phone\"),\\\n    Tag(id=2, name=\"email\"),\\\n    Tag(id=3, name=\"address\"),\\\n    Tag(id=4, name=\"Other\"),\\\n]\n\n# Texts will be a range of different questions.\n# Such as \"How much does it cost?\", \"What is your privacy policy?\", etc.\ntext = \"What is your phone number?\"\n\nasync def get_tags(text: List[str], tags: List[Tag]) -> List[Tag]:\n    allowed_tags = [(tag.id, tag.name) for tag in tags]\n    allowed_tags_str = \", \".join([f\"`{tag}`\" for tag in allowed_tags])\n\n    return await client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a world-class text tagging system.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": f\"Describe the following text: `{text}`\"},\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Here are the allowed tags: {allowed_tags_str}\",\\\n            },\\\n        ],\n        response_model=Iterable[Tag],\n        validation_context={\"tags\": tags},\n    )\n\ntag_results = asyncio.run(get_tags(text, tags))\nfor tag in tag_results:\n    print(tag)\n    #> id=0 name='personal'\n    #> id=1 name='phone'\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/bulk_classification/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/bulk_classification/",
      "title": "User-Provided Tag Classification Tutorial - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/bulk_classification/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/bulk_classification.png",
      "ogTitle": "User-Provided Tag Classification Tutorial - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/bulk_classification.png",
      "og:title": "User-Provided Tag Classification Tutorial - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/bulk_classification/?q=",
      "statusCode": 200,
      "description": "Learn to classify user-provided tags effectively using async functions and FastAPI for parallel processing.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to classify user-provided tags effectively using async functions and FastAPI for parallel processing.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/bulk_classification.png",
      "twitter:title": "User-Provided Tag Classification Tutorial - Instructor",
      "og:description": "Learn to classify user-provided tags effectively using async functions and FastAPI for parallel processing.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to classify user-provided tags effectively using async functions and FastAPI for parallel processing."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/recursive/?q=#recursive-schema-implementation-guide)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/recursive.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/recursive.md \"View source of this page\")\n\n# Recursive Schema Implementation Guide [¶](https://python.useinstructor.com/examples/recursive/?q=\\#recursive-schema-implementation-guide \"Permanent link\")\n\nThis guide demonstrates how to work with recursive schemas in Instructor using Pydantic models. While flat schemas are often simpler to work with, some use cases require recursive structures to represent hierarchical data effectively.\n\nMotivation\n\nRecursive schemas are particularly useful when dealing with: \\* Nested organizational structures \\* File system hierarchies \\* Comment threads with replies \\* Task dependencies with subtasks \\* Abstract syntax trees\n\n## Defining a Recursive Schema [¶](https://python.useinstructor.com/examples/recursive/?q=\\#defining-a-recursive-schema \"Permanent link\")\n\nHere's an example of how to define a recursive Pydantic model:\n\n```md-code__content\nfrom typing import List, Optional\nfrom pydantic import BaseModel, Field\n\nclass RecursiveNode(BaseModel):\n    \"\"\"A node that can contain child nodes of the same type.\"\"\"\n\n    name: str = Field(..., description=\"Name of the node\")\n    value: Optional[str] = Field(\n        None, description=\"Optional value associated with the node\"\n    )\n    children: List[\"RecursiveNode\"] = Field(\n        default_factory=list, description=\"List of child nodes\"\n    )\n\n# Required for recursive Pydantic models\nRecursiveNode.model_rebuild()\n\n```\n\n## Example Usage [¶](https://python.useinstructor.com/examples/recursive/?q=\\#example-usage \"Permanent link\")\n\nLet's see how to use this recursive schema with Instructor:\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\ndef parse_hierarchy(text: str) -> RecursiveNode:\n    \"\"\"Parse text into a hierarchical structure.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are an expert at parsing text into hierarchical structures.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Parse this text into a hierarchical structure: {text}\",\\\n            },\\\n        ],\n        response_model=RecursiveNode,\n    )\n\n# Example usage\nhierarchy = parse_hierarchy(\n    \"\"\"\nCompany: Acme Corp\n- Department: Engineering\n  - Team: Frontend\n    - Project: Website Redesign\n    - Project: Mobile App\n  - Team: Backend\n    - Project: API v2\n    - Project: Database Migration\n- Department: Marketing\n  - Team: Digital\n    - Project: Social Media Campaign\n  - Team: Brand\n    - Project: Logo Refresh\n\"\"\"\n)\n\n```\n\n## Validation and Best Practices [¶](https://python.useinstructor.com/examples/recursive/?q=\\#validation-and-best-practices \"Permanent link\")\n\nWhen working with recursive schemas:\n\n1. Always call `model_rebuild()` after defining the model\n2. Consider adding validation for maximum depth to prevent infinite recursion\n3. Use type hints properly to maintain code clarity\n4. Consider implementing custom validators for specific business rules\n\n```md-code__content\nfrom pydantic import model_validator\n\nclass RecursiveNodeWithDepth(RecursiveNode):\n    @model_validator(mode='after')\n    def validate_depth(self) -> \"RecursiveNodeWithDepth\":\n        def check_depth(node: \"RecursiveNodeWithDepth\", current_depth: int = 0) -> int:\n            if current_depth > 10:  # Maximum allowed depth\n                raise ValueError(\"Maximum depth exceeded\")\n            return max(\n                [check_depth(child, current_depth + 1) for child in node.children],\n                default=current_depth,\n            )\n\n        check_depth(self)\n        return self\n\n```\n\n## Performance Considerations [¶](https://python.useinstructor.com/examples/recursive/?q=\\#performance-considerations \"Permanent link\")\n\nWhile recursive schemas are powerful, they can be more challenging for language models to handle correctly. Consider these tips:\n\n1. Keep structures as shallow as possible\n2. Use clear naming conventions\n3. Provide good examples in your prompts\n4. Consider breaking very large structures into smaller chunks\n\n## Conclusion [¶](https://python.useinstructor.com/examples/recursive/?q=\\#conclusion \"Permanent link\")\n\nRecursive schemas provide a powerful way to handle hierarchical data structures in your applications. While they require more careful handling than flat schemas, they can be invaluable for certain use cases.\n\nFor more examples of working with complex data structures, check out: 1. [Query Planning with Dependencies](https://python.useinstructor.com/examples/planning-tasks/) 2\\. [Knowledge Graph Generation](https://python.useinstructor.com/examples/knowledge_graph/)\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/recursive/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/recursive/",
      "title": "Working with Recursive Schemas in Instructor - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/recursive/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/recursive.png",
      "ogTitle": "Working with Recursive Schemas in Instructor - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/recursive.png",
      "og:title": "Working with Recursive Schemas in Instructor - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/recursive/?q=",
      "statusCode": 200,
      "description": "Learn how to effectively implement and use recursive Pydantic models for handling nested and hierarchical data structures.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to effectively implement and use recursive Pydantic models for handling nested and hierarchical data structures.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/recursive.png",
      "twitter:title": "Working with Recursive Schemas in Instructor - Instructor",
      "og:description": "Learn how to effectively implement and use recursive Pydantic models for handling nested and hierarchical data structures.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to effectively implement and use recursive Pydantic models for handling nested and hierarchical data structures."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/sqlmodel/?q=#integrating-instructor-with-sqlmodel)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/sqlmodel.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/sqlmodel.md \"View source of this page\")\n\n# Integrating Instructor with SQLModel [¶](https://python.useinstructor.com/examples/sqlmodel/?q=\\#integrating-instructor-with-sqlmodel \"Permanent link\")\n\n[SQLModel](https://sqlmodel.tiangolo.com/) is a library designed for interacting with SQL databases from Python code using Python objects. `SQLModel` is based on `Pydantic` and `SQLAlchemy` and was created by [tiangolo](https://twitter.com/tiangolo) who also developed `FastAPI`. So you can expect seamless integration across all these libraries, reducing code duplicating and improving your developer experience.\n\n# Example: Adding responses from Instructor directly to your DB [¶](https://python.useinstructor.com/examples/sqlmodel/?q=\\#example-adding-responses-from-instructor-directly-to-your-db \"Permanent link\")\n\n## Defining the Models [¶](https://python.useinstructor.com/examples/sqlmodel/?q=\\#defining-the-models \"Permanent link\")\n\nFirst we'll define a model that will serve as a table for our database and the structure of our outputs from `Instructor`\n\nModel Definition\n\nYou'll need to subclass your models with both `SQLModel` and `instructor.OpenAISchema` for them to work with SQLModel\n\n```md-code__content\nfrom typing import Optional\nfrom sqlmodel import Field, SQLModel\nimport instructor\n\nclass Hero(SQLModel, instructor.OpenAISchema, table=True):\n    id: Optional[int] = Field(default=None, primary_key=True)\n    name: str\n    secret_name: str\n    age: Optional[int] = None\n\n```\n\n## Generating a record [¶](https://python.useinstructor.com/examples/sqlmodel/?q=\\#generating-a-record \"Permanent link\")\n\nThe `create_hero` function will query `OpenAI` for a `Hero` record\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\ndef create_hero() -> Hero:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Hero,\n        messages=[\\\n            {\"role\": \"user\", \"content\": \"Make a new superhero\"},\\\n        ],\n    )\n\n```\n\n## Inserting the response into the DB [¶](https://python.useinstructor.com/examples/sqlmodel/?q=\\#inserting-the-response-into-the-db \"Permanent link\")\n\n```md-code__content\nengine = create_engine(\"sqlite:///database.db\")\nSQLModel.metadata.create_all(engine)\n\nhero = create_hero()\nprint(hero.model_dump())\n#> {'name': 'Superman', 'secret_name': 'Clark Kent', 'age': 30, 'id': None}\n\nwith Session(engine) as session:\n    session.add(hero)\n    session.commit()\n\n```\n\n![Image of hero record in the database](https://python.useinstructor.com/examples/db.png)\n\nAnd there you have it! You can now use the same models for your database and `Instructor` enabling them work seamlessly! Also checkout the [FastAPI](https://python.useinstructor.com/concepts/fastapi/) guide to see how you can use these models in an API as well.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/sqlmodel/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/sqlmodel/",
      "title": "Integrating Instructor with SQLModel in Python - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/sqlmodel/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/sqlmodel.png",
      "ogTitle": "Integrating Instructor with SQLModel in Python - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/sqlmodel.png",
      "og:title": "Integrating Instructor with SQLModel in Python - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/sqlmodel/?q=",
      "statusCode": 200,
      "description": "Learn how to integrate Instructor with SQLModel for seamless database interactions and API development in Python.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to integrate Instructor with SQLModel for seamless database interactions and API development in Python.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/sqlmodel.png",
      "twitter:title": "Integrating Instructor with SQLModel in Python - Instructor",
      "og:description": "Learn how to integrate Instructor with SQLModel for seamless database interactions and API development in Python.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to integrate Instructor with SQLModel for seamless database interactions and API development in Python."
    }
  },
  {
    "markdown": "# 404 - Not found\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/building_knowledge_graph.md",
      "error": "Not Found",
      "title": "Instructor",
      "author": "Jason Liu",
      "language": "en",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/building_knowledge_graph.md",
      "statusCode": 404,
      "description": "A lightweight library for structured outputs with LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "ogLocaleAlternate": []
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/exact_citations/?q=#example-answering-questions-with-validated-citations)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/exact_citations.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/exact_citations.md \"View source of this page\")\n\n# Example: Answering Questions with Validated Citations [¶](https://python.useinstructor.com/examples/exact_citations/?q=\\#example-answering-questions-with-validated-citations \"Permanent link\")\n\nFor the full code example, check out [examples/citation\\_fuzzy\\_match.py](https://github.com/jxnl/instructor/blob/main/examples/citation_with_extraction/citation_fuzzy_match.py)\n\n## Overview [¶](https://python.useinstructor.com/examples/exact_citations/?q=\\#overview \"Permanent link\")\n\nThis example shows how to use Instructor with validators to not only add citations to answers generated but also prevent hallucinations by ensuring that every statement made by the LLM is backed up by a direct quote from the context provided, and that those quotes exist!\n\nTwo Python classes, `Fact` and `QuestionAnswer`, are defined to encapsulate the information of individual facts and the entire answer, respectively.\n\n## Data Structures [¶](https://python.useinstructor.com/examples/exact_citations/?q=\\#data-structures \"Permanent link\")\n\n### The `Fact` Class [¶](https://python.useinstructor.com/examples/exact_citations/?q=\\#the-fact-class \"Permanent link\")\n\nThe `Fact` class encapsulates a single statement or fact. It contains two fields:\n\n- `fact`: A string representing the body of the fact or statement.\n- `substring_quote`: A list of strings. Each string is a direct quote from the context that supports the `fact`.\n\n#### Validation Method: `validate_sources` [¶](https://python.useinstructor.com/examples/exact_citations/?q=\\#validation-method-validate_sources \"Permanent link\")\n\nThis method validates the sources ( `substring_quote`) in the context. It utilizes regex to find the span of each substring quote in the given context. If the span is not found, the quote is removed from the list.\n\n```md-code__content\nfrom pydantic import Field, BaseModel, model_validator, ValidationInfo\nfrom typing import List\n\nclass Fact(BaseModel):\n    fact: str = Field(...)\n    substring_quote: List[str] = Field(...)\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self, info: ValidationInfo) -> \"Fact\":\n        text_chunks = info.context.get(\"text_chunk\", None)\n        spans = list(self.get_spans(text_chunks))\n        self.substring_quote = [text_chunks[span[0] : span[1]] for span in spans]\n        return self\n\n    def get_spans(self, context):\n        for quote in self.substring_quote:\n            yield from self._get_span(quote, context)\n\n    def _get_span(self, quote, context):\n        for match in re.finditer(re.escape(quote), context):\n            yield match.span()\n\n```\n\n### The `QuestionAnswer` Class [¶](https://python.useinstructor.com/examples/exact_citations/?q=\\#the-questionanswer-class \"Permanent link\")\n\nThis class encapsulates the question and its corresponding answer. It contains two fields:\n\n- `question`: The question asked.\n- `answer`: A list of `Fact` objects that make up the answer.\n\n#### Validation Method: `validate_sources` [¶](https://python.useinstructor.com/examples/exact_citations/?q=\\#validation-method-validate_sources_1 \"Permanent link\")\n\nThis method checks that each `Fact` object in the `answer` list has at least one valid source. If a `Fact` object has no valid sources, it is removed from the `answer` list.\n\n```md-code__content\nfrom pydantic import BaseModel, Field, model_validator\nfrom typing import List\n\nclass QuestionAnswer(BaseModel):\n    question: str = Field(...)\n    answer: List[Fact] = Field(...)\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self) -> \"QuestionAnswer\":\n        self.answer = [fact for fact in self.answer if len(fact.substring_quote) > 0]\n        return self\n\n```\n\n## Function to Ask AI a Question [¶](https://python.useinstructor.com/examples/exact_citations/?q=\\#function-to-ask-ai-a-question \"Permanent link\")\n\n### The `ask_ai` Function [¶](https://python.useinstructor.com/examples/exact_citations/?q=\\#the-ask_ai-function \"Permanent link\")\n\nThis function takes a string `question` and a string `context` and returns a `QuestionAnswer` object. It uses the OpenAI API to fetch the answer and then validates the sources using the defined classes.\n\nTo understand the validation context work from pydantic check out [pydantic's docs](https://docs.pydantic.dev/usage/validators/#model-validators)\n\n```md-code__content\nfrom openai import OpenAI\nimport instructor\n\n# Apply the patch to the OpenAI client\n# enables response_model, validation_context keyword\nclient = instructor.from_openai(OpenAI())\n\ndef ask_ai(question: str, context: str) -> QuestionAnswer:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo-0613\",\n        temperature=0,\n        response_model=QuestionAnswer,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a world class algorithm to answer questions with correct and exact citations.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": f\"{context}\"},\\\n            {\"role\": \"user\", \"content\": f\"Question: {question}\"},\\\n        ],\n        validation_context={\"text_chunk\": context},\n    )\n\n```\n\n## Example [¶](https://python.useinstructor.com/examples/exact_citations/?q=\\#example \"Permanent link\")\n\ndd Here's an example of using these classes and functions to ask a question and validate the answer.\n\n```md-code__content\nquestion = \"What did the author do during college?\"\ncontext = \"\"\"\nMy name is Jason Liu, and I grew up in Toronto Canada but I was born in China.\nI went to an arts high school but in university I studied Computational Mathematics and physics.\nAs part of coop I worked at many companies including Stitchfix, Facebook.\nI also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.\n\"\"\"\n\n```\n\nThe output would be a `QuestionAnswer` object containing validated facts and their sources.\n\n```md-code__content\n{\n    \"question\": \"where did he go to school?\",\n    \"answer\": [\\\n        {\\\n            \"statement\": \"Jason Liu went to an arts highschool.\",\\\n            \"substring_phrase\": [\"arts highschool\"],\\\n        },\\\n        {\\\n            \"statement\": \"Jason Liu studied Computational Mathematics and physics in university.\",\\\n            \"substring_phrase\": [\"university\"],\\\n        },\\\n    ],\n}\n\n```\n\nThis ensures that every piece of information in the answer has been validated against the context.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/exact_citations/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/exact_citations/",
      "title": "Validating AI Answers with Contextual Citations in Python - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/exact_citations/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/exact_citations.png",
      "ogTitle": "Validating AI Answers with Contextual Citations in Python - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/exact_citations.png",
      "og:title": "Validating AI Answers with Contextual Citations in Python - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/exact_citations/?q=",
      "statusCode": 200,
      "description": "Learn to use Python classes to validate AI-generated answers with citations, ensuring accuracy and preventing hallucinations.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to use Python classes to validate AI-generated answers with citations, ensuring accuracy and preventing hallucinations.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/exact_citations.png",
      "twitter:title": "Validating AI Answers with Contextual Citations in Python - Instructor",
      "og:description": "Learn to use Python classes to validate AI-generated answers with citations, ensuring accuracy and preventing hallucinations.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to use Python classes to validate AI-generated answers with citations, ensuring accuracy and preventing hallucinations."
    }
  },
  {
    "markdown": "# 404 - Not found\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/building_knowledge_graph.md?q=",
      "error": "Not Found",
      "title": "Instructor",
      "author": "Jason Liu",
      "language": "en",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/building_knowledge_graph.md?q=",
      "statusCode": 404,
      "description": "A lightweight library for structured outputs with LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "ogLocaleAlternate": []
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/watsonx/?q=#structured-outputs-with-ibm-watsonxai)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/watsonx.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/watsonx.md \"View source of this page\")\n\n# Structured Outputs with IBM watsonx.ai [¶](https://python.useinstructor.com/examples/watsonx/?q=\\#structured-outputs-with-ibm-watsonxai \"Permanent link\")\n\nYou can use IBM watsonx.ai for inference using [LiteLLM](https://docs.litellm.ai/docs/providers/watsonx).\n\n## Prerequisites [¶](https://python.useinstructor.com/examples/watsonx/?q=\\#prerequisites \"Permanent link\")\n\n- IBM Cloud Account\n- API Key from IBM Cloud IAM: [https://cloud.ibm.com/iam/apikeys](https://cloud.ibm.com/iam/apikeys)\n- Project ID (from watsonx.ai instance URL: [https://dataplatform.cloud.ibm.com/projects/](https://dataplatform.cloud.ibm.com/projects/)/)\n\n## Install [¶](https://python.useinstructor.com/examples/watsonx/?q=\\#install \"Permanent link\")\n\n```md-code__content\npoetry install instructor --with litellm\n\n```\n\n## Example [¶](https://python.useinstructor.com/examples/watsonx/?q=\\#example \"Permanent link\")\n\n```md-code__content\nimport os\n\nimport litellm\nfrom litellm import completion\nfrom pydantic import BaseModel, Field\n\nimport instructor\nfrom instructor import Mode\n\nlitellm.drop_params = True  # watsonx.ai doesn't support `json_mode`\n\nos.environ[\"WATSONX_URL\"] = \"https://us-south.ml.cloud.ibm.com\"\nos.environ[\"WATSONX_API_KEY\"] = \"\"\nos.environ[\"WATSONX_PROJECT_ID\"] = \"\"\n# Additional options: https://docs.litellm.ai/docs/providers/watsonx\n\nclass Company(BaseModel):\n    name: str = Field(description=\"name of the company\")\n    year_founded: int = Field(description=\"year the company was founded\")\n\nclient = instructor.from_litellm(completion, mode=Mode.JSON)\n\nresp = client.chat.completions.create(\n    model=\"watsonx/meta-llama/llama-3-8b-instruct\",\n    max_tokens=1024,\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": \"\"\"\\\\\nGiven the following text, create a Company object:\\\n\\\nIBM was founded in 1911 as the Computing-Tabulating-Recording Company (CTR), a holding company of manufacturers of record-keeping and measuring systems.\\\n\"\"\",\\\n        }\\\n    ],\n    project_id=os.environ[\"WATSONX_PROJECT_ID\"],\n    response_model=Company,\n)\n\nprint(resp.model_dump_json(indent=2))\n\"\"\"\n{\n  \"name\": \"IBM\",\n  \"year_founded\": 1911\n}\n\"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/watsonx/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/watsonx/",
      "title": "Using IBM watsonx.ai for Inference - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/watsonx/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/watsonx.png",
      "ogTitle": "Using IBM watsonx.ai for Inference - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/watsonx.png",
      "og:title": "Using IBM watsonx.ai for Inference - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/watsonx/?q=",
      "statusCode": 200,
      "description": "Learn how to use IBM watsonx.ai and LiteLLM for structured outputs, including setup, installation, and coding examples.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use IBM watsonx.ai and LiteLLM for structured outputs, including setup, installation, and coding examples.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/watsonx.png",
      "twitter:title": "Using IBM watsonx.ai for Inference - Instructor",
      "og:description": "Learn how to use IBM watsonx.ai and LiteLLM for structured outputs, including setup, installation, and coding examples.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use IBM watsonx.ai and LiteLLM for structured outputs, including setup, installation, and coding examples."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/planning-tasks/?q=#planning-and-executing-a-query-plan)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/planning-tasks.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/planning-tasks.md \"View source of this page\")\n\n* * *\n\ntitle: Query Planning with OpenAI: A Step-by-Step Guide description: Learn how to effectively plan and execute complex query plans using OpenAI's Function Call model for systematic information gathering.\n\n* * *\n\n# Planning and Executing a Query Plan [¶](https://python.useinstructor.com/examples/planning-tasks/?q=\\#planning-and-executing-a-query-plan \"Permanent link\")\n\nThis example demonstrates how to use the OpenAI Function Call ChatCompletion model to plan and execute a query plan in a question-answering system. By breaking down a complex question into smaller sub-questions with defined dependencies using [lists](https://python.useinstructor.com/concepts/lists/), the system can systematically gather the necessary information to answer the main question similar to [knowledge graph extraction](https://python.useinstructor.com/examples/knowledge_graph/).\n\nMotivation\n\nThe goal of this example is to showcase how query planning can be used to handle complex questions, facilitate iterative information gathering, automate workflows, and optimize processes. By leveraging the OpenAI Function Call model, you can design and execute a structured plan to find answers effectively.\n\n**Use Cases:**\n\n- Complex question answering\n- Iterative information gathering\n- Workflow automation\n- Process optimization\n\nWith the OpenAI Function Call model, you can customize the planning process and integrate it into your specific application to meet your unique requirements.\n\n## Defining the Structures [¶](https://python.useinstructor.com/examples/planning-tasks/?q=\\#defining-the-structures \"Permanent link\")\n\nLet's define the necessary Pydantic models to represent the query plan and the queries.\n\n```md-code__content\nfrom typing import List, Literal\nfrom pydantic import Field, BaseModel\n\nclass Query(BaseModel):\n    \"\"\"Class representing a single question in a query plan.\"\"\"\n\n    id: int = Field(..., description=\"Unique id of the query\")\n    question: str = Field(\n        ...,\n        description=\"Question asked using a question answering system\",\n    )\n    dependencies: List[int] = Field(\n        default_factory=list,\n        description=\"List of sub questions that need to be answered before asking this question\",\n    )\n    node_type: Literal[\"SINGLE\", \"MERGE_MULTIPLE_RESPONSES\"] = Field(\n        default=\"SINGLE\",\n        description=\"Type of question, either a single question or a multi-question merge\",\n    )\n\nclass QueryPlan(BaseModel):\n    \"\"\"Container class representing a tree of questions to ask a question answering system.\"\"\"\n\n    query_graph: List[Query] = Field(\n        ..., description=\"The query graph representing the plan\"\n    )\n\n    def _dependencies(self, ids: List[int]) -> List[Query]:\n        \"\"\"Returns the dependencies of a query given their ids.\"\"\"\n        return [q for q in self.query_graph if q.id in ids]\n\n```\n\nGraph Generation\n\nNotice that this example produces a flat list of items with dependencies that resemble a graph, while pydantic allows for recursive definitions, it's much easier and less confusing for the model to generate flat schemas rather than recursive schemas. If you want to see a recursive example, see [recursive schemas](https://python.useinstructor.com/examples/recursive/)\n\n## Planning a Query Plan [¶](https://python.useinstructor.com/examples/planning-tasks/?q=\\#planning-a-query-plan \"Permanent link\")\n\nNow, let's demonstrate how to plan and execute a query plan using the defined models and the OpenAI API.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\ndef query_planner(question: str) -> QueryPlan:\n    PLANNING_MODEL = \"gpt-4o-mini\"\n\n    messages = [\\\n        {\\\n            \"role\": \"system\",\\\n            \"content\": \"You are a world class query planning algorithm capable ofbreaking apart questions into its dependency queries such that the answers can be used to inform the parent question. Do not answer the questions, simply provide a correct compute graph with good specific questions to ask and relevant dependencies. Before you call the function, think step-by-step to get a better understanding of the problem.\",\\\n        },\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": f\"Consider: {question}\\nGenerate the correct query plan.\",\\\n        },\\\n    ]\n\n    root = client.chat.completions.create(\n        model=PLANNING_MODEL,\n        temperature=0,\n        response_model=QueryPlan,\n        messages=messages,\n        max_tokens=1000,\n    )\n    return root\n\n```\n\n```md-code__content\nplan = query_planner(\n    \"What is the difference in populations of Canada and the Jason's home country?\"\n)\nplan.model_dump()\n\n```\n\nNo RAG\n\nWhile we build the query plan in this example, we do not propose a method to actually answer the question. You can implement your own answer function that perhaps makes a retrieval and calls openai for retrieval augmented generation. That step would also make use of function calls but goes beyond the scope of this example.\n\n```md-code__content\n{\n    \"query_graph\": [\\\n        {\\\n            \"dependencies\": [],\\\n            \"id\": 1,\\\n            \"node_type\": \"SINGLE\",\\\n            \"question\": \"Identify Jason's home country\",\\\n        },\\\n        {\\\n            \"dependencies\": [],\\\n            \"id\": 2,\\\n            \"node_type\": \"SINGLE\",\\\n            \"question\": \"Find the population of Canada\",\\\n        },\\\n        {\\\n            \"dependencies\": [1],\\\n            \"id\": 3,\\\n            \"node_type\": \"SINGLE\",\\\n            \"question\": \"Find the population of Jason's home country\",\\\n        },\\\n        {\\\n            \"dependencies\": [2, 3],\\\n            \"id\": 4,\\\n            \"node_type\": \"SINGLE\",\\\n            \"question\": \"Calculate the difference in populations between Canada and Jasons home country\",\\\n        },\\\n    ]\n}\n\n```\n\nIn the above code, we define a `query_planner` function that takes a question as input and generates a query plan using the OpenAI API.\n\n## Conclusion [¶](https://python.useinstructor.com/examples/planning-tasks/?q=\\#conclusion \"Permanent link\")\n\nIn this example, we demonstrated how to use the OpenAI Function Call `ChatCompletion` model to plan a query using a question-answering system. We defined the necessary structures using Pydantic and created a query planner function that generates a structured plan for answering complex questions.\n\nThe query planner breaks down the main question into smaller, manageable sub-questions, establishing dependencies between them. This approach allows for a systematic and organized way to tackle multi-step queries.\n\nFor more advanced implementations and variations of this concept, you can explore:\n\n1. [Query planning and execution example](https://github.com/jxnl/instructor/blob/main/examples/query_planner_execution/query_planner_execution.py)\n2. [Task planning with topological sort](https://github.com/jxnl/instructor/blob/main/examples/task_planner/task_planner_topological_sort.py)\n\nThese examples provide additional insights into how you can leverage structured outputs for complex query planning and task management.\n\nFeel free to adapt this code to your specific use cases and explore the possibilities of using OpenAI Function Calls to plan and structure complex workflows in your applications.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/planning-tasks/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/planning-tasks/",
      "title": "RAG Query Planning - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/planning-tasks/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/planning-tasks.png",
      "ogTitle": "RAG Query Planning - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/planning-tasks.png",
      "og:title": "RAG Query Planning - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/planning-tasks/?q=",
      "statusCode": 200,
      "description": "A lightweight library for structured outputs with LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "A lightweight library for structured outputs with LLMs.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/planning-tasks.png",
      "twitter:title": "RAG Query Planning - Instructor",
      "og:description": "A lightweight library for structured outputs with LLMs.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "A lightweight library for structured outputs with LLMs."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/single_classification/?q=#single-label-classification)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/single_classification.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/single_classification.md \"View source of this page\")\n\n# Single-Label Classification [¶](https://python.useinstructor.com/examples/single_classification/?q=\\#single-label-classification \"Permanent link\")\n\nThis example demonstrates how to perform single-label classification using the OpenAI API. The example uses the `gpt-3.5-turbo` model to classify text as either `SPAM` or `NOT_SPAM`.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\nfrom openai import OpenAI\nimport instructor\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\nclass ClassificationResponse(BaseModel):\n    \"\"\"\n    A few-shot example of text classification:\n\n    Examples:\n    - \"Buy cheap watches now!\": SPAM\n    - \"Meeting at 3 PM in the conference room\": NOT_SPAM\n    - \"You've won a free iPhone! Click here\": SPAM\n    - \"Can you pick up some milk on your way home?\": NOT_SPAM\n    - \"Increase your followers by 10000 overnight!\": SPAM\n    \"\"\"\n\n    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n        ...,\n        description=\"The predicted class label.\",\n    )\n\ndef classify(data: str) -> ClassificationResponse:\n    \"\"\"Perform single-label classification on the input text.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=ClassificationResponse,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Classify the following text: <text>{data}</text>\",\\\n            },\\\n        ],\n    )\n\nif __name__ == \"__main__\":\n    for text, label in [\\\n        (\"Hey Jason! You're awesome\", \"NOT_SPAM\"),\\\n        (\"I am a nigerian prince and I need your help.\", \"SPAM\"),\\\n    ]:\n        prediction = classify(text)\n        assert prediction.label == label\n        print(f\"Text: {text}, Predicted Label: {prediction.label}\")\n        #> Text: Hey Jason! You're awesome, Predicted Label: NOT_SPAM\n        #> Text: I am a nigerian prince and I need your help., Predicted Label: SPAM\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/single_classification/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/single_classification/",
      "title": "Single-Label Classification with OpenAI API - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/single_classification/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/single_classification.png",
      "ogTitle": "Single-Label Classification with OpenAI API - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/single_classification.png",
      "og:title": "Single-Label Classification with OpenAI API - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/single_classification/?q=",
      "statusCode": 200,
      "description": "Learn to implement single-label classification using the OpenAI API to classify text as SPAM or NOT_SPAM.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to implement single-label classification using the OpenAI API to classify text as SPAM or NOT_SPAM.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/single_classification.png",
      "twitter:title": "Single-Label Classification with OpenAI API - Instructor",
      "og:description": "Learn to implement single-label classification using the OpenAI API to classify text as SPAM or NOT_SPAM.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to implement single-label classification using the OpenAI API to classify text as SPAM or NOT_SPAM."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/extracting_tables/?q=#extracting-tables-using-gpt-vision)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/extracting_tables.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/extracting_tables.md \"View source of this page\")\n\n# Extracting Tables using GPT-Vision [¶](https://python.useinstructor.com/examples/extracting_tables/?q=\\#extracting-tables-using-gpt-vision \"Permanent link\")\n\nThis post demonstrates how to use Python's type annotations and OpenAI's new vision model to extract tables from images and convert them into markdown format. This method is particularly useful for data analysis and automation tasks.\n\nThe full code is available on [GitHub](https://github.com/jxnl/instructor/blob/main/examples/vision/run_table.py)\n\n## Building the Custom Type for Markdown Tables [¶](https://python.useinstructor.com/examples/extracting_tables/?q=\\#building-the-custom-type-for-markdown-tables \"Permanent link\")\n\nFirst, we define a custom type, `MarkdownDataFrame`, to handle pandas DataFrames formatted in markdown. This type uses Python's `Annotated` and `InstanceOf` types, along with decorators `BeforeValidator` and `PlainSerializer`, to process and serialize the data.\n\n```md-code__content\nfrom io import StringIO\nfrom typing import Annotated, Any\nfrom pydantic import BeforeValidator, PlainSerializer, InstanceOf, WithJsonSchema\nimport pandas as pd\n\ndef md_to_df(data: Any) -> Any:\n    # Convert markdown to DataFrame\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),  # Process data\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .applymap(lambda x: x.strip())\n        )\n    return data\n\nMarkdownDataFrame = Annotated[\\\n    InstanceOf[pd.DataFrame],\\\n    BeforeValidator(md_to_df),\\\n    PlainSerializer(lambda df: df.to_markdown()),\\\n    WithJsonSchema(\\\n        {\\\n            \"type\": \"string\",\\\n            \"description\": \"The markdown representation of the table, each one should be tidy, do not try to join tables that should be seperate\",\\\n        }\\\n    ),\\\n]\n\n```\n\n## Defining the Table Class [¶](https://python.useinstructor.com/examples/extracting_tables/?q=\\#defining-the-table-class \"Permanent link\")\n\nThe `Table` class is essential for organizing the extracted data. It includes a caption and a dataframe, processed as a markdown table. Since most of the complexity is handled by the `MarkdownDataFrame` type, the `Table` class is straightforward!\n\n```md-code__content\nfrom pydantic import BaseModel\n\nclass Table(BaseModel):\n    caption: str\n    dataframe: MarkdownDataFrame\n\n```\n\n## Extracting Tables from Images [¶](https://python.useinstructor.com/examples/extracting_tables/?q=\\#extracting-tables-from-images \"Permanent link\")\n\nThe `extract_table` function uses OpenAI's vision model to process an image URL and extract tables in markdown format. We utilize the `instructor` library to patch the OpenAI client for this purpose.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\nfrom typing import Iterable\n\n# Apply the patch to the OpenAI client to support response_model\n# Also use MD_JSON mode since the vision model does not support any special structured output mode\nclient = instructor.from_openai(OpenAI(), mode=instructor.function_calls.Mode.MD_JSON)\n\ndef extract_table(url: str) -> Iterable[Table]:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=Iterable[Table],\n        max_tokens=1800,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": [\\\n                    {\"type\": \"text\", \"text\": \"Extract table from image.\"},\\\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": url}},\\\n                ],\\\n            }\\\n        ],\n    )\n\n```\n\n## Practical Example [¶](https://python.useinstructor.com/examples/extracting_tables/?q=\\#practical-example \"Permanent link\")\n\nIn this example, we apply the method to extract data from an image showing the top grossing apps in Ireland for October 2023.\n\n```md-code__content\nurl = \"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\"\ntables = extract_table(url)\nfor table in tables:\n\n    print(table.dataframe)\n    \"\"\"\n                                      Android App   ... Category\n     Android Rank                                   ...\n    1                                   Google One  ...    Social networking\n    2                                      Disney+  ...        Entertainment\n    3                TikTok - Videos, Music & LIVE  ...        Entertainment\n    4                             Candy Crush Saga  ...        Entertainment\n    5               Tinder: Dating, Chat & Friends  ...                Games\n    6                                  Coin Master  ...        Entertainment\n    7                                       Roblox  ...               Dating\n    8               Bumble - Dating & Make Friends  ...                Games\n    9                                  Royal Match  ...             Business\n    10                 Spotify: Music and Podcasts  ...            Education\n\n    [10 rows x 5 columns]\n    \"\"\"\n\n```\n\nExpand to see the output\n\n![Top 10 Grossing Apps in October 2023 for Ireland](https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png)\n\n### Top 10 Grossing Apps in October 2023 (Ireland) for Android Platforms [¶](https://python.useinstructor.com/examples/extracting_tables/?q=\\#top-10-grossing-apps-in-october-2023-ireland-for-android-platforms \"Permanent link\")\n\n| Rank | App Name | Category |\n| --- | --- | --- |\n| 1 | Google One | Productivity |\n| 2 | Disney+ | Entertainment |\n| 3 | TikTok - Videos, Music & LIVE | Entertainment |\n| 4 | Candy Crush Saga | Games |\n| 5 | Tinder: Dating, Chat & Friends | Social networking |\n| 6 | Coin Master | Games |\n| 7 | Roblox | Games |\n| 8 | Bumble - Dating & Make Friends | Dating |\n| 9 | Royal Match | Games |\n| 10 | Spotify: Music and Podcasts | Music & Audio |\n\n### Top 10 Grossing Apps in October 2023 (Ireland) for iOS Platforms [¶](https://python.useinstructor.com/examples/extracting_tables/?q=\\#top-10-grossing-apps-in-october-2023-ireland-for-ios-platforms \"Permanent link\")\n\n| Rank | App Name | Category |\n| --- | --- | --- |\n| 1 | Tinder: Dating, Chat & Friends | Social networking |\n| 2 | Disney+ | Entertainment |\n| 3 | YouTube: Watch, Listen, Stream | Entertainment |\n| 4 | Audible: Audio Entertainment | Entertainment |\n| 5 | Candy Crush Saga | Games |\n| 6 | TikTok - Videos, Music & LIVE | Entertainment |\n| 7 | Bumble - Dating & Make Friends | Dating |\n| 8 | Roblox | Games |\n| 9 | LinkedIn: Job Search & News | Business |\n| 10 | Duolingo - Language Lessons | Education |\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/extracting_tables/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/extracting_tables/",
      "title": "Extracting Tables from Images using GPT-Vision - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/extracting_tables/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/extracting_tables.png",
      "ogTitle": "Extracting Tables from Images using GPT-Vision - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/extracting_tables.png",
      "og:title": "Extracting Tables from Images using GPT-Vision - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/extracting_tables/?q=",
      "statusCode": 200,
      "description": "Learn how to use Python and GPT-Vision to extract and convert tables from images into markdown for data analysis.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use Python and GPT-Vision to extract and convert tables from images into markdown for data analysis.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/extracting_tables.png",
      "twitter:title": "Extracting Tables from Images using GPT-Vision - Instructor",
      "og:description": "Learn how to use Python and GPT-Vision to extract and convert tables from images into markdown for data analysis.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use Python and GPT-Vision to extract and convert tables from images into markdown for data analysis."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/local_classification/?q=#leveraging-local-models-for-classifying-private-data)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/local_classification.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/local_classification.md \"View source of this page\")\n\n# Leveraging Local Models for Classifying Private Data [¶](https://python.useinstructor.com/examples/local_classification/?q=\\#leveraging-local-models-for-classifying-private-data \"Permanent link\")\n\nIn this article, we'll show you how to use Llama-cpp-python with instructor for classification. This is a perfect use-case for users who want to ensure that confidential documents are handled securely without ever leaving your own infrastructure.\n\n## Setup [¶](https://python.useinstructor.com/examples/local_classification/?q=\\#setup \"Permanent link\")\n\nLet's start by installing the required libraries in your local python environment. This might take a while since we'll need to build and compile `llama-cpp` for your specific environment.\n\n```md-code__content\npip install instructor pydantic\n\n```\n\nNext, we'll install `llama-cpp-python` which is a python package that allows us to use llama-cpp with our python scripts.\n\nFor this tutorial, we'll be using `Mistral-7B-Instruct-v0.2-GGUF` by `TheBloke` to do our function calls. This will require around 6GB of RAM and a GPU.\n\nWe can install the package by running the following command\n\n```md-code__content\nCMAKE_ARGS=\"-DGGML_CUDA=on\" pip install llama-cpp-python\n\n```\n\nDon't have a GPU?\n\nIf you don't have a GPU, we recommend using the `Qwen2-0.5B-Instruct` model instead and compiling llama-cpp-python to use `OpenBLAS`. This allows you to run the program using your CPU instead.\n\nYou can compile `llama-cpp-python` with `OpenBLAS` support by running the command\n\n```md-code__content\nCMAKE_ARGS=\"-DGGML_BLAS=ON -DGGML_BLAS_VENDOR=OpenBLAS\" pip install llama-cpp-python\n\n```\n\n## Using `LLama-cpp-python` [¶](https://python.useinstructor.com/examples/local_classification/?q=\\#using-llama-cpp-python \"Permanent link\")\n\nHere's an example of how to implement a system for handling confidential document queries using local models:\n\n```md-code__content\nfrom llama_cpp import Llama  # type: ignore\nimport instructor\nfrom pydantic import BaseModel\nfrom enum import Enum\nfrom typing import Optional\n\nllm = Llama.from_pretrained(  # type: ignore\n    repo_id=\"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\",\n    filename=\"*Q4_K_M.gguf\",\n    verbose=False,\n    n_gpu_layers=-1,\n)\n\ncreate = instructor.patch(\n    create=llm.create_chat_completion_openai_v1,\n)\n\n# Define query types for document-related inquiries\nclass QueryType(str, Enum):\n    DOCUMENT_CONTENT = \"document_content\"\n    LAST_MODIFIED = \"last_modified\"\n    ACCESS_PERMISSIONS = \"access_permissions\"\n    RELATED_DOCUMENTS = \"related_documents\"\n\n# Define the structure for query responses\nclass QueryResponse(BaseModel):\n    query_type: QueryType\n    response: str\n    additional_info: Optional[str] = None\n\ndef process_confidential_query(query: str) -> QueryResponse:\n    prompt = f\"\"\"Analyze the following confidential document query and provide an appropriate response:\n    Query: {query}\n\n    Determine the type of query (document content, last modified, access permissions, or related documents),\n    provide a response, and include a confidence score and any additional relevant information.\n    Remember, you're handling confidential data, so be cautious about specific details.\n    \"\"\"\n\n    return create(\n        response_model=QueryResponse,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a secure AI assistant trained to handle confidential document queries.\",\\\n            },\\\n            {\"role\": \"user\", \"content\": prompt},\\\n        ],\n    )\n\n# Sample confidential document queries\nconfidential_queries = [\\\n    \"What are the key findings in the Q4 financial report?\",\\\n    \"Who last accessed the merger proposal document?\",\\\n    \"What are the access permissions for the new product roadmap?\",\\\n    \"Are there any documents related to Project X's budget forecast?\",\\\n    \"When was the board meeting minutes document last updated?\",\\\n]\n\n# Process each query and print the results\nfor query in confidential_queries:\n    response: QueryResponse = process_confidential_query(query)\n    print(f\"{query} : {response.query_type}\")\n    \"\"\"\n    #> What are the key findings in the Q4 financial report? : document_content\n    #> Who last accessed the merger proposal document? : access_permissions\n    #> What are the access permissions for the new product roadmap? : access_permissions\n    #> Are there any documents related to Project X's budget forecast? : document_content\n    #> When was the board meeting minutes document last updated? : last_modified\n    \"\"\"\n\n```\n\n## Conclusion [¶](https://python.useinstructor.com/examples/local_classification/?q=\\#conclusion \"Permanent link\")\n\n`instructor` provides a robust solution for organizations needing to handle confidential document queries locally. By processing these queries on your own hardware, you can leverage advanced AI capabilities while maintaining the highest standards of data privacy and security.\n\nBut this goes far beyond just simple confidential documents, using local models unlocks a whole new world of interesting use-cases, fine-tuned specialist models and more!\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/local_classification/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/local_classification/",
      "title": "Classifying Confidential Data with Local AI Models - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/local_classification/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/local_classification.png",
      "ogTitle": "Classifying Confidential Data with Local AI Models - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/local_classification.png",
      "og:title": "Classifying Confidential Data with Local AI Models - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/local_classification/?q=",
      "statusCode": 200,
      "description": "Learn to classify private documents securely using Llama-cpp-python with instructor while maintaining data privacy and local infrastructure.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to classify private documents securely using Llama-cpp-python with instructor while maintaining data privacy and local infrastructure.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/local_classification.png",
      "twitter:title": "Classifying Confidential Data with Local AI Models - Instructor",
      "og:description": "Learn to classify private documents securely using Llama-cpp-python with instructor while maintaining data privacy and local infrastructure.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to classify private documents securely using Llama-cpp-python with instructor while maintaining data privacy and local infrastructure."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/groq/?q=#structured-outputs-using-groq)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/groq.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/groq.md \"View source of this page\")\n\n* * *\n\ntitle: Using Groq for Inference: Setup and Example description: Learn how to use Groq for inference with the mixtral-8x7b model, including API setup and a practical Python example.\n\n* * *\n\n# Structured Outputs using Groq [¶](https://python.useinstructor.com/examples/groq/?q=\\#structured-outputs-using-groq \"Permanent link\")\n\nInstead of using openai or antrophic you can now also use groq for inference by using from\\_groq.\n\nThe examples are using mixtral-8x7b model.\n\n## GroqCloud API [¶](https://python.useinstructor.com/examples/groq/?q=\\#groqcloud-api \"Permanent link\")\n\nTo use groq you need to obtain a groq API key. Goto [groqcloud](https://console.groq.com) and login. Select API Keys from the left menu and then select Create API key to create a new key.\n\n## Use example [¶](https://python.useinstructor.com/examples/groq/?q=\\#use-example \"Permanent link\")\n\nSome pip packages need to be installed to use the example:\n\n```md-code__content\npip install instructor groq pydantic openai anthropic\n\n```\n\nYou need to export the groq API key:\n\n```md-code__content\nexport GROQ_API_KEY=<your-api-key>\n\n```\n\nAn example:\n\n```md-code__content\nimport os\nfrom pydantic import BaseModel, Field\nfrom typing import List\nfrom groq import Groq\nimport instructor\n\nclass Character(BaseModel):\n    name: str\n    fact: List[str] = Field(..., description=\"A list of facts about the subject\")\n\nclient = Groq(\n    api_key=os.environ.get('GROQ_API_KEY'),\n)\n\nclient = instructor.from_groq(client, mode=instructor.Mode.TOOLS)\n\nresp = client.chat.completions.create(\n    model=\"mixtral-8x7b-32768\",\n    messages=[\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": \"Tell me about the company Tesla\",\\\n        }\\\n    ],\n    response_model=Character,\n)\nprint(resp.model_dump_json(indent=2))\n\"\"\"\n{\n  \"name\": \"Tesla\",\n  \"fact\": [\\\n    \"electric vehicle manufacturer\",\\\n    \"solar panel producer\",\\\n    \"based in Palo Alto, California\",\\\n    \"founded in 2003 by Elon Musk\"\\\n  ]\n}\n\"\"\"\n\n```\n\nYou can find another example called groq\\_example2.py under examples/groq of this repository.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/groq/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/groq/",
      "title": "Structured Outputs with Groq - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/groq/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/groq.png",
      "ogTitle": "Structured Outputs with Groq - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/groq.png",
      "og:title": "Structured Outputs with Groq - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/groq/?q=",
      "statusCode": 200,
      "description": "A lightweight library for structured outputs with LLMs.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "A lightweight library for structured outputs with LLMs.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/groq.png",
      "twitter:title": "Structured Outputs with Groq - Instructor",
      "og:description": "A lightweight library for structured outputs with LLMs.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "A lightweight library for structured outputs with LLMs."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/self_critique/?q=#self-correction-with-llm_validator)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/self_critique.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/self_critique.md \"View source of this page\")\n\n# Self-Correction with `llm_validator` [¶](https://python.useinstructor.com/examples/self_critique/?q=\\#self-correction-with-llm_validator \"Permanent link\")\n\n## Introduction [¶](https://python.useinstructor.com/examples/self_critique/?q=\\#introduction \"Permanent link\")\n\nThis guide demonstrates how to use `llm_validator` for implementing self-healing. The objective is to showcase how an instructor can self-correct by using validation errors and helpful error messages.\n\n```md-code__content\nfrom openai import OpenAI\nfrom pydantic import BaseModel\nimport instructor\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\nclass QuestionAnswer(BaseModel):\n    question: str\n    answer: str\n\nquestion = \"What is the meaning of life?\"\ncontext = \"The according to the devil the meaning of live is to live a life of sin and debauchery.\"\n\nqa: QuestionAnswer = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    response_model=QuestionAnswer,\n    messages=[\\\n        {\\\n            \"role\": \"system\",\\\n            \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\\\n        },\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\\\n        },\\\n    ],\n)\n\n```\n\n### Output Before Validation [¶](https://python.useinstructor.com/examples/self_critique/?q=\\#output-before-validation \"Permanent link\")\n\nWhile it calls out the objectionable content, it doesn't provide any details on how to correct it.\n\n```md-code__content\n{\n  \"question\": \"What is the meaning of life?\",\n  \"answer\": \"The meaning of life, according to the context, is to live a life of sin and debauchery.\"\n}\n\n```\n\n## Adding Custom Validation [¶](https://python.useinstructor.com/examples/self_critique/?q=\\#adding-custom-validation \"Permanent link\")\n\nBy adding a validator to the `answer` field, we can try to catch the issue and correct it. Lets integrate `llm_validator` into the model and see the error message. Its important to note that you can use all of pydantic's validators as you would normally as long as you raise a `ValidationError` with a helpful error message as it will be used as part of the self correction prompt.\n\n```md-code__content\nfrom pydantic import BaseModel, BeforeValidator\nfrom typing_extensions import Annotated\nfrom instructor import llm_validator\nfrom openai import OpenAI\nimport instructor\n\nclient = instructor.from_openai(OpenAI())\n\nclass QuestionAnswerNoEvil(BaseModel):\n    question: str\n    answer: Annotated[\\\n        str,\\\n        BeforeValidator(\\\n            llm_validator(\\\n                \"don't say objectionable things\", client=client, allow_override=True\\\n            )\\\n        ),\\\n    ]\n\ntry:\n    qa: QuestionAnswerNoEvil = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=QuestionAnswerNoEvil,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\\\n            },\\\n        ],\n    )\nexcept Exception as e:\n    print(e)\n    #> name 'context' is not defined\n\n```\n\n### Output After Validation [¶](https://python.useinstructor.com/examples/self_critique/?q=\\#output-after-validation \"Permanent link\")\n\nNow, we throw validation error that its objectionable and provide a helpful error message.\n\n```md-code__content\n1 validation error for QuestionAnswerNoEvil\nanswer\n  Assertion failed, The statement promotes sin and debauchery, which is objectionable.\n\n```\n\n## Retrying with Corrections [¶](https://python.useinstructor.com/examples/self_critique/?q=\\#retrying-with-corrections \"Permanent link\")\n\nBy adding the `max_retries` parameter, we can retry the request with corrections. and use the error message to correct the output.\n\n```md-code__content\nqa: QuestionAnswerNoEvil = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    response_model=QuestionAnswerNoEvil,\n    messages=[\\\n        {\\\n            \"role\": \"system\",\\\n            \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\\\n        },\\\n        {\\\n            \"role\": \"user\",\\\n            \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\\\n        },\\\n    ],\n)\n\n```\n\n### Final Output [¶](https://python.useinstructor.com/examples/self_critique/?q=\\#final-output \"Permanent link\")\n\nNow, we get a valid response that is not objectionable!\n\n```md-code__content\n{\n  \"question\": \"What is the meaning of life?\",\n  \"answer\": \"The meaning of life is subjective and can vary depending on individual beliefs and philosophies.\"\n}\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/self_critique/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/self_critique/",
      "title": "Implementing Self-Correction with LLM Validator - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/self_critique/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/self_critique.png",
      "ogTitle": "Implementing Self-Correction with LLM Validator - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/self_critique.png",
      "og:title": "Implementing Self-Correction with LLM Validator - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/self_critique/?q=",
      "statusCode": 200,
      "description": "Learn how to use llm_validator for self-healing in NLP applications and improve response accuracy with validation errors.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to use llm_validator for self-healing in NLP applications and improve response accuracy with validation errors.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/self_critique.png",
      "twitter:title": "Implementing Self-Correction with LLM Validator - Instructor",
      "og:description": "Learn how to use llm_validator for self-healing in NLP applications and improve response accuracy with validation errors.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to use llm_validator for self-healing in NLP applications and improve response accuracy with validation errors."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/extract_contact_info/?q=#customer-information-extraction)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/extract_contact_info.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/extract_contact_info.md \"View source of this page\")\n\n# Customer Information Extraction [¶](https://python.useinstructor.com/examples/extract_contact_info/?q=\\#customer-information-extraction \"Permanent link\")\n\nIn this guide, we'll walk through how to extract customer lead information using OpenAI's API and Pydantic. This use case is essential for seamlessly automating the process of extracting specific information from a context.\n\n## Motivation [¶](https://python.useinstructor.com/examples/extract_contact_info/?q=\\#motivation \"Permanent link\")\n\nYou could potentially integrate this into a chatbot to extract relevant user information from user messages. With the use of machine learning driven validation it would reduce the need for a human to verify the information.\n\n## Defining the Structure [¶](https://python.useinstructor.com/examples/extract_contact_info/?q=\\#defining-the-structure \"Permanent link\")\n\nWe'll model a customer lead as a Lead object, including attributes for the name and phone number. We'll use a Pydantic PhoneNumber type to validate the phone numbers entered and provide a Field to give the model more information on correctly populating the object.\n\n## Extracting Lead Information [¶](https://python.useinstructor.com/examples/extract_contact_info/?q=\\#extracting-lead-information \"Permanent link\")\n\nTo extract lead information, we create the `parse_lead_from_message` function which integrates Instructor. It calls OpenAI's API, processes the text, and returns the extracted lead information as a Lead object.\n\n## Evaluating Lead Extraction [¶](https://python.useinstructor.com/examples/extract_contact_info/?q=\\#evaluating-lead-extraction \"Permanent link\")\n\nTo showcase the `parse_lead_from_message` function we can provide sample user messages that may be obtained from a dialogue with a chatbot assistant. Also take note of the response model being set as `Iterable[Lead]` this allows for multiple leads being extracted from the same message.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber\nfrom typing import Iterable\n\nclass Lead(BaseModel):\n    name: str\n    phone_number: PhoneNumber = Field(\n        description=\"Needs to be a phone number with a country code. If none, assume +1\"\n    )\n\n    # Can define some function here to send Lead information to a database using an API\n\nclient = instructor.from_openai(OpenAI())\n\ndef parse_lead_from_message(user_message: str):\n    return client.chat.completions.create(\n        model=\"gpt-4-turbo-preview\",\n        response_model=Iterable[Lead],\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a data extraction system that extracts a user's name and phone number from a message.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Extract the user's lead information from this user's message: {user_message}\",\\\n            },\\\n        ],\n    )\n\nif __name__ == \"__main__\":\n    lead = parse_lead_from_message(\n        \"Yes, that would be great if someone can reach out my name is Patrick King 9175554587\"\n    )\n    assert all(isinstance(item, Lead) for item in lead)\n    for item in lead:\n        print(item.model_dump_json(indent=2))\n        \"\"\"\n        {\n          \"name\": \"Patrick King\",\n          \"phone_number\": \"tel:+1-917-555-4587\"\n        }\n        \"\"\"\n\n    # Invalid phone number example:\n    try:\n        lead2 = parse_lead_from_message(\n            \"Yes, that would be great if someone can reach out my name is Patrick King 9172234\"\n        )\n        assert all(isinstance(item, Lead) for item in lead2)\n        for item in lead2:\n            print(item.model_dump_json(indent=2))\n            \"\"\"\n            {\n              \"name\": \"Patrick King\",\n              \"phone_number\": \"tel:+1-917-223-4999\"\n            }\n            \"\"\"\n\n    except Exception as e:\n        print(\"ERROR:\", e)\n        \"\"\"\n        ERROR:\n        1 validation error for IterableLead\n        tasks.0.phone_number\n          value is not a valid phone number [type=value_error, input_value='+19172234', input_type=str]\n        \"\"\"\n\n```\n\nIn this example, the `parse_lead_from_message` function successfully extracts lead information from a user message, demonstrating how automation can enhance the efficiency of collecting accurate customer details. It also shows how the function successfully catches that the phone number is invalid so functionality can be implemented for the user to get prompted again to give a correct phone number.\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/extract_contact_info/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/extract_contact_info/",
      "title": "Automate Customer Lead Information Extraction with OpenAI and Pydantic - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/extract_contact_info/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/extract_contact_info.png",
      "ogTitle": "Automate Customer Lead Information Extraction with OpenAI and Pydantic - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/extract_contact_info.png",
      "og:title": "Automate Customer Lead Information Extraction with OpenAI and Pydantic - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/extract_contact_info/?q=",
      "statusCode": 200,
      "description": "Learn to extract customer lead details using OpenAI's API and Pydantic for efficient data automation and validation.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn to extract customer lead details using OpenAI's API and Pydantic for efficient data automation and validation.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/extract_contact_info.png",
      "twitter:title": "Automate Customer Lead Information Extraction with OpenAI and Pydantic - Instructor",
      "og:description": "Learn to extract customer lead details using OpenAI's API and Pydantic for efficient data automation and validation.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn to extract customer lead details using OpenAI's API and Pydantic for efficient data automation and validation."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/pandas_df/?q=#extracting-directly-to-a-dataframe)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/pandas_df.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/pandas_df.md \"View source of this page\")\n\n# Extracting directly to a DataFrame [¶](https://python.useinstructor.com/examples/pandas_df/?q=\\#extracting-directly-to-a-dataframe \"Permanent link\")\n\nIn this example we'll show you how to extract directly to a `pandas.DataFrame`\n\n```md-code__content\nfrom io import StringIO\nfrom typing import Annotated, Any\nfrom pydantic import (\n    BaseModel,\n    BeforeValidator,\n    PlainSerializer,\n    InstanceOf,\n    WithJsonSchema,\n)\nimport pandas as pd\nimport instructor\nimport openai\n\ndef md_to_df(data: Any) -> Any:\n    # Convert markdown to DataFrame\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),  # Process data\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .applymap(lambda x: x.strip())\n        )\n    return data\n\nMarkdownDataFrame = Annotated[\\\n    # Validates final type\\\n    InstanceOf[pd.DataFrame],\\\n    # Converts markdown to DataFrame\\\n    BeforeValidator(md_to_df),\\\n    # Converts DataFrame to markdown on model_dump_json\\\n    PlainSerializer(lambda df: df.to_markdown()),\\\n    # Adds a description to the type\\\n    WithJsonSchema(\\\n        {\\\n            \"type\": \"string\",\\\n            \"description\": \"\"\"\\\n            The markdown representation of the table,\\\n            each one should be tidy, do not try to join\\\n            tables that should be seperate\"\"\",\\\n        }\\\n    ),\\\n]\n\nclient = instructor.from_openai(openai.OpenAI())\n\ndef extract_df(data: str) -> pd.DataFrame:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=MarkdownDataFrame,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a data extraction system, table of writing perfectly formatted markdown tables.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Extract the data into a table: {data}\",\\\n            },\\\n        ],\n    )\n\nclass Table(BaseModel):\n    title: str\n    data: MarkdownDataFrame\n\ndef extract_table(data: str) -> Table:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Table,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": \"You are a data extraction system, table of writing perfectly formatted markdown tables.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Extract the data into a table: {data}\",\\\n            },\\\n        ],\n    )\n\nif __name__ == \"__main__\":\n    df = extract_df(\n        \"\"\"Create a table of the last 5 presidents of the United States,\n        including their party and the years they served.\"\"\"\n    )\n    assert isinstance(df, pd.DataFrame)\n    print(df)\n    \"\"\"\n                         Party          Years Served\n     President\n    Joe Biden                  Democrat  2021 - Present\n    Donald Trump             Republican     2017 - 2021\n    Barack Obama               Democrat     2009 - 2017\n    George W. Bush           Republican     2001 - 2009\n    Bill Clinton               Democrat     1993 - 2001\n    \"\"\"\n\n    table = extract_table(\n        \"\"\"Create a table of the last 5 presidents of the United States,\n        including their party and the years they served.\"\"\"\n    )\n    assert isinstance(table, Table)\n    assert isinstance(table.data, pd.DataFrame)\n    print(table.title)\n    #> Last 5 Presidents of the United States\n    print(table.data)\n    \"\"\"\n                         Party  Years Served\n     President\n    Joe Biden        Democratic     2021-2025\n    Donald Trump     Republican     2017-2021\n    Barack Obama     Democratic     2009-2017\n    George W. Bush   Republican     2001-2009\n    Bill Clinton     Democratic     1993-2001\n    \"\"\"\n\n```\n\nNotice that you can extract both the raw `MarkdownDataFrame` or a more complex structure like `Table` which includes a title and the data as a DataFrame. You can even request `Iterable[Table]` to get multiple tables in a single response!\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/pandas_df/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/pandas_df/",
      "title": "Extracting DataFrames from Markdown using Pandas - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/pandas_df/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/pandas_df.png",
      "ogTitle": "Extracting DataFrames from Markdown using Pandas - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/pandas_df.png",
      "og:title": "Extracting DataFrames from Markdown using Pandas - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/pandas_df/?q=",
      "statusCode": 200,
      "description": "Learn how to extract and convert Markdown tables directly into Pandas DataFrames in Python.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to extract and convert Markdown tables directly into Pandas DataFrames in Python.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/pandas_df.png",
      "twitter:title": "Extracting DataFrames from Markdown using Pandas - Instructor",
      "og:description": "Learn how to extract and convert Markdown tables directly into Pandas DataFrames in Python.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to extract and convert Markdown tables directly into Pandas DataFrames in Python."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/examples/?q=#how-should-i-include-examples)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/examples.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/examples.md \"View source of this page\")\n\n# How should I include examples? [¶](https://python.useinstructor.com/examples/examples/?q=\\#how-should-i-include-examples \"Permanent link\")\n\nTo enhance the clarity and usability of your model and prompt, incorporating examples directly into the JSON schema extra of your Pydantic model is highly recommended. This approach not only streamlines the integration of practical examples but also ensures that they are easily accessible and understandable within the context of your model's schema.\n\n```md-code__content\nimport openai\nimport instructor\nfrom typing import Iterable\nfrom pydantic import BaseModel, ConfigDict\n\nclient = instructor.from_openai(openai.OpenAI())\n\nclass SyntheticQA(BaseModel):\n    question: str\n    answer: str\n\n    model_config = ConfigDict(\n        json_schema_extra={\n            \"examples\": [\\\n                {\"question\": \"What is the capital of France?\", \"answer\": \"Paris\"},\\\n                {\\\n                    \"question\": \"What is the largest planet in our solar system?\",\\\n                    \"answer\": \"Jupiter\",\\\n                },\\\n                {\\\n                    \"question\": \"Who wrote 'To Kill a Mockingbird'?\",\\\n                    \"answer\": \"Harper Lee\",\\\n                },\\\n                {\\\n                    \"question\": \"What element does 'O' represent on the periodic table?\",\\\n                    \"answer\": \"Oxygen\",\\\n                },\\\n            ]\n        }\n    )\n\ndef get_synthetic_data() -> Iterable[SyntheticQA]:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\\\n            {\"role\": \"system\", \"content\": \"Generate synthetic examples\"},\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": \"Generate the exact examples you see in the examples of this prompt. \",\\\n            },\\\n        ],\n        response_model=Iterable[SyntheticQA],\n    )  # type: ignore\n\nif __name__ == \"__main__\":\n    for example in get_synthetic_data():\n        print(example)\n        #> question='What is the capital of France?' answer='Paris'\n        #> question='What is the largest planet in our solar system?' answer='Jupiter'\n        #> question=\"Who wrote 'To Kill a Mockingbird'?\" answer='Harper Lee'\n        \"\"\"\n        question=\"What element does 'O' represent on the periodic table?\" answer='Oxygen'\n        \"\"\"\n        \"\"\"\n        question=\"What element does 'O' represent on the periodic table?\" answer='Oxygen'\n        \"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/examples/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/examples/",
      "title": "Incorporating Examples in Pydantic Models - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/examples/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/examples.png",
      "ogTitle": "Incorporating Examples in Pydantic Models - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/examples.png",
      "og:title": "Incorporating Examples in Pydantic Models - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/examples/?q=",
      "statusCode": 200,
      "description": "Learn how to enhance Pydantic models with practical examples for clarity and usability in JSON schemas.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to enhance Pydantic models with practical examples for clarity and usability in JSON schemas.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/examples.png",
      "twitter:title": "Incorporating Examples in Pydantic Models - Instructor",
      "og:description": "Learn how to enhance Pydantic models with practical examples for clarity and usability in JSON schemas.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to enhance Pydantic models with practical examples for clarity and usability in JSON schemas."
    }
  },
  {
    "markdown": "[Skip to content](https://python.useinstructor.com/examples/extract_slides/?q=#data-extraction-from-slides)\n\n[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/extract_slides.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/extract_slides.md \"View source of this page\")\n\n# Data extraction from slides [¶](https://python.useinstructor.com/examples/extract_slides/?q=\\#data-extraction-from-slides \"Permanent link\")\n\nIn this guide, we demonstrate how to extract data from slides.\n\nMotivation\n\nWhen we want to translate key information from slides into structured data, simply isolating the text and running extraction might not be enough. Sometimes the important data is in the images on the slides, so we should consider including them in our extraction pipeline.\n\n## Defining the necessary Data Structures [¶](https://python.useinstructor.com/examples/extract_slides/?q=\\#defining-the-necessary-data-structures \"Permanent link\")\n\nLet's say we want to extract the competitors from various presentations and categorize them according to their respective industries.\n\nOur data model will have `Industry` which will be a list of `Competitor`'s for a specific industry, and `Competition` which will aggregate the competitors for all the industries.\n\n```md-code__content\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\nclass Competitor(BaseModel):\n    name: str\n    features: Optional[List[str]]\n\n# Define models\nclass Industry(BaseModel):\n    \"\"\"\n    Represents competitors from a specific industry extracted from an image using AI.\n    \"\"\"\n\n    name: str = Field(description=\"The name of the industry\")\n    competitor_list: List[Competitor] = Field(\n        description=\"A list of competitors for this industry\"\n    )\n\nclass Competition(BaseModel):\n    \"\"\"\n    This class serves as a structured representation of\n    competitors and their qualities.\n    \"\"\"\n\n    industry_list: List[Industry] = Field(\n        description=\"A list of industries and their competitors\"\n    )\n\n```\n\n## Competitors extraction [¶](https://python.useinstructor.com/examples/extract_slides/?q=\\#competitors-extraction \"Permanent link\")\n\nTo extract competitors from slides we will define a function which will read images from urls and extract the relevant information from them.\n\n```md-code__content\nimport instructor\nfrom openai import OpenAI\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(OpenAI())\n\n# Define functions\ndef read_images(image_urls: List[str]) -> Competition:\n    \"\"\"\n    Given a list of image URLs, identify the competitors in the images.\n    \"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=Competition,\n        max_tokens=2048,\n        temperature=0,\n        messages=[\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": [\\\n                    {\\\n                        \"type\": \"text\",\\\n                        \"text\": \"Identify competitors and generate key features for each competitor.\",\\\n                    },\\\n                    *[\\\n                        {\"type\": \"image_url\", \"image_url\": {\"url\": url}}\\\n                        for url in image_urls\\\n                    ],\\\n                ],\\\n            }\\\n        ],\n    )\n\n```\n\n## Execution [¶](https://python.useinstructor.com/examples/extract_slides/?q=\\#execution \"Permanent link\")\n\nFinally, we will run the previous function with a few sample slides to see the data extractor in action.\n\nAs we can see, our model extracted the relevant information for each competitor regardless of how this information was formatted in the original presentations.\n\n```md-code__content\nurl = [\\\n    'https://miro.medium.com/v2/resize:fit:1276/0*h1Rsv-fZWzQUyOkt',\\\n]\nmodel = read_images(url)\nprint(model.model_dump_json(indent=2))\n\"\"\"\n{\n  \"industry_list\": [\\\n    {\\\n      \"name\": \"Accommodation Services\",\\\n      \"competitor_list\": [\\\n        {\\\n          \"name\": \"CouchSurfing\",\\\n          \"features\": [\\\n            \"Free accommodation\",\\\n            \"Cultural exchange\",\\\n            \"Community-driven\",\\\n            \"User profiles and reviews\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"Craigslist\",\\\n          \"features\": [\\\n            \"Local listings\",\\\n            \"Variety of accommodation types\",\\\n            \"Direct communication with hosts\",\\\n            \"No booking fees\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"BedandBreakfast.com\",\\\n          \"features\": [\\\n            \"Specialized in B&Bs\",\\\n            \"User reviews\",\\\n            \"Booking options\",\\\n            \"Local experiences\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"AirBed & Breakfast (Airbnb)\",\\\n          \"features\": [\\\n            \"Wide range of accommodations\",\\\n            \"User reviews\",\\\n            \"Instant booking\",\\\n            \"Host profiles\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"Hostels.com\",\\\n          \"features\": [\\\n            \"Budget-friendly hostels\",\\\n            \"User reviews\",\\\n            \"Booking options\",\\\n            \"Global reach\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"RentDigs.com\",\\\n          \"features\": [\\\n            \"Rental listings\",\\\n            \"User-friendly interface\",\\\n            \"Local listings\",\\\n            \"Direct communication with landlords\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"VRBO\",\\\n          \"features\": [\\\n            \"Vacation rentals\",\\\n            \"Family-friendly options\",\\\n            \"User reviews\",\\\n            \"Booking protection\"\\\n          ]\\\n        },\\\n        {\\\n          \"name\": \"Hotels.com\",\\\n          \"features\": [\\\n            \"Wide range of hotels\",\\\n            \"Rewards program\",\\\n            \"User reviews\",\\\n            \"Price match guarantee\"\\\n          ]\\\n        }\\\n      ]\\\n    }\\\n  ]\n}\n\"\"\"\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/extract_slides/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/extract_slides/",
      "title": "Extracting Competitor Data from Slides Using AI - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/extract_slides/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/extract_slides.png",
      "ogTitle": "Extracting Competitor Data from Slides Using AI - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/extract_slides.png",
      "og:title": "Extracting Competitor Data from Slides Using AI - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/extract_slides/?q=",
      "statusCode": 200,
      "description": "Learn how to extract competitor data from presentation slides, leveraging AI for comprehensive information gathering.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to extract competitor data from presentation slides, leveraging AI for comprehensive information gathering.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/extract_slides.png",
      "twitter:title": "Extracting Competitor Data from Slides Using AI - Instructor",
      "og:description": "Learn how to extract competitor data from presentation slides, leveraging AI for comprehensive information gathering.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to extract competitor data from presentation slides, leveraging AI for comprehensive information gathering."
    }
  },
  {
    "markdown": "[Edit this page](https://github.com/jxnl/instructor/edit/main/docs/examples/multiple_classification.md \"Edit this page\") [View source of this page](https://github.com/jxnl/instructor/raw/main/docs/examples/multiple_classification.md \"View source of this page\")\n\n# Multiple Classification Tasks\n\nFor multi-label classification, we introduce a new enum class and a different Pydantic model to handle multiple labels.\n\n```md-code__content\nimport openai\nimport instructor\n\nfrom typing import List, Literal\nfrom pydantic import BaseModel, Field\n\n# Apply the patch to the OpenAI client\n# enables response_model keyword\nclient = instructor.from_openai(openai.OpenAI())\n\nLABELS = Literal[\"ACCOUNT\", \"BILLING\", \"GENERAL_QUERY\"]\n\nclass MultiClassPrediction(BaseModel):\n    \"\"\"\n    A few-shot example of multi-label classification:\n    Examples:\n    - \"My account is locked and I can't access my billing info.\": ACCOUNT, BILLING\n    - \"I need help with my subscription.\": ACCOUNT\n    - \"How do I change my payment method?\": BILLING\n    - \"Can you tell me the status of my order?\": BILLING\n    - \"I have a question about the product features.\": GENERAL_QUERY\n    \"\"\"\n\n    labels: List[LABELS] = Field(\n        ...,\n        description=\"Only select the labels that apply to the support ticket.\",\n    )\n\ndef multi_classify(data: str) -> MultiClassPrediction:\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_model=MultiClassPrediction,\n        messages=[\\\n            {\\\n                \"role\": \"system\",\\\n                \"content\": f\"You are a support agent at a tech company. Only select the labels that apply to the support ticket.\",\\\n            },\\\n            {\\\n                \"role\": \"user\",\\\n                \"content\": f\"Classify the following support ticket: <text>{data}</text>\",\\\n            },\\\n        ],\n    )  # type: ignore\n\nif __name__ == \"__main__\":\n    ticket = \"My account is locked and I can't access my billing info.\"\n    prediction = multi_classify(ticket)\n    assert {\"ACCOUNT\", \"BILLING\"} == {label for label in prediction.labels}\n    print(\"input:\", ticket)\n    #> input: My account is locked and I can't access my billing info.\n    print(\"labels:\", LABELS)\n    #> labels: typing.Literal['ACCOUNT', 'BILLING', 'GENERAL_QUERY']\n    print(\"prediction:\", prediction)\n    #> prediction: labels=['ACCOUNT', 'BILLING']\n\n```\n\nWas this page helpful?\n\nThanks for your feedback!\n\nThanks for your feedback! Help us improve this page by using our [feedback form](https://forms.gle/ijr9Zrcg2QWgKoWs7).\n\nBack to top",
    "metadata": {
      "url": "https://python.useinstructor.com/examples/multiple_classification/?q=",
      "ogUrl": "https://python.useinstructor.com/examples/multiple_classification/",
      "title": "Multi-Label Classification with OpenAI and Pydantic - Instructor",
      "author": "Jason Liu",
      "og:url": "https://python.useinstructor.com/examples/multiple_classification/",
      "og:type": "website",
      "ogImage": "https://python.useinstructor.com/assets/images/social/examples/multiple_classification.png",
      "ogTitle": "Multi-Label Classification with OpenAI and Pydantic - Instructor",
      "language": "en",
      "og:image": "https://python.useinstructor.com/assets/images/social/examples/multiple_classification.png",
      "og:title": "Multi-Label Classification with OpenAI and Pydantic - Instructor",
      "viewport": "width=device-width,initial-scale=1",
      "generator": "mkdocs-1.6.1, mkdocs-material-9.5.46",
      "sourceURL": "https://python.useinstructor.com/examples/multiple_classification/?q=",
      "statusCode": 200,
      "description": "Learn how to implement multi-label classification using OpenAI's API and Pydantic for effective support ticket classification.",
      "theme-color": "#00000000",
      "color-scheme": "normal",
      "twitter:card": "summary_large_image",
      "og:image:type": "image/png",
      "ogDescription": "Learn how to implement multi-label classification using OpenAI's API and Pydantic for effective support ticket classification.",
      "twitter:image": "https://python.useinstructor.com/assets/images/social/examples/multiple_classification.png",
      "twitter:title": "Multi-Label Classification with OpenAI and Pydantic - Instructor",
      "og:description": "Learn how to implement multi-label classification using OpenAI's API and Pydantic for effective support ticket classification.",
      "og:image:width": "1200",
      "og:image:height": "630",
      "ogLocaleAlternate": [],
      "twitter:description": "Learn how to implement multi-label classification using OpenAI's API and Pydantic for effective support ticket classification."
    }
  }
]